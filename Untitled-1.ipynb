{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"y_tilda_mirror.csv\"\n",
    "y_tilda_org = pd.read_csv(file)\n",
    "for i in np.arange(1,16):\n",
    "    shift = 10\n",
    "    set_values = i\n",
    "    #k = 0+15*(set_values-1)\n",
    "    k = i - 1\n",
    "    print(shift,set_values,k)\n",
    "    model_name = 'm_'+str(shift)+'_'+'val'+str(set_values)+'_gates'\n",
    "\n",
    "\n",
    "    # Create an empty DataFrame to store the shifted data\n",
    "    shifted_df = pd.DataFrame()\n",
    "\n",
    "    # Loop through unique trial values\n",
    "    for trial_value in scaled_df['trial'].unique():\n",
    "        # Filter the DataFrame for the current trial\n",
    "        trial_df = scaled_df[scaled_df['trial'] == trial_value].copy()\n",
    "\n",
    "        # Create shifted columns for each column in columns_to_shift\n",
    "        for col in columns_to_shift:\n",
    "            new_col_name = col + '_minus_' + str(shift)\n",
    "            trial_df[new_col_name] = trial_df[col].shift(shift)\n",
    "\n",
    "        # Drop the last 'i' records for each trial\n",
    "        trial_df = trial_df.dropna()\n",
    "\n",
    "        # Append the modified trial_df to the shifted_df\n",
    "        shifted_df = shifted_df.append(trial_df, ignore_index=True)\n",
    "\n",
    "    #selected_columns = ['id', 'trial','s_1_minus_'+str(shift),'s_2_minus_'+str(shift),'s_3_minus_'+str(shift),'s_4_minus_'+str(shift),'s_1','s_2','s_3','s_4']\n",
    "    selected_columns = ['id', 'trial','nose_x_minus_'+str(shift), 'nose_y_minus_'+str(shift),\n",
    "    'nose_z_minus_'+str(shift), 'headTop_x_minus_'+str(shift), 'headTop_y_minus_'+str(shift),\n",
    "    'headTop_z_minus_'+str(shift), 'neck_x_minus_'+str(shift), 'neck_y_minus_'+str(shift),\n",
    "    'neck_z_minus_'+str(shift), 'tailBase_x_minus_'+str(shift), 'tailBase_y_minus_'+str(shift),\n",
    "    'tailBase_z_minus_'+str(shift), 'lEar_x_minus_'+str(shift), 'lEar_y_minus_'+str(shift),\n",
    "    'lEar_z_minus_'+str(shift), 'lShoulder_x_minus_'+str(shift), 'lShoulder_y_minus_'+str(shift),\n",
    "    'lShoulder_z_minus_'+str(shift), 'lElbow_x_minus_'+str(shift), 'lElbow_y_minus_'+str(shift),\n",
    "    'lElbow_z_minus_'+str(shift), 'lWrist_x_minus_'+str(shift), 'lWrist_y_minus_'+str(shift),\n",
    "    'lWrist_z_minus_'+str(shift), 'lHip_x_minus_'+str(shift), 'lHip_y_minus_'+str(shift),\n",
    "    'lHip_z_minus_'+str(shift), 'rEar_x_minus_'+str(shift), 'rEar_y_minus_'+str(shift), 'rEar_z_minus_'+str(shift),\n",
    "    'rShoulder_x_minus_'+str(shift), 'rShoulder_y_minus_'+str(shift), 'rShoulder_z_minus_'+str(shift),\n",
    "    'rElbow_x_minus_'+str(shift), 'rElbow_y_minus_'+str(shift), 'rElbow_z_minus_'+str(shift),\n",
    "    'rWrist_x_minus_'+str(shift), 'rWrist_y_minus_'+str(shift), 'rWrist_z_minus_'+str(shift),\n",
    "    'rHip_x_minus_'+str(shift), 'rHip_y_minus_'+str(shift), 'rHip_z_minus_'+str(shift),'s_1','s_2','s_3','s_4']\n",
    "    #,s_1_minus_'+str(shift),'s_2_minus_'+str(shift), 's_3_minus_'+str(shift), 's_4_minus_'+str(shift),'s_1','s_2','s_3','s_4']\n",
    "    shifted_df = shifted_df[selected_columns]\n",
    "    # Step 5: Split the data into training and test sets based on the 'trial' column\n",
    "    train_set = shifted_df[shifted_df['trial']!=set_values].drop(columns=['id', 'trial'])\n",
    "    test_set = shifted_df[shifted_df['trial']==set_values].drop(columns=['id', 'trial'])\n",
    "    full_set = shifted_df.drop(columns=['id','trial'])\n",
    "\n",
    "    # split data into x and y \n",
    "    X_train, y_train = train_set.drop(columns=labels), train_set[labels]\n",
    "    X_test, y_test = test_set.drop(columns=labels), test_set[labels]\n",
    "    X, y = full_set.drop(columns=labels), full_set[labels]\n",
    "    #print(X_train.columns)\n",
    "    # reset index \n",
    "    X_train, y_train = X_train.reset_index(drop=True), y_train.reset_index(drop=True)\n",
    "    X_test, y_test = X_test.reset_index(drop=True), y_test.reset_index(drop=True)\n",
    "    X, y = X.reset_index(drop=True), y.reset_index(drop=True) \n",
    "\n",
    "    y_tilda = y_tilda_org[y_tilda_org['trial']==set_values].drop(columns=['trial','id'])\n",
    "    col_shift = ['s_1', 's_2', 's_3', 's_4']\n",
    "    # Loop through unique trial values\n",
    "        # Create shifted columns for each column in columns_to_shift\n",
    "    for col in col_shift:\n",
    "        new_col_name = col + '_minus_' + str(shift)\n",
    "        y_tilda[new_col_name] = y_tilda[col].shift(shift)\n",
    "\n",
    "    # Drop the last 'i' records for each trial\n",
    "    y_tilda = y_tilda.dropna()\n",
    "    #print(y_tilda.columns)\n",
    "    y_tilda = y_tilda.drop(columns=['s_1', 's_2', 's_3', 's_4'])\n",
    "    new_column_names = {'s_1_minus_10': 's_1',\n",
    "                        's_2_minus_10': 's_2',\n",
    "                        's_3_minus_10': 's_3',\n",
    "                        's_4_minus_10': 's_4'}\n",
    "\n",
    "    y_tilda = y_tilda.rename(columns=new_column_names)\n",
    "    y_tilda = y_tilda.to_numpy()\n",
    "    # Convert the dictionary keys into a list\n",
    "    keys_list = list(predictions_dict_m.keys())\n",
    "    #print(keys_list)\n",
    "    # Access the second key (index 1 in the list)\n",
    "    trial_key = keys_list[k]\n",
    "    y_hat = predictions_dict_m[trial_key]\n",
    "    # Assuming you have 'y_hat' and 'y_tilda' as tensors containing binary values (0 or 1)\n",
    "    y_hat = torch.tensor(y_hat, dtype=torch.float32)  # Convert to PyTorch tensor\n",
    "    y_hat = y_hat.clone().detach().requires_grad_(True).float()\n",
    "    #y_hat = torch.tensor(y_hat, dtype=torch.float32)  # Convert to float\n",
    "    y_tilda = torch.tensor(y_tilda, dtype=torch.float32)  # Convert to float\n",
    "\n",
    "    y_hat = y_hat.requires_grad_(True)\n",
    "    y_tilda = y_tilda.requires_grad_(True)\n",
    "\n",
    "    # Define the loss function\n",
    "    #loss_fn = nn.BCELoss()\n",
    "\n",
    "    # Calculate the loss\n",
    "    input = torch.tensor(X_test.values)\n",
    "    input = input.unsqueeze(1)\n",
    "    input = input.float()\n",
    "    # set input to require_grad\n",
    "    input = input.requires_grad_(True)\n",
    "    model.eval()\n",
    "    output, f = model(input)\n",
    "\n",
    "    # calculating loss \n",
    "    output = output.requires_grad_(True)\n",
    "    #loss_fn = nn.BCEWithLogitsLoss()\n",
    "    class_weights = torch.tensor([1.8]).to(device)\n",
    "    loss_fn = nn.BCEWithLogitsLoss(pos_weight=class_weights)\n",
    "    print('output shape:',output.shape)\n",
    "    print('target shape:',y_tilda.shape)\n",
    "    loss = loss_fn(output,y_tilda) \n",
    "    loss.backward()\n",
    "    #print(input)\n",
    "\n",
    "    # Access the gradients for the input data\n",
    "    key = f\"sm_shift{shift}_set{set_values}\"\n",
    "\n",
    "    # Store the predictions as NumPy arrays in the dictionary\n",
    "    input_gradients = input.grad.squeeze(1)\n",
    "\n",
    "    \n",
    "    input_gradients_np = input_gradients.numpy()\n",
    "\n",
    "    # Create DataFrame from NumPy array with the same column names as X_test\n",
    "    input_gradients = pd.DataFrame(input_gradients_np, columns=X_test.columns)\n",
    "    print(input_gradients.columns)\n",
    "    print(type(input_gradients['lWrist_x_minus_10']))\n",
    "    lWrist_x_gradient = input_gradients['lWrist_x_minus_10']\n",
    "    rWrist_x_gradient = input_gradients['rWrist_x_minus_10']\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title('gradients for trial: '+str(set_values)+\" \"+\"shift: \"+str(shift))\n",
    "    plt.plot(lWrist_x_gradient,label='left_wrist')\n",
    "    plt.plot(rWrist_x_gradient,label='right_wrist')\n",
    "    plt.legend()\n",
    "    plot_name = 'trial'+str(set_values)+'_'+'shift'+str(shift)+'_wrist_gradients.jpg'\n",
    "    #plt.savefig('C:/Users/kacpe/Desktop/study/research lab/lab_rotation_git/plots/gradients_lWrist_rWrist/'+plot_name)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
