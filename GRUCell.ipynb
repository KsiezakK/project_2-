{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random \n",
    "import math\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils as torch_utils\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import torch.nn.functional as F\n",
    "import d2l\n",
    "import time\n",
    "import traceback\n",
    "import fastprogress\n",
    "from torchmetrics.classification import BinaryAccuracy, Accuracy \n",
    "import torch.nn.init as init\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from itertools import repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 100\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data (with scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset class for loading data\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Implement data retrieval for each index\n",
    "        input_data = self.X[idx]\n",
    "        target_data = self.y[idx]\n",
    "        input_data = input_data.unsqueeze(0)\n",
    "        \n",
    "        # Convert data to torch tensors if required\n",
    "        input_tensor = torch.Tensor(input_data)\n",
    "        target_tensor = torch.Tensor(target_data)\n",
    "        \n",
    "        return input_tensor, target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with scaling\n",
    "df = pd.read_csv(\"C:/Users/kacpe/Desktop/study/research lab/data_model_v2.csv\")\n",
    "# List of column names to drop\n",
    "columns_to_drop = ['lKnee_x','lKnee_y','lKnee_z','lAnkle_x','lAnkle_y','lAnkle_z','rKnee_x','rKnee_y','rKnee_z','rAnkle_x','rAnkle_y','rAnkle_z']\n",
    "#columns_to_keep =  ['id', 'trial','lShoulder_x', 'lShoulder_y', 'lShoulder_z', 'lElbow_x', 'lElbow_y', 'lElbow_z', 'lWrist_x', 'lWrist_y', 'lWrist_z']\n",
    "#df = df.drop(columns=columns_to_drop)\n",
    "#df = df[columns_to_keep]\n",
    "# Step 1: Separate 'id' and 'trial' columns from the rest of the data\n",
    "data_to_scale = df.drop(columns=['id', 'trial'])\n",
    "\n",
    "# Step 2: Apply MinMaxScaler to the remaining columns\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(data_to_scale)\n",
    "\n",
    "# Convert the scaled data back to a DataFrame\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=data_to_scale.columns)\n",
    "\n",
    "# Step 3: Merge 'id' and 'trial' columns with the scaled data\n",
    "scaled_df[['id', 'trial']] = df[['id', 'trial']]\n",
    "\n",
    "# Step 4: Split the data into training and test sets based on the 'trial' column\n",
    "train_set = scaled_df[scaled_df['trial'].isin(range(1, 15))].drop(columns=['id', 'trial'])\n",
    "test_set = scaled_df[scaled_df['trial']==15].drop(columns=['id', 'trial'])\n",
    "val_set = scaled_df[scaled_df['trial']==16].drop(columns=['id', 'trial'])\n",
    "full_set = scaled_df.drop(columns=['id','trial'])\n",
    "\n",
    "# split data into x and y \n",
    "X_train, y_train = train_set.iloc[:,:-4], train_set.iloc[:,-4:]\n",
    "X_test, y_test = test_set.iloc[:,:-4], test_set.iloc[:,-4:]\n",
    "X_val, y_val = val_set.iloc[:,:-4], val_set.iloc[:,-4:]\n",
    "X, y = full_set.iloc[:,:-4], full_set.iloc[:,-4:]\n",
    "\n",
    "# Create custom datasets for training, validation, and testing\n",
    "full_dataset = MyDataset(torch.tensor(X.values), torch.tensor(y.values))\n",
    "train_dataset = MyDataset(torch.tensor(X_train.values), torch.tensor(y_train.values))\n",
    "val_dataset = MyDataset(torch.tensor(X_val.values), torch.tensor(y_val.values))\n",
    "test_dataset = MyDataset(torch.tensor(X_test.values), torch.tensor(y_test.values))\n",
    "\n",
    "# Create a DataLoader\n",
    "#batch_size = 5561#67  # Set your desired batch size\n",
    "#shuffle = False  # Set to False to preserve the order of your data\n",
    "#fullset_b_size = X.shape[0]/2\n",
    "fullset_dataloader = DataLoader(full_dataset, batch_size=X.shape[0], shuffle=False)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=X_train.shape[0], shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=X_test.shape[0], shuffle=False)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=X_val.shape[0], shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, drop_prob=0.2, bidirectional=False):\n",
    "        super(GRUNet, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop_prob)\n",
    "        self.gru = nn.GRUCell(input_dim, hidden_dim, bias=True)\n",
    "        #Xavier initialization for GRU weights\n",
    "        #for name, param in self.gru.named_parameters():\n",
    "        #    if 'weight' in name:\n",
    "        #        init.xavier_uniform_(param.data)\n",
    "        #    elif 'bias' in name:\n",
    "        #        init.constant_(param.data, 0.0)\n",
    "                \n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.sotfplus = nn.Softplus()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        \n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        out, h = self.gru(x, h)\n",
    "        out = self.fc(self.sotfplus(out[:,-1]))\n",
    "        #out = self.fc(self.relu(out[:,-1]))\n",
    "        out = F.softmax(out, dim=1)\n",
    "        return out, h\n",
    "    \n",
    "    #def init_hidden(self, batch_size):\n",
    "        #weight = next(self.parameters()).data\n",
    "        #hidden = weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device)\n",
    "        #return hidden\n",
    "    def init_hidden(self, batch_size):\n",
    "        if batch_size > 1:\n",
    "            weight = next(self.parameters()).data\n",
    "            hidden = weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device)\n",
    "        else:\n",
    "            weight = next(self.parameters()).data\n",
    "            hidden = weight.new(self.n_layers, self.hidden_dim).zero_().to(device)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUCellNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.gru = nn.GRUCell(input_dim, hidden_dim, bias=True)                \n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.gru_cells = nn.ModuleList([\n",
    "            nn.GRUCell(input_dim, hidden_dim) if i == 0 else nn.GRUCell(hidden_dim, hidden_dim)\n",
    "            for i in range(num_layers)\n",
    "        ])\n",
    "        self.batch_norm = nn.BatchNorm1d(hidden_dim)  # Add BatchNorm outside GRU cells\n",
    "\n",
    "        \n",
    "        \n",
    "    def forward(self, x, h=None):\n",
    "        if h is None:\n",
    "            h = [torch.zeros(x.size(0), self.hidden_dim) for _ in range(self.num_layers)]\n",
    "        \n",
    "        hidden_states = []\n",
    "        \n",
    "        for t in range(x.size(1)):\n",
    "            input_t = x[:, t, :]\n",
    "            new_hidden_states = []\n",
    "            for layer_idx, gru_cell in enumerate(self.gru_cells):\n",
    "                h[layer_idx] = gru_cell(input_t, h[layer_idx])\n",
    "                new_hidden_states.append(h[layer_idx])\n",
    "                input_t = h[layer_idx]  # Update input_t with the new hidden state for the next layer\n",
    "            hidden_states.append(new_hidden_states)\n",
    "        \n",
    "        last_hidden_states = [layer_states[-1] for layer_states in hidden_states]\n",
    "        # Apply BatchNorm to the last hidden state\n",
    "        last_hidden_states[-1] = self.batch_norm(last_hidden_states[-1])\n",
    "        #all_hidden_states = torch.cat(hidden_states, dim=1)  # Stack all hidden states across time steps\n",
    "        \n",
    "        \n",
    "        out = self.fc(self.softplus(last_hidden_states[-1]))\n",
    "        #out = self.fc(self.softplus(all_hidden_states[:, -1]))  # Use the last hidden state for prediction\n",
    "        #probs = torch.sigmoid(out)  # Apply sigmoid activation to get probabilities\n",
    "        #preds = torch.round(probs)  # Convert probabilities to binary predictions\n",
    "        #out = F.sigmoid(out, dim=1)\n",
    "        \n",
    "        return out, last_hidden_states \n",
    "    \n",
    "    \n",
    "    \n",
    "    #def init_hidden(self, batch_size):\n",
    "     #   return nn.Parameter(torch.zeros([batch_size, self.gru_cells[0].hidden_size]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(correct, total):\n",
    "    return float(correct)/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, optimizer, loss_fn, scheduler=None, device=None):\n",
    "    epoch_loss = []\n",
    "    epoch_correct, epoch_total = 0, 0\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    predicted_probs = []\n",
    "    predicted_labels = []\n",
    "    #hidden_states = []\n",
    "    for x, y in dataloader:\n",
    "        x = x.to(device).float()\n",
    "        y = y.to(device).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out, last_hidden_states = model(x)\n",
    "        y_prob = torch.sigmoid(out)\n",
    "        # Append the predicted probabilities to the list\n",
    "        predicted_probs.append(y_prob.cpu().detach().numpy())\n",
    "        loss = loss_fn(out, y)\n",
    "        epoch_loss.append(loss.item())\n",
    "\n",
    "        #hidden_states.append(hidden)\n",
    "        \n",
    "        y_pred = torch.round(y_prob)\n",
    "        epoch_correct += sum((y == y_pred).flatten()).item()\n",
    "        epoch_total += y.numel()\n",
    "        \n",
    "        loss.backward()\n",
    "        torch_utils.clip_grad_norm_(model.parameters(), max_norm=10)\n",
    "        optimizer.step()\n",
    "\n",
    "        predicted_labels.extend(zip(y_pred.cpu().detach().cpu().numpy(), y.cpu().numpy()))\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "    \n",
    "    return np.mean(epoch_loss), accuracy(epoch_correct, epoch_total), predicted_labels, predicted_probs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(dataloader, model, loss_fn, device=None):\n",
    "    epoch_loss = []\n",
    "    epoch_correct, epoch_total = 0, 0\n",
    "    model = model.to(device).float()\n",
    "    model.eval()\n",
    "    predicted_probs = []\n",
    "    predicted_labels = []\n",
    "    #hidden_states = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x = x.to(device).float()\n",
    "            y = y.to(device).float()\n",
    "            \n",
    "            out, last_hidden_states = model(x)\n",
    "            \n",
    "            loss = loss_fn(out, y)\n",
    "            epoch_loss.append(loss.item())\n",
    "\n",
    "            #hidden_states.append(hidden)\n",
    "            y_pred = torch.sigmoid(out)\n",
    "            predicted_probs.append(y_pred.cpu().detach().numpy())\n",
    "            y_pred = torch.round(y_pred)\n",
    "            epoch_correct += sum((y == y_pred).flatten())\n",
    "            epoch_total += y.numel()\n",
    "            predicted_labels.extend(zip(y_pred.cpu().numpy(), y.cpu().numpy()))\n",
    "    \n",
    "    return np.mean(epoch_loss), accuracy(epoch_correct, epoch_total), predicted_labels, predicted_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(train_dataloader, val_dataloader, model, optimizer, loss_fn, num_epochs, scheduler=None, device=None, schedule_on_train=True, verbose=True):\n",
    "    train_losses, train_accs = [], []\n",
    "    val_losses, val_accs = [], []\n",
    "\n",
    "    #train_hidden_states, val_hidden_states = [], []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_train_loss, epoch_train_acc, train_preds, train_probs = train(train_dataloader, model, optimizer, loss_fn, scheduler, device)\n",
    "        \n",
    "        train_losses.append(epoch_train_loss)\n",
    "        train_accs.append(epoch_train_acc)\n",
    "\n",
    "        #train_hidden_states.extend(train_hidden)\n",
    "        \n",
    "        if val_dataloader is not None:\n",
    "            epoch_val_loss, epoch_val_acc, val_preds, val_probs = validate(val_dataloader, model, loss_fn, device)\n",
    "        \n",
    "            val_losses.append(epoch_val_loss)\n",
    "            val_accs.append(epoch_val_acc)\n",
    "\n",
    "            #val_hidden_states.extend(val_hidden)\n",
    "        \n",
    "        #if isinstance(scheduler, ReduceLROnPlateau):\n",
    "        #    scheduler.step(epoch_train_acc if schedule_on_train or val_dataloader is None else epoch_val_acc)\n",
    "            \n",
    "        if epoch % 50 == 0:\n",
    "            val_str = f\", val loss: {epoch_val_loss}, val acc: {epoch_val_acc}\" if val_dataloader is not None else \"\"\n",
    "            print(f\"Epoch {epoch}, train loss: {epoch_train_loss}, train acc: {epoch_train_acc}{val_str}\")\n",
    "        if epoch == num_epochs - 1:  # Store values only for the final epoch\n",
    "            train_predicted_labels = train_preds\n",
    "            #val_predicted_labels = val_preds\n",
    "            train_probs_final = train_probs\n",
    "            #val_probs_final = val_probs\n",
    "            if val_dataloader is not None:\n",
    "                val_predicted_labels = val_preds\n",
    "                val_probs_final = val_probs\n",
    "\n",
    "    if val_dataloader is not None:        \n",
    "        return train_losses, train_accs, val_losses, val_accs, train_predicted_labels, val_predicted_labels, train_probs_final, val_probs_final\n",
    "    else: \n",
    "        return train_losses, train_accs, val_losses, val_accs, train_predicted_labels, train_probs_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6107, 54)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hyperparameters\n",
    "input_dim = 54\n",
    "hidden_dim = 22\n",
    "output_dim = 4\n",
    "num_layers = 1\n",
    "n_epochs =2500\n",
    "lr = 0.01\n",
    "\n",
    "# Create an instance of GRUCellNet\n",
    "model = GRUCellNet(input_dim, hidden_dim, output_dim, num_layers)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "class_weights = torch.tensor([1.8]).to(device)\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=class_weights)  \n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train loss: 0.1825670599937439, train acc: 0.9345423284755199, val loss: 1.117614984512329, val acc: 0.8097014925373134\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_losses, train_accs, val_losses, val_accs, train_predicted, val_predicted, train_probs, val_probs\u001b[39m=\u001b[39m run_training(\n\u001b[0;32m      2\u001b[0m     train_dataloader, val_dataloader\u001b[39m=\u001b[39;49mval_dataloader, model\u001b[39m=\u001b[39;49mmodel, optimizer\u001b[39m=\u001b[39;49moptimizer, loss_fn\u001b[39m=\u001b[39;49mloss_fn, num_epochs\u001b[39m=\u001b[39;49mn_epochs, scheduler\u001b[39m=\u001b[39;49mscheduler)\n",
      "Cell \u001b[1;32mIn[12], line 8\u001b[0m, in \u001b[0;36mrun_training\u001b[1;34m(train_dataloader, val_dataloader, model, optimizer, loss_fn, num_epochs, scheduler, device, schedule_on_train, verbose)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39m#train_hidden_states, val_hidden_states = [], []\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[1;32m----> 8\u001b[0m     epoch_train_loss, epoch_train_acc, train_preds, train_probs \u001b[39m=\u001b[39m train(train_dataloader, model, optimizer, loss_fn, scheduler, device)\n\u001b[0;32m     10\u001b[0m     train_losses\u001b[39m.\u001b[39mappend(epoch_train_loss)\n\u001b[0;32m     11\u001b[0m     train_accs\u001b[39m.\u001b[39mappend(epoch_train_acc)\n",
      "Cell \u001b[1;32mIn[10], line 15\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(dataloader, model, optimizer, loss_fn, scheduler, device)\u001b[0m\n\u001b[0;32m     11\u001b[0m y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mto(device)\u001b[39m.\u001b[39mfloat()\n\u001b[0;32m     13\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> 15\u001b[0m out, last_hidden_states \u001b[39m=\u001b[39m model(x)\n\u001b[0;32m     16\u001b[0m y_prob \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msigmoid(out)\n\u001b[0;32m     17\u001b[0m \u001b[39m# Append the predicted probabilities to the list\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kacpe\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[15], line 29\u001b[0m, in \u001b[0;36mGRUCellNet.forward\u001b[1;34m(self, x, h)\u001b[0m\n\u001b[0;32m     27\u001b[0m new_hidden_states \u001b[39m=\u001b[39m []\n\u001b[0;32m     28\u001b[0m \u001b[39mfor\u001b[39;00m layer_idx, gru_cell \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgru_cells):\n\u001b[1;32m---> 29\u001b[0m     h[layer_idx] \u001b[39m=\u001b[39m gru_cell(input_t, h[layer_idx])\n\u001b[0;32m     30\u001b[0m     new_hidden_states\u001b[39m.\u001b[39mappend(h[layer_idx])\n\u001b[0;32m     31\u001b[0m     input_t \u001b[39m=\u001b[39m h[layer_idx]  \u001b[39m# Update input_t with the new hidden state for the next layer\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kacpe\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\kacpe\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1279\u001b[0m, in \u001b[0;36mGRUCell.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m   1276\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1277\u001b[0m     hx \u001b[39m=\u001b[39m hx\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_batched \u001b[39melse\u001b[39;00m hx\n\u001b[1;32m-> 1279\u001b[0m ret \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mgru_cell(\n\u001b[0;32m   1280\u001b[0m     \u001b[39minput\u001b[39;49m, hx,\n\u001b[0;32m   1281\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight_ih, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight_hh,\n\u001b[0;32m   1282\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_ih, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_hh,\n\u001b[0;32m   1283\u001b[0m )\n\u001b[0;32m   1285\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_batched:\n\u001b[0;32m   1286\u001b[0m     ret \u001b[39m=\u001b[39m ret\u001b[39m.\u001b[39msqueeze(\u001b[39m0\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_losses, train_accs, val_losses, val_accs, train_predicted, val_predicted, train_probs, val_probs= run_training(\n",
    "    train_dataloader, val_dataloader=val_dataloader, model=model, optimizer=optimizer, loss_fn=loss_fn, num_epochs=n_epochs, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRUCellNet(\n",
       "  (gru): GRUCell(54, 22)\n",
       "  (fc): Linear(in_features=22, out_features=4, bias=True)\n",
       "  (softplus): Softplus(beta=1, threshold=20)\n",
       "  (relu): ReLU()\n",
       "  (gru_cells): ModuleList(\n",
       "    (0): GRUCell(54, 22)\n",
       "  )\n",
       "  (batch_norm): BatchNorm1d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the saved weights into the model\n",
    "#torch.save(model.state_dict(), 'model_weights.pth')\n",
    "#model = GRUCellNet(input_dim, hidden_dim, output_dim, num_layers)\n",
    "model.load_state_dict(torch.load('model_weights.pth'))\n",
    "model.eval()  # Set the model in evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Forward pass to get predictions\u001b[39;00m\n\u001b[0;32m      2\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[1;32m----> 3\u001b[0m epoch_loss, accuracy, predicted_labels, predicted_probs \u001b[39m=\u001b[39m validate(test_dataloader,model,loss_fn)\n\u001b[0;32m      4\u001b[0m predicted_labels\n",
      "Cell \u001b[1;32mIn[11], line 27\u001b[0m, in \u001b[0;36mvalidate\u001b[1;34m(dataloader, model, loss_fn, device)\u001b[0m\n\u001b[0;32m     24\u001b[0m         epoch_total \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mnumel()\n\u001b[0;32m     25\u001b[0m         predicted_labels\u001b[39m.\u001b[39mextend(\u001b[39mzip\u001b[39m(y_pred\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy(), y\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()))\n\u001b[1;32m---> 27\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mmean(epoch_loss), accuracy(epoch_correct, epoch_total), predicted_labels, predicted_probs\n",
      "\u001b[1;31mTypeError\u001b[0m: 'float' object is not callable"
     ]
    }
   ],
   "source": [
    "# Forward pass to get predictions\n",
    "model.eval()\n",
    "epoch_loss, accuracy, predicted_labels, predicted_probs = validate(test_dataloader,model,loss_fn)\n",
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('model_weights.pth'))  # Load saved weights\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "# Initialize an empty list to store predictions\n",
    "all_predictions = []\n",
    "\n",
    "# Iterate through the test data batches\n",
    "for inputs, _ in test_dataloader:\n",
    "    inputs = inputs.float()\n",
    "    # Forward pass to get predictions\n",
    "    with torch.no_grad():\n",
    "        predictions, _ = model(inputs)\n",
    "        probabilities = torch.sigmoid(predictions)\n",
    "        preds = torch.round(probabilities)\n",
    "\n",
    "    # Append predictions to the list\n",
    "    all_predictions.append(preds)\n",
    "\n",
    "# Concatenate the predicted batches\n",
    "all_predictions = torch.cat(all_predictions, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s_1</th>\n",
       "      <th>s_2</th>\n",
       "      <th>s_3</th>\n",
       "      <th>s_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6107</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6108</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6109</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6110</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6111</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6612</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6613</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6614</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6615</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6616</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>510 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      s_1  s_2  s_3  s_4\n",
       "6107  1.0  1.0  1.0  1.0\n",
       "6108  1.0  1.0  1.0  1.0\n",
       "6109  1.0  1.0  1.0  1.0\n",
       "6110  1.0  1.0  1.0  1.0\n",
       "6111  1.0  1.0  1.0  1.0\n",
       "...   ...  ...  ...  ...\n",
       "6612  1.0  0.0  0.0  1.0\n",
       "6613  1.0  0.0  0.0  1.0\n",
       "6614  1.0  0.0  0.0  1.0\n",
       "6615  1.0  0.0  0.0  1.0\n",
       "6616  1.0  0.0  0.0  1.0\n",
       "\n",
       "[510 rows x 4 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for each output state:\n",
      "0.7480392156862744\n"
     ]
    }
   ],
   "source": [
    "# Convert the tensor of predictions to a DataFrame\n",
    "predictions_df = pd.DataFrame(all_predictions.numpy(), columns=y_test.columns, index=y_test.index)\n",
    "# Calculate accuracy for each output state\n",
    "accuracies = (predictions_df == y_test).mean()\n",
    "\n",
    "print(\"Accuracy for each output state:\")\n",
    "print(np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, optimizer, loss_fn, scheduler=None, device=None):\n",
    "    epoch_loss = []\n",
    "    epoch_correct, epoch_total = 0, 0\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    predicted_probs = []\n",
    "    predicted_labels = []\n",
    "    hidden_states = []\n",
    "    \n",
    "    for x, y in dataloader:\n",
    "        x = x.to(device).float()\n",
    "        y = y.to(device).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred_probs, _, hidden = model(x)  # Get probabilities and hidden states\n",
    "        \n",
    "        loss = loss_fn(y_pred_probs, y)\n",
    "        epoch_loss.append(loss.item())\n",
    "\n",
    "        hidden_states.append(hidden)\n",
    "        \n",
    "        y_pred = torch.round(y_pred_probs)\n",
    "        epoch_correct += sum((y == y_pred).flatten()).item()\n",
    "        epoch_total += y.numel()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        predicted_probs.extend(y_pred_probs.cpu().detach().numpy())\n",
    "        predicted_labels.extend(zip(y_pred.cpu().detach().numpy(), y.cpu().numpy()))\n",
    "        \n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "    \n",
    "    #all_hidden_states = torch.cat([torch.stack(layer_states) for layer_states in hidden_states], dim=1)  # Concatenate tensors within each time step\n",
    "    \n",
    "    return np.mean(epoch_loss), accuracy(epoch_correct, epoch_total), predicted_labels,predicted_probs #all_hidden_states \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(train_dataloader, val_dataloader, model, optimizer, loss_fn, num_epochs, scheduler=None, device=None, schedule_on_train=True, verbose=True):\n",
    "    train_losses, train_accs = [], []\n",
    "    val_losses, val_accs = [], []\n",
    "    train_predicted_labels = []  \n",
    "    val_predicted_labels = []  \n",
    "    train_hidden_states = []  \n",
    "    val_hidden_states = []  \n",
    "    train_predicted_probs = []  \n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        #epoch_train_loss, epoch_train_acc, train_preds, train_hidden, train_probs = train(train_dataloader, model, optimizer, loss_fn, scheduler, device)\n",
    "        epoch_train_loss, epoch_train_acc, train_preds, train_probs = train(train_dataloader, model, optimizer, loss_fn, scheduler, device)\n",
    "        \n",
    "        train_losses.append(epoch_train_loss)\n",
    "        train_accs.append(epoch_train_acc)\n",
    "        train_predicted_labels.extend(train_preds)\n",
    "        train_hidden_states.extend(train_hidden)\n",
    "        train_predicted_probs.extend(train_probs)\n",
    "        \n",
    "        if val_dataloader is not None:\n",
    "            epoch_val_loss, epoch_val_acc, val_preds, val_hidden, val_probs = validate(val_dataloader, model, loss_fn, device)\n",
    "        \n",
    "            val_losses.append(epoch_val_loss)\n",
    "            val_accs.append(epoch_val_acc)\n",
    "            val_predicted_labels.extend(val_preds)\n",
    "            val_hidden_states.extend(val_hidden)\n",
    "            val_predicted_probs.extend(val_probs)\n",
    "        \n",
    "        if epoch % 50 == 0:\n",
    "            val_str = f\", val loss: {epoch_val_loss}, val acc: {epoch_val_acc}\" if val_dataloader is not None else \"\"\n",
    "            print(f\"Epoch {epoch}, train loss: {epoch_train_loss}, train acc: {epoch_train_acc}{val_str}\")\n",
    "            \n",
    "    return (\n",
    "        train_losses, train_accs, val_losses, val_accs,\n",
    "        train_predicted_labels, val_predicted_labels,\n",
    "        train_predicted_probs, val_predicted_probs )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
