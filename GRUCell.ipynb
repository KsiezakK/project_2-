{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random \n",
    "import math\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils as torch_utils\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import torch.nn.functional as F\n",
    "import d2l\n",
    "import time\n",
    "import traceback\n",
    "import fastprogress\n",
    "from torchmetrics.classification import BinaryAccuracy, Accuracy \n",
    "import torch.nn.init as init\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from itertools import repeat\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "090524\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Get the current date and time\n",
    "current_datetime = datetime.now()\n",
    "\n",
    "# Format the date and time\n",
    "current_datetime = current_datetime.strftime('%d%m%y')\n",
    "\n",
    "print(current_datetime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 100\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if CUDA (GPU support) is available\n",
    "if torch.cuda.is_available():\n",
    "    # Set the device to the first available GPU\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    # If GPU is not available, use the CPU\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] The system cannot find the file specified: 'c:\\\\Users\\\\kacpe\\\\Desktop\\\\lab_rotation_git\\\\data\\\\data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Combine the current directory with the relative path to get the absolute path\u001b[39;00m\n\u001b[0;32m      8\u001b[0m absolute_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(current_dir, relative_path)\n\u001b[1;32m----> 9\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mabsolute_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified: 'c:\\\\Users\\\\kacpe\\\\Desktop\\\\lab_rotation_git\\\\data\\\\data'"
     ]
    }
   ],
   "source": [
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Define the relative path to the desired directory\n",
    "relative_path = \"data\"\n",
    "\n",
    "# Combine the current directory with the relative path to get the absolute path\n",
    "absolute_path = os.path.join(current_dir, relative_path)\n",
    "os.chdir(absolute_path)\n",
    "#print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\kacpe\\\\Desktop\\\\lab_rotation_git\\\\data'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUCellNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.gru = nn.GRUCell(input_dim, hidden_dim, bias=True)                \n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.gru_cells = nn.ModuleList([\n",
    "            nn.GRUCell(input_dim, hidden_dim) if i == 0 else nn.GRUCell(hidden_dim, hidden_dim)\n",
    "            for i in range(num_layers)\n",
    "        ])\n",
    "        self.batch_norm = nn.BatchNorm1d(hidden_dim)  # Add BatchNorm outside GRU cells\n",
    "\n",
    "        \n",
    "        \n",
    "    def forward(self, x, h=None):\n",
    "        if h is None:\n",
    "            h = [torch.zeros(x.size(0), self.hidden_dim) for _ in range(self.num_layers)]\n",
    "        \n",
    "        hidden_states = []\n",
    "        \n",
    "        for t in range(x.size(1)):\n",
    "            input_t = x[:, t, :]\n",
    "            new_hidden_states = []\n",
    "            for layer_idx, gru_cell in enumerate(self.gru_cells):\n",
    "                h[layer_idx] = gru_cell(input_t, h[layer_idx])\n",
    "                new_hidden_states.append(h[layer_idx])\n",
    "                input_t = h[layer_idx]  # Update input_t with the new hidden state for the next layer\n",
    "            hidden_states.append(new_hidden_states)\n",
    "        \n",
    "        last_hidden_states = [layer_states[-1] for layer_states in hidden_states]\n",
    "        # Apply BatchNorm to the last hidden state\n",
    "        last_hidden_states[-1] = self.batch_norm(last_hidden_states[-1])\n",
    "        out = self.fc(self.relu(last_hidden_states[-1]))\n",
    "        #out = self.fc(last_hidden_states[-1])\n",
    "        #out = torch.sigmoid(out)\n",
    "        \n",
    "        return out, last_hidden_states "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset class for loading data\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Implement data retrieval for each index\n",
    "        input_data = self.X[idx]\n",
    "        target_data = self.y[idx]\n",
    "        input_data = input_data.unsqueeze(0)\n",
    "        \n",
    "        # Convert data to torch tensors if required\n",
    "        input_tensor = torch.Tensor(input_data)\n",
    "        target_tensor = torch.Tensor(target_data)\n",
    "        \n",
    "        return input_tensor, target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(correct, total):\n",
    "    return float(correct)/total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, optimizer, loss_fn, scheduler=None, device=None):\n",
    "    epoch_loss = []\n",
    "    epoch_correct, epoch_total = 0, 0\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    predicted_probs = []\n",
    "    predicted_labels = []\n",
    "    hidden_states = []\n",
    "    for x, y in dataloader:\n",
    "        x = x.to(device).float()\n",
    "        y = y.to(device).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        hidden_states_batch = []  # Initialize a list to store hidden states for the current batch        \n",
    "        out, last_hidden_states = model(x)\n",
    "        y_prob = torch.sigmoid(out)\n",
    "        # Append the predicted probabilities to the list\n",
    "        predicted_probs.append(y_prob.cpu().detach().numpy())\n",
    "        loss = loss_fn(out, y)\n",
    "        epoch_loss.append(loss.item())\n",
    "\n",
    "        #hidden_states.append(hidden)\n",
    "        \n",
    "        y_pred = torch.round(y_prob)\n",
    "        # Append the batch's hidden states to the list\n",
    "        for layer_state in last_hidden_states:\n",
    "            hidden_states_batch.append(layer_state.cpu().detach().numpy())\n",
    "        epoch_correct += sum((y == y_pred).flatten()).item()\n",
    "        epoch_total += y.numel()\n",
    "        # Append the batch's hidden states to the overall hidden_states list\n",
    "        hidden_states.append(hidden_states_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        torch_utils.clip_grad_norm_(model.parameters(), max_norm=10)\n",
    "        optimizer.step()\n",
    "\n",
    "        predicted_labels.extend(zip(y_pred.cpu().detach().cpu().numpy(), y.cpu().numpy()))\n",
    "        if scheduler:\n",
    "            scheduler.step(loss)\n",
    "    \n",
    "    return np.mean(epoch_loss), accuracy(epoch_correct, epoch_total), predicted_labels, predicted_probs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(dataloader, model, loss_fn, device=None):\n",
    "    epoch_loss = []\n",
    "    epoch_correct, epoch_total = 0, 0\n",
    "    model = model.to(device).float()\n",
    "    model.eval()\n",
    "    predicted_probs = []\n",
    "    predicted_labels = []\n",
    "    #hidden_states = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x = x.to(device).float()\n",
    "            y = y.to(device).float()\n",
    "            \n",
    "            out, last_hidden_states = model(x)\n",
    "            \n",
    "            loss = loss_fn(out, y)\n",
    "            epoch_loss.append(loss.item())\n",
    "\n",
    "            #hidden_states.append(hidden)\n",
    "            y_pred = torch.sigmoid(out)\n",
    "            predicted_probs.append(y_pred.cpu().detach().numpy())\n",
    "            y_pred = torch.round(y_pred)\n",
    "            epoch_correct += sum((y == y_pred).flatten())\n",
    "            epoch_total += y.numel()\n",
    "            predicted_labels.extend(zip(y_pred.cpu().numpy(), y.cpu().numpy()))\n",
    "    \n",
    "    return np.mean(epoch_loss), accuracy(epoch_correct, epoch_total), predicted_labels, predicted_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(train_dataloader, val_dataloader, model, optimizer, loss_fn, num_epochs, scheduler=None, device=None, schedule_on_train=True, verbose=True):\n",
    "    train_losses, train_accs = [], []\n",
    "    val_losses, val_accs = [], []\n",
    "\n",
    "    #train_hidden_states, val_hidden_states = [], []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_train_loss, epoch_train_acc, train_preds, train_probs = train(train_dataloader, model, optimizer, loss_fn, scheduler, device)\n",
    "        \n",
    "        train_losses.append(epoch_train_loss)\n",
    "        train_accs.append(epoch_train_acc)\n",
    "\n",
    "        #train_hidden_states.extend(train_hidden)\n",
    "        \n",
    "        if val_dataloader is not None:\n",
    "            epoch_val_loss, epoch_val_acc, val_preds, val_probs = validate(val_dataloader, model, loss_fn, device)\n",
    "        \n",
    "            val_losses.append(epoch_val_loss)\n",
    "            val_accs.append(epoch_val_acc)\n",
    "\n",
    "            #val_hidden_states.extend(val_hidden)\n",
    "        \n",
    "        if isinstance(scheduler, ReduceLROnPlateau):\n",
    "            scheduler.step(epoch_train_acc if schedule_on_train or val_dataloader is None else epoch_val_acc)\n",
    "            \n",
    "        if epoch % 10 == 0:\n",
    "            val_str = f\", val loss: {epoch_val_loss}, val acc: {epoch_val_acc}\" if val_dataloader is not None else \"\"\n",
    "            print(f\"Epoch {epoch}, train loss: {epoch_train_loss}, train acc: {epoch_train_acc}{val_str}\")\n",
    "        if epoch == num_epochs - 1:  # Store values only for the final epoch\n",
    "            train_predicted_labels = train_preds\n",
    "            #val_predicted_labels = val_preds\n",
    "            train_probs_final = train_probs\n",
    "            #val_probs_final = val_probs\n",
    "            if val_dataloader is not None:\n",
    "                val_predicted_labels = val_preds\n",
    "                val_probs_final = val_probs\n",
    "\n",
    "    if val_dataloader is not None:        \n",
    "        return train_losses, train_accs, val_losses, val_accs, train_predicted_labels, val_predicted_labels, train_probs_final, val_probs_final\n",
    "    else: \n",
    "        return train_losses, train_accs, val_losses, val_accs, train_predicted_labels, train_probs_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, y, current_datetime=None):\n",
    "    \"\"\"\n",
    "    Evaluate the given model using the provided train dataloader and labels.\n",
    "    \n",
    "    Args:\n",
    "    - model: The PyTorch model to evaluate.\n",
    "    - train_dataloader: The DataLoader for training data.\n",
    "    - y_train: The ground truth labels for training data.\n",
    "    - current_datetime: The current date and time for folder naming.\n",
    "\n",
    "    Returns:\n",
    "    - mean_accuracy: Mean accuracy for each output state.\n",
    "    \"\"\"\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Initialize empty lists to store predictions\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "\n",
    "    # Iterate through the train data batches\n",
    "    for inputs, _ in dataloader:\n",
    "        inputs = inputs.float()\n",
    "        with torch.no_grad():\n",
    "            predictions, _ = model(inputs)\n",
    "            probabilities = torch.sigmoid(predictions)\n",
    "            preds = torch.round(probabilities)\n",
    "\n",
    "        # Append predictions to the list\n",
    "        all_preds.append(preds.numpy())\n",
    "        all_probs.append(probabilities.numpy())\n",
    "\n",
    "    # Concatenate the predicted batches\n",
    "    all_preds_array = np.concatenate(all_preds, axis=0)\n",
    "    all_probs_array = np.concatenate(all_probs, axis=0)\n",
    "\n",
    "    # Define column names\n",
    "    columns = ['s_1', 's_2', 's_3', 's_4']\n",
    "\n",
    "    # Create DataFrames from NumPy arrays\n",
    "    all_probs_df = pd.DataFrame(all_probs_array, columns=columns)\n",
    "    predictions_df = pd.DataFrame(all_preds_array, columns=y.columns, index=y.index)\n",
    "\n",
    "    # Calculate accuracy for each output state\n",
    "    accuracies = (predictions_df == y).mean()\n",
    "\n",
    "    # Print and save accuracy results\n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    print(\"Accuracy for each output state:\")\n",
    "    print(mean_accuracy)\n",
    "\n",
    "    return mean_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(file_path, value_to_save):\n",
    "    \"\"\"\n",
    "    Save a value to a file, creating the file if it doesn't exist.\n",
    "    \n",
    "    Args:\n",
    "    - file_path: The path to the file.\n",
    "    - value_to_save: The value to save to the file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if the file exists\n",
    "        if not os.path.exists(file_path):\n",
    "            # If the file doesn't exist, create it\n",
    "            with open(file_path, \"w\") as file:\n",
    "                pass  # Empty pass to create an empty file\n",
    "\n",
    "        # Open the file in append mode and write the value\n",
    "        with open(file_path, \"a\") as file:\n",
    "            file.write(value_to_save + '\\n')\n",
    "            print(f\"Value '{value_to_save}' saved to '{file_path}' successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s_1', 's_2', 's_3', 's_4']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_drop = ['lKnee_x','lKnee_y','lKnee_z','lAnkle_x','lAnkle_y','lAnkle_z','rKnee_x','rKnee_y','rKnee_z','rAnkle_x','rAnkle_y','rAnkle_z']\n",
    "data = \"data_m_filtered_oldlabels.csv\"\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(data)\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "labels = ['s_1','s_2','s_3','s_4']\n",
    "data_to_scale = df.drop(columns=['trial'])\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(data_to_scale)\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=data_to_scale.columns)\n",
    "scaled_df[['trial']] = df[['trial']]\n",
    "cols_to_omit = ['trial']\n",
    "columns_to_shift = ['s_1','s_2','s_3','s_4']\n",
    "columns_to_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_dim = 4\n",
    "hidden_dim = 4\n",
    "output_dim = 4\n",
    "num_layers = 1\n",
    "n_epochs =100\n",
    "lr = 0.01\n",
    "\n",
    "# Create an instance of GRUCellNet\n",
    "model = GRUCellNet(input_dim, hidden_dim, output_dim, num_layers)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "#class_weights = torch.tensor([1.8]).to(device)\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=None)  \n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.9)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.9, patience=10, verbose=True, threshold=0.01, threshold_mode='rel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train loss: 0.7499982118606567, train acc: 0.40565161186070936\n",
      "Epoch 00013: reducing learning rate of group 0 to 9.0000e-03.\n",
      "Epoch 10, train loss: 0.6582965850830078, train acc: 0.6205259755999031\n",
      "Epoch 00024: reducing learning rate of group 0 to 8.1000e-03.\n",
      "Epoch 00035: reducing learning rate of group 0 to 7.2900e-03.\n",
      "Epoch 20, train loss: 0.6143960952758789, train acc: 0.6298779995152298\n",
      "Epoch 00046: reducing learning rate of group 0 to 6.5610e-03.\n",
      "Epoch 00057: reducing learning rate of group 0 to 5.9049e-03.\n",
      "Epoch 30, train loss: 0.5724542140960693, train acc: 0.6814454229619455\n",
      "Epoch 00068: reducing learning rate of group 0 to 5.3144e-03.\n",
      "Epoch 00079: reducing learning rate of group 0 to 4.7830e-03.\n",
      "Epoch 40, train loss: 0.5300863981246948, train acc: 0.7659368182919932\n",
      "Epoch 00090: reducing learning rate of group 0 to 4.3047e-03.\n",
      "Epoch 00101: reducing learning rate of group 0 to 3.8742e-03.\n",
      "Epoch 50, train loss: 0.49731695652008057, train acc: 0.771127898521451\n",
      "Epoch 00112: reducing learning rate of group 0 to 3.4868e-03.\n",
      "Epoch 60, train loss: 0.47165629267692566, train acc: 0.8241900298941586\n",
      "Epoch 00123: reducing learning rate of group 0 to 3.1381e-03.\n",
      "Epoch 00134: reducing learning rate of group 0 to 2.8243e-03.\n",
      "Epoch 70, train loss: 0.451786607503891, train acc: 0.8241900298941586\n",
      "Epoch 00145: reducing learning rate of group 0 to 2.5419e-03.\n",
      "Epoch 00156: reducing learning rate of group 0 to 2.2877e-03.\n",
      "Epoch 80, train loss: 0.43635183572769165, train acc: 0.8241900298941586\n",
      "Epoch 00167: reducing learning rate of group 0 to 2.0589e-03.\n",
      "Epoch 00178: reducing learning rate of group 0 to 1.8530e-03.\n",
      "Epoch 90, train loss: 0.42407816648483276, train acc: 0.8225539306778702\n",
      "Epoch 00189: reducing learning rate of group 0 to 1.6677e-03.\n",
      "Epoch 00200: reducing learning rate of group 0 to 1.5009e-03.\n",
      "Model saved successfully at: c:\\Users\\kacpe\\Desktop\\lab_rotation_git\\data\\models\\model_s_090524\\s_10_val1.pth\n",
      "Accuracy for each output state:\n",
      "0.8642643613153429\n",
      "Value 's_10_val1: 0.8642643613153429' saved to 'c:\\Users\\kacpe\\Desktop\\lab_rotation_git\\data\\results/s_results_train_090524.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.902317880794702\n",
      "Value 's_10_val1: 0.902317880794702' saved to 'c:\\Users\\kacpe\\Desktop\\lab_rotation_git\\data\\results/s_results_test_090524.txt' successfully.\n",
      "Epoch 0, train loss: 0.442021906375885, train acc: 0.8359471474438133\n",
      "Epoch 00211: reducing learning rate of group 0 to 1.3509e-03.\n",
      "Epoch 00222: reducing learning rate of group 0 to 1.2158e-03.\n",
      "Epoch 10, train loss: 0.4350432753562927, train acc: 0.8359471474438133\n",
      "Epoch 00233: reducing learning rate of group 0 to 1.0942e-03.\n",
      "Epoch 20, train loss: 0.42950689792633057, train acc: 0.8436239400675064\n",
      "Epoch 00244: reducing learning rate of group 0 to 9.8477e-04.\n",
      "Epoch 00255: reducing learning rate of group 0 to 8.8629e-04.\n",
      "Epoch 30, train loss: 0.4251260757446289, train acc: 0.8613443648637523\n",
      "Epoch 00266: reducing learning rate of group 0 to 7.9766e-04.\n",
      "Epoch 00277: reducing learning rate of group 0 to 7.1790e-04.\n",
      "Epoch 40, train loss: 0.42162376642227173, train acc: 0.8613443648637523\n",
      "Epoch 00288: reducing learning rate of group 0 to 6.4611e-04.\n",
      "Epoch 00299: reducing learning rate of group 0 to 5.8150e-04.\n",
      "Epoch 50, train loss: 0.4187953472137451, train acc: 0.8613443648637523\n",
      "Epoch 00310: reducing learning rate of group 0 to 5.2335e-04.\n",
      "Epoch 00321: reducing learning rate of group 0 to 4.7101e-04.\n",
      "Epoch 60, train loss: 0.4165230095386505, train acc: 0.8567753354737795\n",
      "Epoch 00332: reducing learning rate of group 0 to 4.2391e-04.\n",
      "Epoch 70, train loss: 0.4146650731563568, train acc: 0.8567753354737795\n",
      "Epoch 00343: reducing learning rate of group 0 to 3.8152e-04.\n",
      "Epoch 00354: reducing learning rate of group 0 to 3.4337e-04.\n",
      "Epoch 80, train loss: 0.41314446926116943, train acc: 0.8567753354737795\n",
      "Epoch 00365: reducing learning rate of group 0 to 3.0903e-04.\n",
      "Epoch 00376: reducing learning rate of group 0 to 2.7813e-04.\n",
      "Epoch 90, train loss: 0.41189178824424744, train acc: 0.8567753354737795\n",
      "Epoch 00387: reducing learning rate of group 0 to 2.5032e-04.\n",
      "Epoch 00398: reducing learning rate of group 0 to 2.2528e-04.\n",
      "Model saved successfully at: c:\\Users\\kacpe\\Desktop\\lab_rotation_git\\data\\models\\model_s_090524\\s_20_val1.pth\n",
      "Accuracy for each output state:\n",
      "0.8567753354737795\n",
      "Value 's_20_val1: 0.8567753354737795' saved to 'c:\\Users\\kacpe\\Desktop\\lab_rotation_git\\data\\results/s_results_train_090524.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8776595744680851\n",
      "Value 's_20_val1: 0.8776595744680851' saved to 'c:\\Users\\kacpe\\Desktop\\lab_rotation_git\\data\\results/s_results_test_090524.txt' successfully.\n",
      "Epoch 0, train loss: 0.43850603699684143, train acc: 0.8343542837962574\n",
      "Epoch 00409: reducing learning rate of group 0 to 2.0276e-04.\n",
      "Epoch 00420: reducing learning rate of group 0 to 1.8248e-04.\n",
      "Epoch 10, train loss: 0.4376567602157593, train acc: 0.8343542837962574\n",
      "Epoch 00431: reducing learning rate of group 0 to 1.6423e-04.\n",
      "Epoch 00442: reducing learning rate of group 0 to 1.4781e-04.\n",
      "Epoch 20, train loss: 0.43693357706069946, train acc: 0.8707099102123017\n",
      "Epoch 00453: reducing learning rate of group 0 to 1.3303e-04.\n",
      "Epoch 30, train loss: 0.43633779883384705, train acc: 0.8707099102123017\n",
      "Epoch 00464: reducing learning rate of group 0 to 1.1973e-04.\n",
      "Epoch 00475: reducing learning rate of group 0 to 1.0775e-04.\n",
      "Epoch 40, train loss: 0.435852587223053, train acc: 0.8707099102123017\n",
      "Epoch 00486: reducing learning rate of group 0 to 9.6977e-05.\n",
      "Epoch 00497: reducing learning rate of group 0 to 8.7280e-05.\n",
      "Epoch 50, train loss: 0.43545764684677124, train acc: 0.8707099102123017\n",
      "Epoch 00508: reducing learning rate of group 0 to 7.8552e-05.\n",
      "Epoch 00519: reducing learning rate of group 0 to 7.0697e-05.\n",
      "Epoch 60, train loss: 0.43513327836990356, train acc: 0.8707099102123017\n",
      "Epoch 00530: reducing learning rate of group 0 to 6.3627e-05.\n",
      "Epoch 00541: reducing learning rate of group 0 to 5.7264e-05.\n",
      "Epoch 70, train loss: 0.4348715543746948, train acc: 0.8707099102123017\n",
      "Epoch 00552: reducing learning rate of group 0 to 5.1538e-05.\n",
      "Epoch 80, train loss: 0.434653639793396, train acc: 0.8707099102123017\n",
      "Epoch 00563: reducing learning rate of group 0 to 4.6384e-05.\n",
      "Epoch 00574: reducing learning rate of group 0 to 4.1746e-05.\n",
      "Epoch 90, train loss: 0.4344746768474579, train acc: 0.8707099102123017\n",
      "Epoch 00585: reducing learning rate of group 0 to 3.7571e-05.\n",
      "Epoch 00596: reducing learning rate of group 0 to 3.3814e-05.\n",
      "Model saved successfully at: c:\\Users\\kacpe\\Desktop\\lab_rotation_git\\data\\models\\model_s_090524\\s_30_val1.pth\n",
      "Accuracy for each output state:\n",
      "0.8707099102123017\n",
      "Value 's_30_val1: 0.8707099102123017' saved to 'c:\\Users\\kacpe\\Desktop\\lab_rotation_git\\data\\results/s_results_train_090524.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9427480916030534\n",
      "Value 's_30_val1: 0.9427480916030534' saved to 'c:\\Users\\kacpe\\Desktop\\lab_rotation_git\\data\\results/s_results_test_090524.txt' successfully.\n",
      "Epoch 0, train loss: 0.46116721630096436, train acc: 0.8490416702318816\n",
      "Epoch 00607: reducing learning rate of group 0 to 3.0433e-05.\n",
      "Epoch 00618: reducing learning rate of group 0 to 2.7389e-05.\n",
      "Epoch 10, train loss: 0.4610179364681244, train acc: 0.8490416702318816\n",
      "Epoch 00629: reducing learning rate of group 0 to 2.4650e-05.\n",
      "Epoch 00640: reducing learning rate of group 0 to 2.2185e-05.\n",
      "Epoch 20, train loss: 0.4608863294124603, train acc: 0.8490416702318816\n",
      "Epoch 00651: reducing learning rate of group 0 to 1.9967e-05.\n",
      "Epoch 00662: reducing learning rate of group 0 to 1.7970e-05.\n",
      "Epoch 30, train loss: 0.4607762396335602, train acc: 0.8490416702318816\n",
      "Epoch 00673: reducing learning rate of group 0 to 1.6173e-05.\n",
      "Epoch 40, train loss: 0.4606870710849762, train acc: 0.8490416702318816\n",
      "Epoch 00684: reducing learning rate of group 0 to 1.4556e-05.\n",
      "Epoch 00695: reducing learning rate of group 0 to 1.3100e-05.\n",
      "Epoch 50, train loss: 0.4606136679649353, train acc: 0.8490416702318816\n",
      "Epoch 00706: reducing learning rate of group 0 to 1.1790e-05.\n",
      "Epoch 00717: reducing learning rate of group 0 to 1.0611e-05.\n",
      "Epoch 60, train loss: 0.46055418252944946, train acc: 0.8490416702318816\n",
      "Epoch 00728: reducing learning rate of group 0 to 9.5500e-06.\n",
      "Epoch 00739: reducing learning rate of group 0 to 8.5950e-06.\n",
      "Epoch 70, train loss: 0.46050408482551575, train acc: 0.8490416702318816\n",
      "Epoch 00750: reducing learning rate of group 0 to 7.7355e-06.\n",
      "Epoch 00761: reducing learning rate of group 0 to 6.9620e-06.\n",
      "Epoch 80, train loss: 0.4604645371437073, train acc: 0.8490416702318816\n",
      "Epoch 00772: reducing learning rate of group 0 to 6.2658e-06.\n",
      "Epoch 90, train loss: 0.46043142676353455, train acc: 0.8490416702318816\n",
      "Epoch 00783: reducing learning rate of group 0 to 5.6392e-06.\n",
      "Epoch 00794: reducing learning rate of group 0 to 5.0753e-06.\n",
      "Model saved successfully at: c:\\Users\\kacpe\\Desktop\\lab_rotation_git\\data\\models\\model_s_090524\\s_40_val1.pth\n",
      "Accuracy for each output state:\n",
      "0.8490416702318816\n",
      "Value 's_40_val1: 0.8490416702318816' saved to 'c:\\Users\\kacpe\\Desktop\\lab_rotation_git\\data\\results/s_results_train_090524.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9173553719008265\n",
      "Value 's_40_val1: 0.9173553719008265' saved to 'c:\\Users\\kacpe\\Desktop\\lab_rotation_git\\data\\results/s_results_test_090524.txt' successfully.\n",
      "Epoch 0, train loss: 0.48693642020225525, train acc: 0.8283800296761805\n",
      "Epoch 00805: reducing learning rate of group 0 to 4.5678e-06.\n",
      "Epoch 00816: reducing learning rate of group 0 to 4.1110e-06.\n",
      "Epoch 10, train loss: 0.48690688610076904, train acc: 0.8283800296761805\n",
      "Epoch 00827: reducing learning rate of group 0 to 3.6999e-06.\n",
      "Epoch 00838: reducing learning rate of group 0 to 3.3299e-06.\n",
      "Epoch 20, train loss: 0.4868813455104828, train acc: 0.8283800296761805\n",
      "Epoch 00849: reducing learning rate of group 0 to 2.9969e-06.\n",
      "Epoch 00860: reducing learning rate of group 0 to 2.6972e-06.\n",
      "Epoch 30, train loss: 0.486859530210495, train acc: 0.8283800296761805\n",
      "Epoch 00871: reducing learning rate of group 0 to 2.4275e-06.\n",
      "Epoch 00882: reducing learning rate of group 0 to 2.1847e-06.\n",
      "Epoch 40, train loss: 0.48684147000312805, train acc: 0.8283800296761805\n",
      "Epoch 00893: reducing learning rate of group 0 to 1.9663e-06.\n",
      "Epoch 50, train loss: 0.4868275225162506, train acc: 0.8283800296761805\n",
      "Epoch 00904: reducing learning rate of group 0 to 1.7696e-06.\n",
      "Epoch 00915: reducing learning rate of group 0 to 1.5927e-06.\n",
      "Epoch 60, train loss: 0.48681581020355225, train acc: 0.8283800296761805\n",
      "Epoch 00926: reducing learning rate of group 0 to 1.4334e-06.\n",
      "Epoch 00937: reducing learning rate of group 0 to 1.2901e-06.\n",
      "Epoch 70, train loss: 0.4868055284023285, train acc: 0.8283800296761805\n",
      "Epoch 00948: reducing learning rate of group 0 to 1.1611e-06.\n",
      "Epoch 00959: reducing learning rate of group 0 to 1.0450e-06.\n",
      "Epoch 80, train loss: 0.48679983615875244, train acc: 0.8283800296761805\n",
      "Epoch 00970: reducing learning rate of group 0 to 9.4046e-07.\n",
      "Epoch 00981: reducing learning rate of group 0 to 8.4641e-07.\n",
      "Epoch 90, train loss: 0.4867931008338928, train acc: 0.8283800296761805\n",
      "Epoch 00992: reducing learning rate of group 0 to 7.6177e-07.\n",
      "Model saved successfully at: c:\\Users\\kacpe\\Desktop\\lab_rotation_git\\data\\models\\model_s_090524\\s_50_val1.pth\n",
      "Accuracy for each output state:\n",
      "0.8283800296761805\n",
      "Value 's_50_val1: 0.8283800296761805' saved to 'c:\\Users\\kacpe\\Desktop\\lab_rotation_git\\data\\results/s_results_train_090524.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8896396396396397\n",
      "Value 's_50_val1: 0.8896396396396397' saved to 'c:\\Users\\kacpe\\Desktop\\lab_rotation_git\\data\\results/s_results_test_090524.txt' successfully.\n",
      "Epoch 0, train loss: 0.5132816433906555, train acc: 0.8075175915204418\n",
      "Epoch 01003: reducing learning rate of group 0 to 6.8560e-07.\n",
      "Epoch 01014: reducing learning rate of group 0 to 6.1704e-07.\n",
      "Epoch 10, train loss: 0.5132760405540466, train acc: 0.8075175915204418\n",
      "Epoch 01025: reducing learning rate of group 0 to 5.5533e-07.\n",
      "Epoch 01036: reducing learning rate of group 0 to 4.9980e-07.\n",
      "Epoch 20, train loss: 0.5132704377174377, train acc: 0.8075175915204418\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 71\u001b[0m\n\u001b[0;32m     67\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39mX_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     68\u001b[0m test_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(test_dataset, batch_size\u001b[38;5;241m=\u001b[39mX_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 71\u001b[0m train_losses, train_accs, val_losses, val_accs, train_predicted_labels, train_probs_final \u001b[38;5;241m=\u001b[39m \u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mstate_dict()\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# Specify the folder path and the model filename\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[14], line 8\u001b[0m, in \u001b[0;36mrun_training\u001b[1;34m(train_dataloader, val_dataloader, model, optimizer, loss_fn, num_epochs, scheduler, device, schedule_on_train, verbose)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#train_hidden_states, val_hidden_states = [], []\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m----> 8\u001b[0m     epoch_train_loss, epoch_train_acc, train_preds, train_probs \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(epoch_train_loss)\n\u001b[0;32m     11\u001b[0m     train_accs\u001b[38;5;241m.\u001b[39mappend(epoch_train_acc)\n",
      "Cell \u001b[1;32mIn[12], line 28\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(dataloader, model, optimizer, loss_fn, scheduler, device)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer_state \u001b[38;5;129;01min\u001b[39;00m last_hidden_states:\n\u001b[0;32m     27\u001b[0m     hidden_states_batch\u001b[38;5;241m.\u001b[39mappend(layer_state\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m---> 28\u001b[0m epoch_correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     29\u001b[0m epoch_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mnumel()\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Append the batch's hidden states to the overall hidden_states list\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kacpe\\anaconda3\\lib\\site-packages\\torch\\_tensor.py:729\u001b[0m, in \u001b[0;36mTensor.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_tracing_state():\n\u001b[0;32m    725\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIterating over a tensor might cause the trace to be incorrect. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    726\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPassing a tensor of different shape won\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt change the number of \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    727\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124miterations executed (and might lead to errors or silently give \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    728\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mincorrect results).\u001b[39m\u001b[38;5;124m'\u001b[39m, category\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mTracerWarning, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m--> 729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munbind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for j in np.arange(1,25):\n",
    "    for i in np.arange(10,101,step=10):\n",
    "        shift = i\n",
    "        set_values = j\n",
    "        model_name = 's_'+str(shift)+'_'+'val'+str(set_values)\n",
    "\n",
    "\n",
    "        # Create an empty DataFrame to store the shifted data\n",
    "        shifted_df = pd.DataFrame()\n",
    "\n",
    "        # Loop through unique trial values\n",
    "        for trial_value in scaled_df['trial'].unique():\n",
    "            # Filter the DataFrame for the current trial\n",
    "            trial_df = scaled_df[scaled_df['trial'] == trial_value].copy()\n",
    "\n",
    "            # Create shifted columns for each column in columns_to_shift\n",
    "            for col in columns_to_shift:\n",
    "                new_col_name = col + '_minus_' + str(shift)\n",
    "                trial_df[new_col_name] = trial_df[col].shift(shift)\n",
    "\n",
    "            # Drop the last 'i' records for each trial\n",
    "            trial_df = trial_df.dropna()\n",
    "\n",
    "            # Append the modified trial_df to the shifted_df\n",
    "            shifted_df = shifted_df.append(trial_df, ignore_index=True)\n",
    "        \n",
    "        #selected_columns = ['id', 'trial','s_1_minus_'+str(shift),'s_2_minus_'+str(shift),'s_3_minus_'+str(shift),'s_4_minus_'+str(shift),'s_1','s_2','s_3','s_4']\n",
    "        selected_columns = ['trial', 's_1_minus_'+str(shift),\n",
    "        's_2_minus_'+str(shift), 's_3_minus_'+str(shift), 's_4_minus_'+str(shift),'s_1','s_2','s_3','s_4']\n",
    "        shifted_df = shifted_df[selected_columns]\n",
    "        \n",
    "        trial_groups = shifted_df.groupby('trial')\n",
    "        \n",
    "        # Get a list of trial group names (trial IDs)\n",
    "        trial_ids = list(trial_groups.groups.keys())\n",
    "        \n",
    "        # Shuffle the trial IDs randomly \n",
    "        random.shuffle(trial_ids)\n",
    "        # Create an empty list to store shuffled trial DataFrames\n",
    "        shuffled_trial_dfs = []\n",
    "        \n",
    "        # Iterate through the shuffled trial IDs and add the corresponding trial DataFrames to the list\n",
    "        for trial_id in trial_ids:\n",
    "            shuffled_trial_dfs.append(trial_groups.get_group(trial_id))\n",
    "            \n",
    "        # Step 5: Split the data into training and test sets based on the 'trial' column\n",
    "        train_set = shifted_df[shifted_df['trial']!=set_values].drop(columns=['trial'])\n",
    "        test_set = shifted_df[shifted_df['trial']==set_values].drop(columns=['trial'])\n",
    "        full_set = shifted_df.drop(columns=['trial'])\n",
    "\n",
    "        # split data into x and y \n",
    "        X_train, y_train = train_set.drop(columns=labels), train_set[labels]\n",
    "        X_test, y_test = test_set.drop(columns=labels), test_set[labels]\n",
    "        X, y = full_set.drop(columns=labels), full_set[labels]\n",
    "        \n",
    "        # reset index \n",
    "        X_train, y_train = X_train.reset_index(drop=True), y_train.reset_index(drop=True)\n",
    "        X_test, y_test = X_test.reset_index(drop=True), y_test.reset_index(drop=True)\n",
    "        X, y = X.reset_index(drop=True), y.reset_index(drop=True) \n",
    "\n",
    "        # Create custom datasets for training, validation, and testing\n",
    "        full_dataset = MyDataset(torch.tensor(X.values), torch.tensor(y.values))\n",
    "        train_dataset = MyDataset(torch.tensor(X_train.values), torch.tensor(y_train.values))\n",
    "        test_dataset = MyDataset(torch.tensor(X_test.values), torch.tensor(y_test.values))\n",
    "\n",
    "        fullset_dataloader = DataLoader(full_dataset, batch_size=X.shape[0], shuffle=False)\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=X_train.shape[0], shuffle=False)\n",
    "        test_dataloader = DataLoader(test_dataset, batch_size=X_test.shape[0], shuffle=False)\n",
    "\n",
    "\n",
    "        train_losses, train_accs, val_losses, val_accs, train_predicted_labels, train_probs_final = run_training(\n",
    "            train_dataloader, val_dataloader=None, model=model, optimizer=optimizer, loss_fn=loss_fn, num_epochs=n_epochs, scheduler=scheduler)\n",
    "\n",
    "\n",
    "        state_dict = model.state_dict()\n",
    "\n",
    "        # Specify the folder path and the model filename\n",
    "        folder_path = os.path.join(current_dir, 'models')\n",
    "        dir_name = \"model_s_\" + current_datetime\n",
    "        folder_path = os.path.join(folder_path, dir_name)\n",
    "\n",
    "        try:\n",
    "            # Check if the directory exists, if not, create it\n",
    "            if not os.path.exists(folder_path):\n",
    "                os.makedirs(folder_path)\n",
    "\n",
    "            # Combine the folder path and model filename\n",
    "            model_filename = model_name + '.pth'\n",
    "            full_model = os.path.join(folder_path, model_filename)\n",
    "\n",
    "            # Save the model to the specified folder\n",
    "            torch.save(state_dict, full_model)\n",
    "            print(\"Model saved successfully at:\", full_model)\n",
    "        except Exception as e:\n",
    "            print(\"An error occurred:\", e)\n",
    "\n",
    "\n",
    "\n",
    "        accs = evaluate_model(model, train_dataloader, y_train, current_datetime)\n",
    "        \n",
    "        # Define the directory where you want to save the file relative to current_dir\n",
    "        relative_dir = \"results/\"\n",
    "\n",
    "        # Create the full directory path by joining current_dir and relative_dir\n",
    "        full_dir_path = os.path.join(current_dir, relative_dir)\n",
    "\n",
    "        # Ensure that the directory exists, if not, create it\n",
    "        if not os.path.exists(full_dir_path):\n",
    "            os.makedirs(full_dir_path)\n",
    "\n",
    "        # Define the file name\n",
    "        file_name = 's_results_train_' + current_datetime + '.txt'\n",
    "\n",
    "        # Create the full file path by joining the directory path and the file name\n",
    "        file_path = os.path.join(full_dir_path, file_name)\n",
    "\n",
    "        # Define the value you want to save\n",
    "        value_to_save = model_name + \": \" + str(accs)\n",
    "\n",
    "        try:\n",
    "            # Open the file in append mode (create if it doesn't exist)\n",
    "            with open(file_path, \"a+\") as file:\n",
    "                # Move the file cursor to the beginning to check if the file is empty\n",
    "                file.seek(0)\n",
    "                # Read the first character of the file\n",
    "                first_char = file.read(1)\n",
    "                # If the first character is empty (file is empty), write a new line\n",
    "                if not first_char:\n",
    "                    file.write('\\n')\n",
    "                # Write the value to the file\n",
    "                file.write(value_to_save + '\\n')\n",
    "                print(f\"Value '{value_to_save}' saved to '{file_path}' successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            \n",
    "        accs = evaluate_model(model, test_dataloader, y_test, current_datetime)\n",
    "\n",
    "        # Define the directory where you want to save the file relative to current_dir\n",
    "        relative_dir = \"results/\"\n",
    "\n",
    "        # Create the full directory path by joining current_dir and relative_dir\n",
    "        full_dir_path = os.path.join(current_dir, relative_dir)\n",
    "\n",
    "        # Ensure that the directory exists, if not, create it\n",
    "        if not os.path.exists(full_dir_path):\n",
    "            os.makedirs(full_dir_path)\n",
    "\n",
    "        # Define the file name\n",
    "        file_name = 's_results_test_' + current_datetime + '.txt'\n",
    "\n",
    "        # Create the full file path by joining the directory path and the file name\n",
    "        file_path = os.path.join(full_dir_path, file_name)\n",
    "\n",
    "        # Define the value you want to save\n",
    "        value_to_save = model_name + \": \" + str(accs)\n",
    "\n",
    "        try:\n",
    "            # Open the file in append mode (create if it doesn't exist)\n",
    "            with open(file_path, \"a+\") as file:\n",
    "                # Move the file cursor to the beginning to check if the file is empty\n",
    "                file.seek(0)\n",
    "                # Read the first character of the file\n",
    "                first_char = file.read(1)\n",
    "                # If the first character is empty (file is empty), write a new line\n",
    "                if not first_char:\n",
    "                    file.write('\\n')\n",
    "                # Write the value to the file\n",
    "                file.write(value_to_save + '\\n')\n",
    "                print(f\"Value '{value_to_save}' saved to '{file_path}' successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\kacpe\\\\Desktop\\\\lab_rotation_git'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['nose_x', 'nose_y', 'nose_z', 'headTop_x', 'headTop_y', 'headTop_z',\n",
       "       'neck_x', 'neck_y', 'neck_z', 'tailBase_x', 'tailBase_y', 'tailBase_z',\n",
       "       'lEar_x', 'lEar_y', 'lEar_z', 'lShoulder_x', 'lShoulder_y',\n",
       "       'lShoulder_z', 'lElbow_x', 'lElbow_y', 'lElbow_z', 'lWrist_x',\n",
       "       'lWrist_y', 'lWrist_z', 'lHip_x', 'lHip_y', 'lHip_z', 'rEar_x',\n",
       "       'rEar_y', 'rEar_z', 'rShoulder_x', 'rShoulder_y', 'rShoulder_z',\n",
       "       'rElbow_x', 'rElbow_y', 'rElbow_z', 'rWrist_x', 'rWrist_y', 'rWrist_z',\n",
       "       'rHip_x', 'rHip_y', 'rHip_z', 's_1', 's_2', 's_3', 's_4', 'b_1', 'b_2',\n",
       "       'b_3', 'b_4'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_drop = ['lKnee_x','lKnee_y','lKnee_z','lAnkle_x','lAnkle_y','lAnkle_z','rKnee_x','rKnee_y','rKnee_z','rAnkle_x','rAnkle_y','rAnkle_z']\n",
    "file = \"data_m_filtered_oldlabels.csv\"\n",
    "# Read the CSV file\n",
    "\n",
    "df = pd.read_csv(file)\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "labels = ['s_1','s_2','s_3','s_4']\n",
    "data_to_scale = df.drop(columns=['trial'])\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(data_to_scale)\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=data_to_scale.columns)\n",
    "scaled_df[['trial']] = df[['trial']]\n",
    "cols_to_omit = ['trial']\n",
    "columns_to_shift = scaled_df.drop(cols_to_omit, axis=1).columns\n",
    "columns_to_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_dim = 46\n",
    "hidden_dim = 34\n",
    "output_dim = 4\n",
    "num_layers = 1\n",
    "n_epochs =1\n",
    "lr = 0.01\n",
    "\n",
    "# Create an instance of GRUCellNet\n",
    "model = GRUCellNet(input_dim, hidden_dim, output_dim, num_layers)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "#class_weights = torch.tensor([1.8]).to(device)\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=None)  \n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.9, patience=10, verbose=True, threshold=0.01, threshold_mode='rel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train loss: 0.7162711024284363, train acc: 0.5266219600872586\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/kacpe/Desktop/study/research lab/lab_rotation_git/models\\\\s_m10_val1.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 100\u001b[0m\n\u001b[0;32m     97\u001b[0m full_model \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_path, model_filename)\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# Save the model to the specified folder\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m model\u001b[38;5;241m.\u001b[39meval()  \u001b[38;5;66;03m# Set the model to evaluation mode\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;66;03m# Initialize an empty list to store predictions\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kacpe\\anaconda3\\lib\\site-packages\\torch\\serialization.py:376\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"save(obj, f, pickle_module=pickle, pickle_protocol=DEFAULT_PROTOCOL, _use_new_zipfile_serialization=True)\u001b[39;00m\n\u001b[0;32m    341\u001b[0m \n\u001b[0;32m    342\u001b[0m \u001b[38;5;124;03mSaves an object to a disk file.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;124;03m    >>> torch.save(x, buffer)\u001b[39;00m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    374\u001b[0m _check_dill_version(pickle_module)\n\u001b[1;32m--> 376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m    378\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(opened_file) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n",
      "File \u001b[1;32mc:\\Users\\kacpe\\anaconda3\\lib\\site-packages\\torch\\serialization.py:230\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 230\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    232\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32mc:\\Users\\kacpe\\anaconda3\\lib\\site-packages\\torch\\serialization.py:211\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 211\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_open_file, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/kacpe/Desktop/study/research lab/lab_rotation_git/models\\\\s_m10_val1.pth'"
     ]
    }
   ],
   "source": [
    "for j in np.arange(1,25):\n",
    "    for i in np.arange(10,101,step=10):\n",
    "        shift = i\n",
    "        set_values = j\n",
    "        model_name = 's_m'+str(shift)+'_'+'val'+str(set_values)\n",
    "\n",
    "\n",
    "        # Create an empty DataFrame to store the shifted data\n",
    "        shifted_df = pd.DataFrame()\n",
    "\n",
    "        # Loop through unique trial values\n",
    "        for trial_value in scaled_df['trial'].unique():\n",
    "            # Filter the DataFrame for the current trial\n",
    "            trial_df = scaled_df[scaled_df['trial'] == trial_value].copy()\n",
    "\n",
    "            # Create shifted columns for each column in columns_to_shift\n",
    "            for col in columns_to_shift:\n",
    "                new_col_name = col + '_minus_' + str(shift)\n",
    "                trial_df[new_col_name] = trial_df[col].shift(shift)\n",
    "\n",
    "            # Drop the last 'i' records for each trial\n",
    "            trial_df = trial_df.dropna()\n",
    "\n",
    "            # Append the modified trial_df to the shifted_df\n",
    "            shifted_df = shifted_df.append(trial_df, ignore_index=True)\n",
    "        \n",
    "        #selected_columns = ['id', 'trial','s_1_minus_'+str(shift),'s_2_minus_'+str(shift),'s_3_minus_'+str(shift),'s_4_minus_'+str(shift),'s_1','s_2','s_3','s_4']\n",
    "        selected_columns = ['trial','nose_x_minus_'+str(shift), 'nose_y_minus_'+str(shift),\n",
    "        'nose_z_minus_'+str(shift), 'headTop_x_minus_'+str(shift), 'headTop_y_minus_'+str(shift),\n",
    "        'headTop_z_minus_'+str(shift), 'neck_x_minus_'+str(shift), 'neck_y_minus_'+str(shift),\n",
    "        'neck_z_minus_'+str(shift), 'tailBase_x_minus_'+str(shift), 'tailBase_y_minus_'+str(shift),\n",
    "        'tailBase_z_minus_'+str(shift), 'lEar_x_minus_'+str(shift), 'lEar_y_minus_'+str(shift),\n",
    "        'lEar_z_minus_'+str(shift), 'lShoulder_x_minus_'+str(shift), 'lShoulder_y_minus_'+str(shift),\n",
    "        'lShoulder_z_minus_'+str(shift), 'lElbow_x_minus_'+str(shift), 'lElbow_y_minus_'+str(shift),\n",
    "        'lElbow_z_minus_'+str(shift), 'lWrist_x_minus_'+str(shift), 'lWrist_y_minus_'+str(shift),\n",
    "        'lWrist_z_minus_'+str(shift), 'lHip_x_minus_'+str(shift), 'lHip_y_minus_'+str(shift),\n",
    "        'lHip_z_minus_'+str(shift), 'rEar_x_minus_'+str(shift), 'rEar_y_minus_'+str(shift), 'rEar_z_minus_'+str(shift),\n",
    "        'rShoulder_x_minus_'+str(shift), 'rShoulder_y_minus_'+str(shift), 'rShoulder_z_minus_'+str(shift),\n",
    "        'rElbow_x_minus_'+str(shift), 'rElbow_y_minus_'+str(shift), 'rElbow_z_minus_'+str(shift),\n",
    "        'rWrist_x_minus_'+str(shift), 'rWrist_y_minus_'+str(shift), 'rWrist_z_minus_'+str(shift),\n",
    "        'rHip_x_minus_'+str(shift), 'rHip_y_minus_'+str(shift), 'rHip_z_minus_'+str(shift), 's_1_minus_'+str(shift),\n",
    "        's_2_minus_'+str(shift), 's_3_minus_'+str(shift), 's_4_minus_'+str(shift),'s_1','s_2','s_3','s_4']\n",
    "        shifted_df = shifted_df[selected_columns]\n",
    "        \n",
    "        trial_groups = shifted_df.groupby('trial')\n",
    "        \n",
    "        # Get a list of trial group names (trial IDs)\n",
    "        trial_ids = list(trial_groups.groups.keys())\n",
    "        \n",
    "        # Shuffle the trial IDs randomly \n",
    "        random.shuffle(trial_ids)\n",
    "        # Create an empty list to store shuffled trial DataFrames\n",
    "        shuffled_trial_dfs = []\n",
    "        \n",
    "        # Iterate through the shuffled trial IDs and add the corresponding trial DataFrames to the list\n",
    "        for trial_id in trial_ids:\n",
    "            shuffled_trial_dfs.append(trial_groups.get_group(trial_id))\n",
    "            \n",
    "        # Step 5: Split the data into training and test sets based on the 'trial' column\n",
    "        train_set = shifted_df[shifted_df['trial']!=set_values].drop(columns=['trial'])\n",
    "        test_set = shifted_df[shifted_df['trial']==set_values].drop(columns=['trial'])\n",
    "        full_set = shifted_df.drop(columns=['trial'])\n",
    "\n",
    "        # split data into x and y \n",
    "        X_train, y_train = train_set.drop(columns=labels), train_set[labels]\n",
    "        X_test, y_test = test_set.drop(columns=labels), test_set[labels]\n",
    "        X, y = full_set.drop(columns=labels), full_set[labels]\n",
    "        \n",
    "        # reset index \n",
    "        X_train, y_train = X_train.reset_index(drop=True), y_train.reset_index(drop=True)\n",
    "        X_test, y_test = X_test.reset_index(drop=True), y_test.reset_index(drop=True)\n",
    "        X, y = X.reset_index(drop=True), y.reset_index(drop=True) \n",
    "\n",
    "        # Create custom datasets for training, validation, and testing\n",
    "        full_dataset = MyDataset(torch.tensor(X.values), torch.tensor(y.values))\n",
    "        train_dataset = MyDataset(torch.tensor(X_train.values), torch.tensor(y_train.values))\n",
    "        test_dataset = MyDataset(torch.tensor(X_test.values), torch.tensor(y_test.values))\n",
    "\n",
    "        fullset_dataloader = DataLoader(full_dataset, batch_size=X.shape[0], shuffle=False)\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=X_train.shape[0], shuffle=False)\n",
    "        test_dataloader = DataLoader(test_dataset, batch_size=X_test.shape[0], shuffle=False)\n",
    "\n",
    "\n",
    "        train_losses, train_accs, val_losses, val_accs, train_predicted_labels, train_probs_final = run_training(\n",
    "            train_dataloader, val_dataloader=None, model=model, optimizer=optimizer, loss_fn=loss_fn, num_epochs=n_epochs, scheduler=scheduler)\n",
    "\n",
    "\n",
    "        state_dict = model.state_dict()\n",
    "\n",
    "        # Specify the folder path and the model filename\n",
    "        folder_path = os.path.join(current_dir, 'models')\n",
    "        dir_name = \"model_sm_\" + current_datetime\n",
    "        folder_path = os.path.join(folder_path, dir_name)\n",
    "\n",
    "        try:\n",
    "            # Check if the directory exists, if not, create it\n",
    "            if not os.path.exists(folder_path):\n",
    "                os.makedirs(folder_path)\n",
    "\n",
    "            # Combine the folder path and model filename\n",
    "            model_filename = model_name + '.pth'\n",
    "            full_model = os.path.join(folder_path, model_filename)\n",
    "\n",
    "            # Save the model to the specified folder\n",
    "            torch.save(state_dict, full_model)\n",
    "            print(\"Model saved successfully at:\", full_model)\n",
    "        except Exception as e:\n",
    "            print(\"An error occurred:\", e)\n",
    "\n",
    "\n",
    "\n",
    "        accs = evaluate_model(model, train_dataloader, y_train, current_datetime)\n",
    "        \n",
    "        # Define the directory where you want to save the file relative to current_dir\n",
    "        relative_dir = \"results/\"\n",
    "\n",
    "        # Create the full directory path by joining current_dir and relative_dir\n",
    "        full_dir_path = os.path.join(current_dir, relative_dir)\n",
    "\n",
    "        # Ensure that the directory exists, if not, create it\n",
    "        if not os.path.exists(full_dir_path):\n",
    "            os.makedirs(full_dir_path)\n",
    "\n",
    "        # Define the file name\n",
    "        file_name = 'sm_results_train_' + current_datetime + '.txt'\n",
    "\n",
    "        # Create the full file path by joining the directory path and the file name\n",
    "        file_path = os.path.join(full_dir_path, file_name)\n",
    "\n",
    "        # Define the value you want to save\n",
    "        value_to_save = model_name + \": \" + str(accs)\n",
    "\n",
    "        try:\n",
    "            # Open the file in append mode (create if it doesn't exist)\n",
    "            with open(file_path, \"a+\") as file:\n",
    "                # Move the file cursor to the beginning to check if the file is empty\n",
    "                file.seek(0)\n",
    "                # Read the first character of the file\n",
    "                first_char = file.read(1)\n",
    "                # If the first character is empty (file is empty), write a new line\n",
    "                if not first_char:\n",
    "                    file.write('\\n')\n",
    "                # Write the value to the file\n",
    "                file.write(value_to_save + '\\n')\n",
    "                print(f\"Value '{value_to_save}' saved to '{file_path}' successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            \n",
    "        accs = evaluate_model(model, test_dataloader, y_test, current_datetime)\n",
    "\n",
    "        # Define the directory where you want to save the file relative to current_dir\n",
    "        relative_dir = \"results/\"\n",
    "\n",
    "        # Create the full directory path by joining current_dir and relative_dir\n",
    "        full_dir_path = os.path.join(current_dir, relative_dir)\n",
    "\n",
    "        # Ensure that the directory exists, if not, create it\n",
    "        if not os.path.exists(full_dir_path):\n",
    "            os.makedirs(full_dir_path)\n",
    "\n",
    "        # Define the file name\n",
    "        file_name = 'sm_results_test_' + current_datetime + '.txt'\n",
    "\n",
    "        # Create the full file path by joining the directory path and the file name\n",
    "        file_path = os.path.join(full_dir_path, file_name)\n",
    "\n",
    "        # Define the value you want to save\n",
    "        value_to_save = model_name + \": \" + str(accs)\n",
    "\n",
    "        try:\n",
    "            # Open the file in append mode (create if it doesn't exist)\n",
    "            with open(file_path, \"a+\") as file:\n",
    "                # Move the file cursor to the beginning to check if the file is empty\n",
    "                file.seek(0)\n",
    "                # Read the first character of the file\n",
    "                first_char = file.read(1)\n",
    "                # If the first character is empty (file is empty), write a new line\n",
    "                if not first_char:\n",
    "                    file.write('\\n')\n",
    "                # Write the value to the file\n",
    "                file.write(value_to_save + '\\n')\n",
    "                print(f\"Value '{value_to_save}' saved to '{file_path}' successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['H_headFront_x', 'H_headFront_y', 'H_headFront_z', 'H_neck_x',\n",
       "       'H_neck_y', 'H_neck_z', 'H_lowerBack_x', 'H_lowerBack_y',\n",
       "       'H_lowerBack_z', 'H_leftWrist_x', 'H_leftWrist_y', 'H_leftWrist_z',\n",
       "       'H_leftShoulder_x', 'H_leftShoulder_y', 'H_leftShoulder_z',\n",
       "       'H_leftElbow_x', 'H_leftElbow_y', 'H_leftElbow_z', 'nose_x', 'nose_y',\n",
       "       'nose_z', 'headTop_x', 'headTop_y', 'headTop_z', 'neck_x', 'neck_y',\n",
       "       'neck_z', 'tailBase_x', 'tailBase_y', 'tailBase_z', 'lEar_x', 'lEar_y',\n",
       "       'lEar_z', 'lShoulder_x', 'lShoulder_y', 'lShoulder_z', 'lElbow_x',\n",
       "       'lElbow_y', 'lElbow_z', 'lWrist_x', 'lWrist_y', 'lWrist_z', 'lHip_x',\n",
       "       'lHip_y', 'lHip_z', 'rEar_x', 'rEar_y', 'rEar_z', 'rShoulder_x',\n",
       "       'rShoulder_y', 'rShoulder_z', 'rElbow_x', 'rElbow_y', 'rElbow_z',\n",
       "       'rWrist_x', 'rWrist_y', 'rWrist_z', 'rHip_x', 'rHip_y', 'rHip_z', 's_1',\n",
       "       's_2', 's_3', 's_4', 'b_1', 'b_2', 'b_3', 'b_4'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_drop = ['lKnee_x','lKnee_y','lKnee_z','lAnkle_x','lAnkle_y','lAnkle_z','rKnee_x','rKnee_y','rKnee_z','rAnkle_x','rAnkle_y','rAnkle_z']\n",
    "\n",
    "df_human = pd.read_csv(\"data_human_jarvis_oldlabels.csv\")\n",
    "df_human = df_human.drop(columns=['s_1','s_2','s_3','s_4'])\n",
    "data = \"data_m_filtered_oldlabels.csv\"\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(data)\n",
    "# List of column names to drop\n",
    "\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "# Concatenate the two dataframes vertically (along rows)\n",
    "df = pd.concat([df_human,df], axis=1)\n",
    "\n",
    "# Reset the index of the concatenated dataframe\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "labels = ['s_1','s_2','s_3','s_4']\n",
    "data_to_scale = df.drop(columns=['trial','H_trial'])\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(data_to_scale)\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=data_to_scale.columns)\n",
    "scaled_df[['trial']] = df[['trial']]\n",
    "scaled_df = scaled_df.dropna(axis=0)\n",
    "cols_to_omit = ['trial']\n",
    "# Use the drop method to exclude columns\n",
    "columns_to_shift = scaled_df.drop(cols_to_omit, axis=1).columns\n",
    "columns_to_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_dim = 64\n",
    "hidden_dim = 46\n",
    "output_dim = 4\n",
    "num_layers = 1\n",
    "n_epochs =100\n",
    "lr = 0.01\n",
    "\n",
    "# Create an instance of GRUCellNet\n",
    "model = GRUCellNet(input_dim, hidden_dim, output_dim, num_layers)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "#class_weights = torch.tensor([1.8]).to(device)\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=None)  \n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.9, patience=10, verbose=True, threshold=0.01, threshold_mode='rel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train loss: 0.10116040706634521, train acc: 0.9689100060748069\n",
      "Epoch 10, train loss: 0.09583305567502975, train acc: 0.9693222251149874\n",
      "Epoch 0, train loss: 0.09545652568340302, train acc: 0.9693005293760305\n",
      "Epoch 10, train loss: 0.09244198352098465, train acc: 0.9692788336370737\n",
      "Accuracy for each output state:\n",
      "0.969560878243513\n",
      "Value 's_m_h10_val1: 0.969560878243513' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9784768211920529\n",
      "Value 's_m_h10_val1: 0.9784768211920529' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.14073814451694489, train acc: 0.9413651243032823\n",
      "Epoch 00396: reducing learning rate of group 0 to 7.1790e-04.\n",
      "Epoch 00407: reducing learning rate of group 0 to 6.4611e-04.\n",
      "Epoch 10, train loss: 0.13224878907203674, train acc: 0.94231619923914\n",
      "Epoch 0, train loss: 0.1315433382987976, train acc: 0.9427364416526586\n",
      "Epoch 00418: reducing learning rate of group 0 to 5.8150e-04.\n",
      "Epoch 00429: reducing learning rate of group 0 to 5.2335e-04.\n",
      "Epoch 10, train loss: 0.12600824236869812, train acc: 0.9458993187649297\n",
      "Accuracy for each output state:\n",
      "0.9448597717420153\n",
      "Value 's_m_h20_val1: 0.9448597717420153' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9645390070921986\n",
      "Value 's_m_h20_val1: 0.9645390070921986' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.1647718846797943, train acc: 0.9187494360732653\n",
      "Epoch 00440: reducing learning rate of group 0 to 4.7101e-04.\n",
      "Epoch 00451: reducing learning rate of group 0 to 4.2391e-04.\n",
      "Epoch 10, train loss: 0.15390653908252716, train acc: 0.9257421275827844\n",
      "Epoch 0, train loss: 0.15310852229595184, train acc: 0.9264639538031219\n",
      "Epoch 00462: reducing learning rate of group 0 to 3.8152e-04.\n",
      "Epoch 00473: reducing learning rate of group 0 to 3.4337e-04.\n",
      "Epoch 10, train loss: 0.14730826020240784, train acc: 0.9314490661373275\n",
      "Accuracy for each output state:\n",
      "0.9275241360642426\n",
      "Value 's_m_h30_val1: 0.9275241360642426' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9637404580152672\n",
      "Value 's_m_h30_val1: 0.9637404580152672' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.18242044746875763, train acc: 0.9076452177114978\n",
      "Epoch 00484: reducing learning rate of group 0 to 3.0903e-04.\n",
      "Epoch 00495: reducing learning rate of group 0 to 2.7813e-04.\n",
      "Epoch 10, train loss: 0.17376498878002167, train acc: 0.9157461106508331\n",
      "Epoch 0, train loss: 0.17311203479766846, train acc: 0.9166666666666666\n",
      "Epoch 00506: reducing learning rate of group 0 to 2.5032e-04.\n",
      "Epoch 00517: reducing learning rate of group 0 to 2.2528e-04.\n",
      "Epoch 10, train loss: 0.167650505900383, train acc: 0.9203488907300009\n",
      "Accuracy for each output state:\n",
      "0.9213615023474178\n",
      "Value 's_m_h40_val1: 0.9213615023474178' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.981404958677686\n",
      "Value 's_m_h40_val1: 0.981404958677686' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.2059294879436493, train acc: 0.8970919853424786\n",
      "Epoch 00528: reducing learning rate of group 0 to 2.0276e-04.\n",
      "Epoch 00539: reducing learning rate of group 0 to 1.8248e-04.\n",
      "Epoch 10, train loss: 0.197424978017807, train acc: 0.9048435591468571\n",
      "Epoch 0, train loss: 0.1967070996761322, train acc: 0.9054777788217608\n",
      "Epoch 00550: reducing learning rate of group 0 to 1.6423e-04.\n",
      "Epoch 00561: reducing learning rate of group 0 to 1.4781e-04.\n",
      "Epoch 10, train loss: 0.1908404380083084, train acc: 0.9103401296626891\n",
      "Accuracy for each output state:\n",
      "0.9106924739265244\n",
      "Value 's_m_h50_val1: 0.9106924739265244' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "1.0\n",
      "Value 's_m_h50_val1: 1.0' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.22957149147987366, train acc: 0.8893792574114938\n",
      "Epoch 00572: reducing learning rate of group 0 to 1.3303e-04.\n",
      "Epoch 00583: reducing learning rate of group 0 to 1.1973e-04.\n",
      "Epoch 10, train loss: 0.22106653451919556, train acc: 0.8970306053919217\n",
      "Epoch 0, train loss: 0.2203119397163391, train acc: 0.8974863283123861\n",
      "Epoch 00594: reducing learning rate of group 0 to 1.0775e-04.\n",
      "Epoch 00605: reducing learning rate of group 0 to 9.6977e-05.\n",
      "Epoch 10, train loss: 0.21410736441612244, train acc: 0.902715149189293\n",
      "Accuracy for each output state:\n",
      "0.9038664491988871\n",
      "Value 's_m_h60_val1: 0.9038664491988871' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "1.0\n",
      "Value 's_m_h60_val1: 1.0' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.2615971863269806, train acc: 0.8793247084190924\n",
      "Epoch 00616: reducing learning rate of group 0 to 8.7280e-05.\n",
      "Epoch 00627: reducing learning rate of group 0 to 7.8552e-05.\n",
      "Epoch 10, train loss: 0.25347524881362915, train acc: 0.8834411447613447\n",
      "Epoch 0, train loss: 0.25274857878685, train acc: 0.883857688915025\n",
      "Epoch 00638: reducing learning rate of group 0 to 7.0697e-05.\n",
      "Epoch 00649: reducing learning rate of group 0 to 6.3627e-05.\n",
      "Epoch 10, train loss: 0.24668185412883759, train acc: 0.887484073311771\n",
      "Accuracy for each output state:\n",
      "0.8885621875918848\n",
      "Value 's_m_h70_val1: 0.8885621875918848' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "1.0\n",
      "Value 's_m_h70_val1: 1.0' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.30085501074790955, train acc: 0.863643193428829\n",
      "Epoch 00660: reducing learning rate of group 0 to 5.7264e-05.\n",
      "Epoch 00671: reducing learning rate of group 0 to 5.1538e-05.\n",
      "Epoch 10, train loss: 0.2934838831424713, train acc: 0.8675247921466493\n",
      "Epoch 0, train loss: 0.2928217649459839, train acc: 0.8680506861664831\n",
      "Epoch 00682: reducing learning rate of group 0 to 4.6384e-05.\n",
      "Epoch 00693: reducing learning rate of group 0 to 4.1746e-05.\n",
      "Epoch 10, train loss: 0.2872333228588104, train acc: 0.870980667134128\n",
      "Accuracy for each output state:\n",
      "0.8713312631473505\n",
      "Value 's_m_h80_val1: 0.8713312631473505' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "1.0\n",
      "Value 's_m_h80_val1: 1.0' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.34536272287368774, train acc: 0.8485352862849534\n",
      "Epoch 00704: reducing learning rate of group 0 to 3.7571e-05.\n",
      "Epoch 00715: reducing learning rate of group 0 to 3.3814e-05.\n",
      "Epoch 10, train loss: 0.3388008773326874, train acc: 0.8522738912219605\n",
      "Epoch 0, train loss: 0.3382106125354767, train acc: 0.8524787462870019\n",
      "Epoch 00726: reducing learning rate of group 0 to 3.0433e-05.\n",
      "Epoch 00737: reducing learning rate of group 0 to 2.7389e-05.\n",
      "Epoch 10, train loss: 0.33319512009620667, train acc: 0.8549882208337601\n",
      "Accuracy for each output state:\n",
      "0.8530933114821264\n",
      "Value 's_m_h90_val1: 0.8530933114821264' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "1.0\n",
      "Value 's_m_h90_val1: 1.0' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.3970266878604889, train acc: 0.8319972754898879\n",
      "Epoch 00748: reducing learning rate of group 0 to 2.4650e-05.\n",
      "Epoch 00759: reducing learning rate of group 0 to 2.2185e-05.\n",
      "Epoch 10, train loss: 0.39112386107444763, train acc: 0.833909672010898\n",
      "Epoch 0, train loss: 0.39059028029441833, train acc: 0.834040658073981\n",
      "Epoch 00770: reducing learning rate of group 0 to 1.9967e-05.\n",
      "Epoch 00781: reducing learning rate of group 0 to 1.7970e-05.\n",
      "Epoch 10, train loss: 0.3860252797603607, train acc: 0.8355338991931258\n",
      "Accuracy for each output state:\n",
      "0.8334905166090327\n",
      "Value 's_m_h100_val1: 0.8334905166090327' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "1.0\n",
      "Value 's_m_h100_val1: 1.0' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.2703225314617157, train acc: 0.887754635973326\n",
      "Epoch 00792: reducing learning rate of group 0 to 1.6173e-05.\n",
      "Epoch 00803: reducing learning rate of group 0 to 1.4556e-05.\n",
      "Epoch 10, train loss: 0.26400893926620483, train acc: 0.8895587832282817\n",
      "Epoch 0, train loss: 0.262989342212677, train acc: 0.8898556682196035\n",
      "Epoch 00814: reducing learning rate of group 0 to 1.3100e-05.\n",
      "Epoch 00825: reducing learning rate of group 0 to 1.1790e-05.\n",
      "Epoch 10, train loss: 0.2533581852912903, train acc: 0.8924362839134009\n",
      "Accuracy for each output state:\n",
      "0.8926874942906732\n",
      "Value 's_m_h10_val2: 0.8926874942906732' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9050894085281982\n",
      "Value 's_m_h10_val2: 0.9050894085281982' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.22651782631874084, train acc: 0.9045632516080917\n",
      "Epoch 00836: reducing learning rate of group 0 to 1.0611e-05.\n",
      "Epoch 00847: reducing learning rate of group 0 to 9.5500e-06.\n",
      "Epoch 10, train loss: 0.220522940158844, train acc: 0.9065442341754452\n",
      "Epoch 0, train loss: 0.22003725171089172, train acc: 0.9068239023026009\n",
      "Epoch 00858: reducing learning rate of group 0 to 8.5950e-06.\n",
      "Epoch 00869: reducing learning rate of group 0 to 7.7355e-06.\n",
      "Epoch 10, train loss: 0.21599669754505157, train acc: 0.9083853826792206\n",
      "Accuracy for each output state:\n",
      "0.9080124918430129\n",
      "Value 's_m_h20_val2: 0.9080124918430129' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9170153417015341\n",
      "Value 's_m_h20_val2: 0.9170153417015341' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.19582611322402954, train acc: 0.9197201865423051\n",
      "Epoch 00880: reducing learning rate of group 0 to 6.9620e-06.\n",
      "Epoch 00891: reducing learning rate of group 0 to 6.2658e-06.\n",
      "Epoch 10, train loss: 0.19363607466220856, train acc: 0.9204339963833634\n",
      "Epoch 0, train loss: 0.19345898926258087, train acc: 0.9205053773674693\n",
      "Epoch 00902: reducing learning rate of group 0 to 5.6392e-06.\n",
      "Epoch 00913: reducing learning rate of group 0 to 5.0753e-06.\n",
      "Epoch 10, train loss: 0.1919666975736618, train acc: 0.9211715998857904\n",
      "Accuracy for each output state:\n",
      "0.9209812505948416\n",
      "Value 's_m_h30_val2: 0.9209812505948416' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9317538896746818\n",
      "Value 's_m_h30_val2: 0.9317538896746818' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.1836666315793991, train acc: 0.9269952367065228\n",
      "Epoch 00924: reducing learning rate of group 0 to 4.5678e-06.\n",
      "Epoch 00935: reducing learning rate of group 0 to 4.1110e-06.\n",
      "Epoch 10, train loss: 0.18288931250572205, train acc: 0.9271653543307087\n",
      "Epoch 0, train loss: 0.18282568454742432, train acc: 0.9272139593661903\n",
      "Epoch 00946: reducing learning rate of group 0 to 3.6999e-06.\n",
      "Epoch 00957: reducing learning rate of group 0 to 3.3299e-06.\n",
      "Epoch 10, train loss: 0.18228310346603394, train acc: 0.9273840769903762\n",
      "Accuracy for each output state:\n",
      "0.9274569845435987\n",
      "Value 's_m_h40_val2: 0.9274569845435987' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9383070301291249\n",
      "Value 's_m_h40_val2: 0.9383070301291249' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.18832673132419586, train acc: 0.923611800933744\n",
      "Epoch 00968: reducing learning rate of group 0 to 2.9969e-06.\n",
      "Epoch 00979: reducing learning rate of group 0 to 2.6972e-06.\n",
      "Epoch 10, train loss: 0.18805155158042908, train acc: 0.9237608026224298\n",
      "Epoch 0, train loss: 0.18802867829799652, train acc: 0.9238104698519917\n",
      "Epoch 00990: reducing learning rate of group 0 to 2.4275e-06.\n",
      "Epoch 01001: reducing learning rate of group 0 to 2.1847e-06.\n",
      "Epoch 10, train loss: 0.1878315657377243, train acc: 0.9238353034667727\n",
      "Accuracy for each output state:\n",
      "0.9238849706963346\n",
      "Value 's_m_h50_val2: 0.9238849706963346' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9446870451237264\n",
      "Value 's_m_h50_val2: 0.9446870451237264' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.20385757088661194, train acc: 0.9150502691174978\n",
      "Epoch 01012: reducing learning rate of group 0 to 1.9663e-06.\n",
      "Epoch 01023: reducing learning rate of group 0 to 1.7696e-06.\n",
      "Epoch 10, train loss: 0.20375622808933258, train acc: 0.9151264344470397\n",
      "Epoch 0, train loss: 0.20374736189842224, train acc: 0.9151518228902203\n",
      "Epoch 01034: reducing learning rate of group 0 to 1.5927e-06.\n",
      "Epoch 01045: reducing learning rate of group 0 to 1.4334e-06.\n",
      "Epoch 10, train loss: 0.20366856455802917, train acc: 0.915177211333401\n",
      "Accuracy for each output state:\n",
      "0.9152025997765818\n",
      "Value 's_m_h60_val2: 0.9152025997765818' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9435007385524372\n",
      "Value 's_m_h60_val2: 0.9435007385524372' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.23665475845336914, train acc: 0.8982289394411551\n",
      "Epoch 01056: reducing learning rate of group 0 to 1.2901e-06.\n",
      "Epoch 01067: reducing learning rate of group 0 to 1.1611e-06.\n",
      "Epoch 10, train loss: 0.23660089075565338, train acc: 0.8982549080710501\n",
      "Epoch 0, train loss: 0.23659557104110718, train acc: 0.8982549080710501\n",
      "Epoch 01078: reducing learning rate of group 0 to 1.0450e-06.\n",
      "Epoch 01089: reducing learning rate of group 0 to 9.4046e-07.\n",
      "Epoch 10, train loss: 0.23654606938362122, train acc: 0.8983328139607354\n",
      "Accuracy for each output state:\n",
      "0.8984107198504206\n",
      "Value 's_m_h70_val2: 0.8984107198504206' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9329085457271364\n",
      "Value 's_m_h70_val2: 0.9329085457271364' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.2832109034061432, train acc: 0.8768736047624109\n",
      "Epoch 01100: reducing learning rate of group 0 to 8.4641e-07.\n",
      "Epoch 01111: reducing learning rate of group 0 to 7.6177e-07.\n",
      "Epoch 10, train loss: 0.28315359354019165, train acc: 0.876979908578718\n",
      "Epoch 0, train loss: 0.28314775228500366, train acc: 0.8770064845327947\n",
      "Epoch 01122: reducing learning rate of group 0 to 6.8560e-07.\n",
      "Epoch 01133: reducing learning rate of group 0 to 6.1704e-07.\n",
      "Epoch 10, train loss: 0.28309166431427, train acc: 0.8770330604868715\n",
      "Accuracy for each output state:\n",
      "0.8772456681194856\n",
      "Value 's_m_h80_val2: 0.8772456681194856' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9155251141552512\n",
      "Value 's_m_h80_val2: 0.9155251141552512' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.33972853422164917, train acc: 0.8541417219984762\n",
      "Epoch 01144: reducing learning rate of group 0 to 5.5533e-07.\n",
      "Epoch 01155: reducing learning rate of group 0 to 4.9980e-07.\n",
      "Epoch 10, train loss: 0.3396528363227844, train acc: 0.854168934363775\n",
      "Epoch 0, train loss: 0.3396451771259308, train acc: 0.854168934363775\n",
      "Epoch 01166: reducing learning rate of group 0 to 4.4982e-07.\n",
      "Epoch 01177: reducing learning rate of group 0 to 4.0484e-07.\n",
      "Epoch 10, train loss: 0.33957305550575256, train acc: 0.8541961467290737\n",
      "Accuracy for each output state:\n",
      "0.8543322085555677\n",
      "Value 's_m_h90_val2: 0.8543322085555677' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8945131375579599\n",
      "Value 's_m_h90_val2: 0.8945131375579599' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.40745291113853455, train acc: 0.8299877327980373\n",
      "Epoch 01188: reducing learning rate of group 0 to 3.6435e-07.\n",
      "Epoch 01199: reducing learning rate of group 0 to 3.2792e-07.\n",
      "Epoch 10, train loss: 0.4073585271835327, train acc: 0.8299877327980373\n",
      "Epoch 0, train loss: 0.40734922885894775, train acc: 0.8299877327980373\n",
      "Epoch 01210: reducing learning rate of group 0 to 2.9513e-07.\n",
      "Epoch 01221: reducing learning rate of group 0 to 2.6561e-07.\n",
      "Epoch 10, train loss: 0.40726298093795776, train acc: 0.8300434928069589\n",
      "Accuracy for each output state:\n",
      "0.830015612802498\n",
      "Value 's_m_h100_val2: 0.830015612802498' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8712715855572999\n",
      "Value 's_m_h100_val2: 0.8712715855572999' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.2284270077943802, train acc: 0.9001164561497805\n",
      "Epoch 01232: reducing learning rate of group 0 to 2.3905e-07.\n",
      "Epoch 01243: reducing learning rate of group 0 to 2.1515e-07.\n",
      "Epoch 10, train loss: 0.22841818630695343, train acc: 0.9001164561497805\n",
      "Epoch 0, train loss: 0.22841288149356842, train acc: 0.9001164561497805\n",
      "Epoch 01254: reducing learning rate of group 0 to 1.9363e-07.\n",
      "Epoch 01265: reducing learning rate of group 0 to 1.7427e-07.\n",
      "Epoch 10, train loss: 0.22834835946559906, train acc: 0.9001164561497805\n",
      "Accuracy for each output state:\n",
      "0.8997581295350712\n",
      "Value 's_m_h10_val3: 0.8997581295350712' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8928571428571428\n",
      "Value 's_m_h10_val3: 0.8928571428571428' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.2058904469013214, train acc: 0.9116330074019922\n",
      "Epoch 01276: reducing learning rate of group 0 to 1.5684e-07.\n",
      "Epoch 01287: reducing learning rate of group 0 to 1.4116e-07.\n",
      "Epoch 10, train loss: 0.20584160089492798, train acc: 0.9116330074019922\n",
      "Epoch 0, train loss: 0.20583727955818176, train acc: 0.9116558530567486\n",
      "Epoch 01298: reducing learning rate of group 0 to 1.2704e-07.\n",
      "Epoch 01309: reducing learning rate of group 0 to 1.1434e-07.\n",
      "Epoch 10, train loss: 0.20579856634140015, train acc: 0.9116558530567486\n",
      "Accuracy for each output state:\n",
      "0.9116786987115051\n",
      "Value 's_m_h20_val3: 0.9116786987115051' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9156686626746509\n",
      "Value 's_m_h20_val3: 0.9156686626746509' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.18757210671901703, train acc: 0.922572973981162\n",
      "Epoch 01320: reducing learning rate of group 0 to 1.0290e-07.\n",
      "Epoch 01331: reducing learning rate of group 0 to 9.2614e-08.\n",
      "Epoch 10, train loss: 0.18755006790161133, train acc: 0.9225962883521402\n",
      "Epoch 0, train loss: 0.1875482201576233, train acc: 0.9225962883521402\n",
      "Epoch 10, train loss: 0.18753018975257874, train acc: 0.9225962883521402\n",
      "Accuracy for each output state:\n",
      "0.922572973981162\n",
      "Value 's_m_h30_val3: 0.922572973981162' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9358452138492872\n",
      "Value 's_m_h30_val3: 0.9358452138492872' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.17987945675849915, train acc: 0.9283538036751404\n",
      "Epoch 10, train loss: 0.17986774444580078, train acc: 0.9283776063981719\n",
      "Epoch 0, train loss: 0.17986662685871124, train acc: 0.9283776063981719\n",
      "Epoch 10, train loss: 0.17985597252845764, train acc: 0.9283776063981719\n",
      "Accuracy for each output state:\n",
      "0.928282395506046\n",
      "Value 's_m_h40_val3: 0.928282395506046' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9449064449064449\n",
      "Value 's_m_h40_val3: 0.9449064449064449' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.1853470355272293, train acc: 0.9238792181270057\n",
      "Epoch 10, train loss: 0.18534010648727417, train acc: 0.9238792181270057\n",
      "Epoch 0, train loss: 0.18533943593502045, train acc: 0.9238792181270057\n",
      "Epoch 10, train loss: 0.1853330433368683, train acc: 0.9238792181270057\n",
      "Accuracy for each output state:\n",
      "0.9238549061557912\n",
      "Value 's_m_h50_val3: 0.9238549061557912' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.947452229299363\n",
      "Value 's_m_h50_val3: 0.947452229299363' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.19977964460849762, train acc: 0.9149110603199841\n",
      "Epoch 10, train loss: 0.19977520406246185, train acc: 0.9149110603199841\n",
      "Epoch 0, train loss: 0.19977477192878723, train acc: 0.9149110603199841\n",
      "Epoch 10, train loss: 0.19977040588855743, train acc: 0.9149110603199841\n",
      "Accuracy for each output state:\n",
      "0.9147868428897943\n",
      "Value 's_m_h60_val3: 0.9147868428897943' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9408893709327548\n",
      "Value 's_m_h60_val3: 0.9408893709327548' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.2307160645723343, train acc: 0.8982779640353551\n",
      "Epoch 10, train loss: 0.23071224987506866, train acc: 0.8982779640353551\n",
      "Epoch 0, train loss: 0.23071181774139404, train acc: 0.8982779640353551\n",
      "Epoch 10, train loss: 0.23070751130580902, train acc: 0.8982779640353551\n",
      "Accuracy for each output state:\n",
      "0.8982525652748146\n",
      "Value 's_m_h70_val3: 0.8982525652748146' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.926829268292683\n",
      "Value 's_m_h70_val3: 0.926829268292683' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.27517786622047424, train acc: 0.8771692819287125\n",
      "Epoch 10, train loss: 0.27517184615135193, train acc: 0.8771433025044165\n",
      "Epoch 0, train loss: 0.2751712203025818, train acc: 0.8771433025044165\n",
      "Epoch 10, train loss: 0.27516409754753113, train acc: 0.8771692819287125\n",
      "Accuracy for each output state:\n",
      "0.8770134053829367\n",
      "Value 's_m_h80_val3: 0.8770134053829367' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9024943310657597\n",
      "Value 's_m_h80_val3: 0.9024943310657597' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.32962390780448914, train acc: 0.8543815803466979\n",
      "Epoch 10, train loss: 0.3296123147010803, train acc: 0.8543815803466979\n",
      "Epoch 0, train loss: 0.32961103320121765, train acc: 0.8543815803466979\n",
      "Epoch 10, train loss: 0.3295973837375641, train acc: 0.8543815803466979\n",
      "Accuracy for each output state:\n",
      "0.8543018185685419\n",
      "Value 's_m_h90_val3: 0.8543018185685419' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8776102088167053\n",
      "Value 's_m_h90_val3: 0.8776102088167053' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.3946256935596466, train acc: 0.8306381356855058\n",
      "Epoch 10, train loss: 0.3946036398410797, train acc: 0.8306381356855058\n",
      "Epoch 0, train loss: 0.3946012258529663, train acc: 0.8306381356855058\n",
      "Epoch 10, train loss: 0.39457622170448303, train acc: 0.8306381356855058\n",
      "Accuracy for each output state:\n",
      "0.8306109114668409\n",
      "Value 's_m_h100_val3: 0.8306109114668409' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8509501187648457\n",
      "Value 's_m_h100_val3: 0.8509501187648457' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.23409871757030487, train acc: 0.8986208131828766\n",
      "Epoch 10, train loss: 0.23409534990787506, train acc: 0.8986432025792584\n",
      "Epoch 0, train loss: 0.23409311473369598, train acc: 0.8986432025792584\n",
      "Epoch 10, train loss: 0.23406212031841278, train acc: 0.8986655919756403\n",
      "Accuracy for each output state:\n",
      "0.8982625828407667\n",
      "Value 's_m_h10_val4: 0.8982625828407667' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.905511811023622\n",
      "Value 's_m_h10_val4: 0.905511811023622' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.2086394876241684, train acc: 0.9108806870089531\n",
      "Epoch 10, train loss: 0.2086101621389389, train acc: 0.9108806870089531\n",
      "Epoch 0, train loss: 0.2086072564125061, train acc: 0.9108806870089531\n",
      "Epoch 10, train loss: 0.208578422665596, train acc: 0.9108806870089531\n",
      "Accuracy for each output state:\n",
      "0.9109035264023387\n",
      "Value 's_m_h20_val4: 0.9109035264023387' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9021084337349398\n",
      "Value 's_m_h20_val4: 0.9021084337349398' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.18776032328605652, train acc: 0.9232472496736901\n",
      "Epoch 10, train loss: 0.187739759683609, train acc: 0.923270557523774\n",
      "Epoch 0, train loss: 0.18773780763149261, train acc: 0.923270557523774\n",
      "Epoch 10, train loss: 0.1877189725637436, train acc: 0.9232472496736901\n",
      "Accuracy for each output state:\n",
      "0.9232472496736901\n",
      "Value 's_m_h30_val4: 0.9232472496736901' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9031762295081968\n",
      "Value 's_m_h30_val4: 0.9031762295081968' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.17847755551338196, train acc: 0.9300637730820484\n",
      "Epoch 10, train loss: 0.17846521735191345, train acc: 0.9300875690081858\n",
      "Epoch 0, train loss: 0.17846406996250153, train acc: 0.9300875690081858\n",
      "Epoch 10, train loss: 0.17845295369625092, train acc: 0.9300875690081858\n",
      "Accuracy for each output state:\n",
      "0.9301113649343233\n",
      "Value 's_m_h40_val4: 0.9301113649343233' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8948744769874477\n",
      "Value 's_m_h40_val4: 0.8948744769874477' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.18224096298217773, train acc: 0.9276200661092747\n",
      "Epoch 10, train loss: 0.1822340041399002, train acc: 0.9276200661092747\n",
      "Epoch 0, train loss: 0.18223336338996887, train acc: 0.9276200661092747\n",
      "Epoch 10, train loss: 0.18222704529762268, train acc: 0.9276200661092747\n",
      "Accuracy for each output state:\n",
      "0.9276443709896949\n",
      "Value 's_m_h50_val4: 0.9276443709896949' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8691239316239315\n",
      "Value 's_m_h50_val4: 0.8691239316239315' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.19608159363269806, train acc: 0.9189101927279952\n",
      "Epoch 10, train loss: 0.19607780873775482, train acc: 0.9189101927279952\n",
      "Epoch 0, train loss: 0.19607746601104736, train acc: 0.9189101927279952\n",
      "Epoch 10, train loss: 0.19607381522655487, train acc: 0.9189101927279952\n",
      "Accuracy for each output state:\n",
      "0.9189598648917147\n",
      "Value 's_m_h60_val4: 0.9189598648917147' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8515283842794759\n",
      "Value 's_m_h60_val4: 0.8515283842794759' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.22693897783756256, train acc: 0.9028285598212472\n",
      "Epoch 10, train loss: 0.22693607211112976, train acc: 0.9028285598212472\n",
      "Epoch 0, train loss: 0.2269357591867447, train acc: 0.9028285598212472\n",
      "Epoch 10, train loss: 0.2269323617219925, train acc: 0.9028285598212472\n",
      "Accuracy for each output state:\n",
      "0.902752386756043\n",
      "Value 's_m_h70_val4: 0.902752386756043' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8370535714285714\n",
      "Value 's_m_h70_val4: 0.8370535714285714' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.27128344774246216, train acc: 0.8814668605859132\n",
      "Epoch 10, train loss: 0.27127838134765625, train acc: 0.8814668605859132\n",
      "Epoch 0, train loss: 0.2712777853012085, train acc: 0.8814668605859132\n",
      "Epoch 10, train loss: 0.2712714374065399, train acc: 0.8814668605859132\n",
      "Accuracy for each output state:\n",
      "0.8814408892582589\n",
      "Value 's_m_h80_val4: 0.8814408892582589' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8327625570776255\n",
      "Value 's_m_h80_val4: 0.8327625570776255' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.3259771466255188, train acc: 0.8588401020625133\n",
      "Epoch 10, train loss: 0.3259660303592682, train acc: 0.8588401020625133\n",
      "Epoch 0, train loss: 0.3259648084640503, train acc: 0.8588401020625133\n",
      "Epoch 10, train loss: 0.32595157623291016, train acc: 0.8588401020625133\n",
      "Accuracy for each output state:\n",
      "0.8588666808420158\n",
      "Value 's_m_h90_val4: 0.8588666808420158' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8218457943925234\n",
      "Value 's_m_h90_val4: 0.8218457943925234' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.3923868238925934, train acc: 0.8348029610276507\n",
      "Epoch 10, train loss: 0.3923649191856384, train acc: 0.8348301763553233\n",
      "Epoch 0, train loss: 0.392362505197525, train acc: 0.8348301763553233\n",
      "Epoch 10, train loss: 0.392337441444397, train acc: 0.8348573916829959\n",
      "Accuracy for each output state:\n",
      "0.8348301763553233\n",
      "Value 's_m_h100_val4: 0.8348301763553233' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8068181818181818\n",
      "Value 's_m_h100_val4: 0.8068181818181818' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.23432877659797668, train acc: 0.8969949312092687\n",
      "Epoch 10, train loss: 0.23432429134845734, train acc: 0.8969949312092687\n",
      "Epoch 0, train loss: 0.23432202637195587, train acc: 0.8969949312092687\n",
      "Epoch 10, train loss: 0.23429124057292938, train acc: 0.8969949312092687\n",
      "Accuracy for each output state:\n",
      "0.8968591600289645\n",
      "Value 's_m_h10_val5: 0.8968591600289645' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.915335463258786\n",
      "Value 's_m_h10_val5: 0.915335463258786' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.21025928854942322, train acc: 0.910024935352789\n",
      "Epoch 10, train loss: 0.21023070812225342, train acc: 0.9100018470631696\n",
      "Epoch 0, train loss: 0.21022789180278778, train acc: 0.9100018470631696\n",
      "Epoch 10, train loss: 0.21019986271858215, train acc: 0.910024935352789\n",
      "Accuracy for each output state:\n",
      "0.9100018470631696\n",
      "Value 's_m_h20_val5: 0.9100018470631696' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9330357142857143\n",
      "Value 's_m_h20_val5: 0.9330357142857143' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.1908957064151764, train acc: 0.921615761689291\n",
      "Epoch 10, train loss: 0.1908760517835617, train acc: 0.921615761689291\n",
      "Epoch 0, train loss: 0.19087418913841248, train acc: 0.921615761689291\n",
      "Epoch 10, train loss: 0.1908562183380127, train acc: 0.9216393288084465\n",
      "Accuracy for each output state:\n",
      "0.9216628959276018\n",
      "Value 's_m_h30_val5: 0.9216628959276018' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9533828382838284\n",
      "Value 's_m_h30_val5: 0.9533828382838284' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.1829153150320053, train acc: 0.9272237196765498\n",
      "Epoch 10, train loss: 0.18290342390537262, train acc: 0.9271996534462842\n",
      "Epoch 0, train loss: 0.18290232121944427, train acc: 0.9271755872160184\n",
      "Epoch 10, train loss: 0.18289148807525635, train acc: 0.9271755872160184\n",
      "Accuracy for each output state:\n",
      "0.9272237196765498\n",
      "Value 's_m_h40_val5: 0.9272237196765498' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9618288590604026\n",
      "Value 's_m_h40_val5: 0.9618288590604026' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.187894806265831, train acc: 0.9240509441384737\n",
      "Epoch 10, train loss: 0.18788772821426392, train acc: 0.9240509441384737\n",
      "Epoch 0, train loss: 0.1878870576620102, train acc: 0.9240509441384737\n",
      "Epoch 10, train loss: 0.18788045644760132, train acc: 0.9240509441384737\n",
      "Accuracy for each output state:\n",
      "0.9239280094413848\n",
      "Value 's_m_h50_val5: 0.9239280094413848' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9556313993174061\n",
      "Value 's_m_h50_val5: 0.9556313993174061' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.20213018357753754, train acc: 0.9156363088057901\n",
      "Epoch 10, train loss: 0.20212571322917938, train acc: 0.9156614394853236\n",
      "Epoch 0, train loss: 0.20212526619434357, train acc: 0.9156614394853236\n",
      "Epoch 10, train loss: 0.2021208107471466, train acc: 0.9156614394853236\n",
      "Accuracy for each output state:\n",
      "0.9156614394853237\n",
      "Value 's_m_h60_val5: 0.9156614394853237' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.94140625\n",
      "Value 's_m_h60_val5: 0.94140625' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.23390774428844452, train acc: 0.8992084703947368\n",
      "Epoch 10, train loss: 0.2339038848876953, train acc: 0.8992084703947368\n",
      "Epoch 0, train loss: 0.23390348255634308, train acc: 0.8992084703947368\n",
      "Epoch 10, train loss: 0.23389916121959686, train acc: 0.8992084703947368\n",
      "Accuracy for each output state:\n",
      "0.8990285773026315\n",
      "Value 's_m_h70_val5: 0.8990285773026315' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9275618374558303\n",
      "Value 's_m_h70_val5: 0.9275618374558303' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.2795500159263611, train acc: 0.8788388725283971\n",
      "Epoch 10, train loss: 0.27954408526420593, train acc: 0.8788651661758519\n",
      "Epoch 0, train loss: 0.2795434296131134, train acc: 0.8788651661758519\n",
      "Epoch 10, train loss: 0.2795363962650299, train acc: 0.8788651661758519\n",
      "Accuracy for each output state:\n",
      "0.8787599915860329\n",
      "Value 's_m_h80_val5: 0.8787599915860329' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9042266187050358\n",
      "Value 's_m_h80_val5: 0.9042266187050358' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.33494406938552856, train acc: 0.8566698966408268\n",
      "Epoch 10, train loss: 0.33493277430534363, train acc: 0.856696813092162\n",
      "Epoch 0, train loss: 0.33493155241012573, train acc: 0.856696813092162\n",
      "Epoch 10, train loss: 0.33491840958595276, train acc: 0.8566698966408268\n",
      "Accuracy for each output state:\n",
      "0.8566160637381567\n",
      "Value 's_m_h90_val5: 0.8566160637381567' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8804945054945055\n",
      "Value 's_m_h90_val5: 0.8804945054945055' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.4017060101032257, train acc: 0.8329565505072783\n",
      "Epoch 10, train loss: 0.40168488025665283, train acc: 0.8329565505072783\n",
      "Epoch 0, train loss: 0.4016825258731842, train acc: 0.8329565505072783\n",
      "Epoch 10, train loss: 0.40165847539901733, train acc: 0.8329841199823556\n",
      "Accuracy for each output state:\n",
      "0.8329289810322011\n",
      "Value 's_m_h100_val5: 0.8329289810322011' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8540111940298508\n",
      "Value 's_m_h100_val5: 0.8540111940298508' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.23261119425296783, train acc: 0.8979081400636653\n",
      "Epoch 10, train loss: 0.23260781168937683, train acc: 0.8979081400636653\n",
      "Epoch 0, train loss: 0.23260581493377686, train acc: 0.8979308776716689\n",
      "Epoch 10, train loss: 0.2325773984193802, train acc: 0.8979536152796725\n",
      "Accuracy for each output state:\n",
      "0.8972260118235562\n",
      "Value 's_m_h10_val6: 0.8972260118235562' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9381443298969072\n",
      "Value 's_m_h10_val6: 0.9381443298969072' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.20860788226127625, train acc: 0.9097447795823665\n",
      "Epoch 10, train loss: 0.20858106017112732, train acc: 0.9097679814385151\n",
      "Epoch 0, train loss: 0.20857836306095123, train acc: 0.9097679814385151\n",
      "Epoch 10, train loss: 0.2085517942905426, train acc: 0.9097679814385151\n",
      "Accuracy for each output state:\n",
      "0.9098143851508121\n",
      "Value 's_m_h20_val6: 0.9098143851508121' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9480568011958146\n",
      "Value 's_m_h20_val6: 0.9480568011958146' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.18924012780189514, train acc: 0.9210800568450971\n",
      "Epoch 10, train loss: 0.1892213076353073, train acc: 0.9210563713879678\n",
      "Epoch 0, train loss: 0.18921950459480286, train acc: 0.9210563713879678\n",
      "Epoch 10, train loss: 0.18920215964317322, train acc: 0.9210563713879678\n",
      "Accuracy for each output state:\n",
      "0.9211511132164851\n",
      "Value 's_m_h30_val6: 0.9211511132164851' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9616843702579666\n",
      "Value 's_m_h30_val6: 0.9616843702579666' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.18174123764038086, train acc: 0.9261490082244799\n",
      "Epoch 10, train loss: 0.18172958493232727, train acc: 0.9261973875181423\n",
      "Epoch 0, train loss: 0.1817285120487213, train acc: 0.9261973875181423\n",
      "Epoch 10, train loss: 0.18171784281730652, train acc: 0.9261973875181423\n",
      "Accuracy for each output state:\n",
      "0.9262215771649734\n",
      "Value 's_m_h40_val6: 0.9262215771649734' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9722650231124808\n",
      "Value 's_m_h40_val6: 0.9722650231124808' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.18639029562473297, train acc: 0.9223677706376668\n",
      "Epoch 10, train loss: 0.18638336658477783, train acc: 0.9223677706376668\n",
      "Epoch 0, train loss: 0.1863827109336853, train acc: 0.9223677706376668\n",
      "Epoch 10, train loss: 0.18637622892856598, train acc: 0.9223677706376668\n",
      "Accuracy for each output state:\n",
      "0.9223924864063273\n",
      "Value 's_m_h50_val6: 0.9223924864063273' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9577464788732395\n",
      "Value 's_m_h50_val6: 0.9577464788732395' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.1997603178024292, train acc: 0.9142243557352198\n",
      "Epoch 10, train loss: 0.1997559666633606, train acc: 0.9142243557352198\n",
      "Epoch 0, train loss: 0.19975551962852478, train acc: 0.9142243557352198\n",
      "Epoch 10, train loss: 0.19975122809410095, train acc: 0.914199090449722\n",
      "Accuracy for each output state:\n",
      "0.914199090449722\n",
      "Value 's_m_h60_val6: 0.914199090449722' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9348171701112878\n",
      "Value 's_m_h60_val6: 0.9348171701112878' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.22992853820323944, train acc: 0.8981653746770026\n",
      "Epoch 10, train loss: 0.22992479801177979, train acc: 0.8981653746770026\n",
      "Epoch 0, train loss: 0.22992442548274994, train acc: 0.8981912144702843\n",
      "Epoch 10, train loss: 0.22992025315761566, train acc: 0.8981653746770026\n",
      "Accuracy for each output state:\n",
      "0.8981653746770026\n",
      "Value 's_m_h70_val6: 0.8981653746770026' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9091276252019386\n",
      "Value 's_m_h70_val6: 0.9091276252019386' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.27404534816741943, train acc: 0.8775780010576415\n",
      "Epoch 10, train loss: 0.27403974533081055, train acc: 0.8775780010576415\n",
      "Epoch 0, train loss: 0.2740391492843628, train acc: 0.8775780010576415\n",
      "Epoch 10, train loss: 0.27403250336647034, train acc: 0.8775780010576415\n",
      "Accuracy for each output state:\n",
      "0.8776573241671073\n",
      "Value 's_m_h80_val6: 0.8776573241671073' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8825944170771757\n",
      "Value 's_m_h80_val6: 0.8825944170771757' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.32905814051628113, train acc: 0.8550893340552247\n",
      "Epoch 10, train loss: 0.32904738187789917, train acc: 0.8550893340552247\n",
      "Epoch 0, train loss: 0.32904618978500366, train acc: 0.8550893340552247\n",
      "Epoch 10, train loss: 0.3290334641933441, train acc: 0.8550893340552247\n",
      "Accuracy for each output state:\n",
      "0.8549810503519221\n",
      "Value 's_m_h90_val6: 0.8549810503519221' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8589315525876461\n",
      "Value 's_m_h90_val6: 0.8589315525876461' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.3951561748981476, train acc: 0.8308097615085968\n",
      "Epoch 10, train loss: 0.3951355814933777, train acc: 0.8308097615085968\n",
      "Epoch 0, train loss: 0.3951333165168762, train acc: 0.8308097615085968\n",
      "Epoch 10, train loss: 0.39510971307754517, train acc: 0.8308097615085968\n",
      "Accuracy for each output state:\n",
      "0.830865224625624\n",
      "Value 's_m_h100_val6: 0.830865224625624' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.83616298811545\n",
      "Value 's_m_h100_val6: 0.83616298811545' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.2242790013551712, train acc: 0.9038866990558254\n",
      "Epoch 10, train loss: 0.22427739202976227, train acc: 0.903909615913466\n",
      "Epoch 0, train loss: 0.2242756485939026, train acc: 0.9039325327711064\n",
      "Epoch 10, train loss: 0.22425147891044617, train acc: 0.9039325327711064\n",
      "Accuracy for each output state:\n",
      "0.9036575304794207\n",
      "Value 's_m_h10_val7: 0.9036575304794207' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8591503267973856\n",
      "Value 's_m_h10_val7: 0.8591503267973856' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.20190326869487762, train acc: 0.914795584245486\n",
      "Epoch 10, train loss: 0.2018807977437973, train acc: 0.9148189727757507\n",
      "Epoch 0, train loss: 0.20187857747077942, train acc: 0.9148189727757507\n",
      "Epoch 10, train loss: 0.2018563598394394, train acc: 0.9148189727757507\n",
      "Accuracy for each output state:\n",
      "0.914795584245486\n",
      "Value 's_m_h20_val7: 0.914795584245486' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8844370860927153\n",
      "Value 's_m_h20_val7: 0.8844370860927153' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.18380628526210785, train acc: 0.9249450759384851\n",
      "Epoch 10, train loss: 0.18379110097885132, train acc: 0.9249450759384851\n",
      "Epoch 0, train loss: 0.1837896704673767, train acc: 0.9249450759384851\n",
      "Epoch 10, train loss: 0.18377576768398285, train acc: 0.9249689559652307\n",
      "Accuracy for each output state:\n",
      "0.9249211959117395\n",
      "Value 's_m_h30_val7: 0.9249211959117395' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9073825503355705\n",
      "Value 's_m_h30_val7: 0.9073825503355705' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.1765972077846527, train acc: 0.9309200897648551\n",
      "Epoch 10, train loss: 0.17658819258213043, train acc: 0.9309200897648551\n",
      "Epoch 0, train loss: 0.17658734321594238, train acc: 0.9309200897648551\n",
      "Epoch 10, train loss: 0.1765790581703186, train acc: 0.9309200897648551\n",
      "Accuracy for each output state:\n",
      "0.930749341399161\n",
      "Value 's_m_h40_val7: 0.930749341399161' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9088435374149659\n",
      "Value 's_m_h40_val7: 0.9088435374149659' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.1825728565454483, train acc: 0.926662678233124\n",
      "Epoch 10, train loss: 0.1825675070285797, train acc: 0.926662678233124\n",
      "Epoch 0, train loss: 0.18256697058677673, train acc: 0.926662678233124\n",
      "Epoch 10, train loss: 0.18256190419197083, train acc: 0.926662678233124\n",
      "Accuracy for each output state:\n",
      "0.9265380396849138\n",
      "Value 's_m_h50_val7: 0.9265380396849138' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9065517241379311\n",
      "Value 's_m_h50_val7: 0.9065517241379311' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.19748032093048096, train acc: 0.91739728820471\n",
      "Epoch 10, train loss: 0.19747674465179443, train acc: 0.91739728820471\n",
      "Epoch 0, train loss: 0.19747638702392578, train acc: 0.91739728820471\n",
      "Epoch 10, train loss: 0.19747276604175568, train acc: 0.9174227750025487\n",
      "Accuracy for each output state:\n",
      "0.9174737485982261\n",
      "Value 's_m_h60_val7: 0.9174737485982261' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8965034965034965\n",
      "Value 's_m_h60_val7: 0.8965034965034965' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.2281968891620636, train acc: 0.9016581499634998\n",
      "Epoch 10, train loss: 0.2281934916973114, train acc: 0.9016581499634998\n",
      "Epoch 0, train loss: 0.22819314897060394, train acc: 0.9016581499634998\n",
      "Epoch 10, train loss: 0.22818931937217712, train acc: 0.9016581499634998\n",
      "Accuracy for each output state:\n",
      "0.9015277922619669\n",
      "Value 's_m_h70_val7: 0.9015277922619669' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.876950354609929\n",
      "Value 's_m_h70_val7: 0.876950354609929' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.2725445330142975, train acc: 0.8806702956558864\n",
      "Epoch 10, train loss: 0.2725392282009125, train acc: 0.8806702956558864\n",
      "Epoch 0, train loss: 0.2725386321544647, train acc: 0.8806702956558864\n",
      "Epoch 10, train loss: 0.2725323438644409, train acc: 0.8806702956558864\n",
      "Accuracy for each output state:\n",
      "0.8806436119116234\n",
      "Value 's_m_h80_val7: 0.8806436119116234' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8532374100719424\n",
      "Value 's_m_h80_val7: 0.8532374100719424' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.32582780718803406, train acc: 0.8576620395671658\n",
      "Epoch 10, train loss: 0.32581770420074463, train acc: 0.8576620395671658\n",
      "Epoch 0, train loss: 0.32581663131713867, train acc: 0.8576620395671658\n",
      "Epoch 10, train loss: 0.3258048892021179, train acc: 0.8576620395671658\n",
      "Accuracy for each output state:\n",
      "0.8577166903486719\n",
      "Value 's_m_h90_val7: 0.8577166903486719' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8255474452554744\n",
      "Value 's_m_h90_val7: 0.8255474452554744' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.389822781085968, train acc: 0.8343879493784299\n",
      "Epoch 10, train loss: 0.3898041248321533, train acc: 0.8343879493784299\n",
      "Epoch 0, train loss: 0.38980209827423096, train acc: 0.8343879493784299\n",
      "Epoch 10, train loss: 0.38978075981140137, train acc: 0.8343879493784299\n",
      "Accuracy for each output state:\n",
      "0.8344439466905588\n",
      "Value 's_m_h100_val7: 0.8344439466905588' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.7985185185185184\n",
      "Value 's_m_h100_val7: 0.7985185185185184' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.23236815631389618, train acc: 0.897812166488794\n",
      "Epoch 10, train loss: 0.23236459493637085, train acc: 0.897812166488794\n",
      "Epoch 0, train loss: 0.2323625534772873, train acc: 0.897812166488794\n",
      "Epoch 10, train loss: 0.2323341965675354, train acc: 0.8978788687299893\n",
      "Accuracy for each output state:\n",
      "0.8975675916044112\n",
      "Value 's_m_h10_val8: 0.8975675916044112' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9546511627906976\n",
      "Value 's_m_h10_val8: 0.9546511627906976' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.20823796093463898, train acc: 0.9094929245283019\n",
      "Epoch 10, train loss: 0.20821154117584229, train acc: 0.9094929245283019\n",
      "Epoch 0, train loss: 0.20820894837379456, train acc: 0.9094929245283019\n",
      "Epoch 10, train loss: 0.2081829011440277, train acc: 0.9094929245283019\n",
      "Accuracy for each output state:\n",
      "0.9094929245283019\n",
      "Value 's_m_h20_val8: 0.9094929245283019' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9666666666666667\n",
      "Value 's_m_h20_val8: 0.9666666666666667' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.18851357698440552, train acc: 0.9209783413550536\n",
      "Epoch 10, train loss: 0.18849551677703857, train acc: 0.9209783413550536\n",
      "Epoch 0, train loss: 0.18849381804466248, train acc: 0.9209783413550536\n",
      "Epoch 10, train loss: 0.1884773075580597, train acc: 0.9209552017771195\n",
      "Accuracy for each output state:\n",
      "0.9210246205109219\n",
      "Value 's_m_h30_val8: 0.9210246205109219' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.975\n",
      "Value 's_m_h30_val8: 0.975' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.18055380880832672, train acc: 0.9265636810279667\n",
      "Epoch 10, train loss: 0.1805432140827179, train acc: 0.9265873015873016\n",
      "Epoch 0, train loss: 0.1805422306060791, train acc: 0.9265873015873016\n",
      "Epoch 10, train loss: 0.18053266406059265, train acc: 0.9265873015873016\n",
      "Accuracy for each output state:\n",
      "0.926681783824641\n",
      "Value 's_m_h40_val8: 0.926681783824641' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9725\n",
      "Value 's_m_h40_val8: 0.9725' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.1858508288860321, train acc: 0.9232197993052875\n",
      "Epoch 10, train loss: 0.18584489822387695, train acc: 0.9232197993052875\n",
      "Epoch 0, train loss: 0.18584434688091278, train acc: 0.9232197993052875\n",
      "Epoch 10, train loss: 0.18583892285823822, train acc: 0.9232439212659205\n",
      "Accuracy for each output state:\n",
      "0.9231715553840215\n",
      "Value 's_m_h50_val8: 0.9231715553840215' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9583333333333334\n",
      "Value 's_m_h50_val8: 0.9583333333333334' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.20076479017734528, train acc: 0.9142103706624606\n",
      "Epoch 10, train loss: 0.20076137781143188, train acc: 0.9142103706624606\n",
      "Epoch 0, train loss: 0.20076104998588562, train acc: 0.9142103706624606\n",
      "Epoch 10, train loss: 0.2007576823234558, train acc: 0.9142103706624606\n",
      "Accuracy for each output state:\n",
      "0.9142350157728707\n",
      "Value 's_m_h60_val8: 0.9142350157728707' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9434210526315789\n",
      "Value 's_m_h60_val8: 0.9434210526315789' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.2334272265434265, train acc: 0.8976219266424829\n",
      "Epoch 10, train loss: 0.23342420160770416, train acc: 0.8976219266424829\n",
      "Epoch 0, train loss: 0.2334238439798355, train acc: 0.8976219266424829\n",
      "Epoch 10, train loss: 0.23342028260231018, train acc: 0.8976219266424829\n",
      "Accuracy for each output state:\n",
      "0.8975967351874244\n",
      "Value 's_m_h70_val8: 0.8975967351874244' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9331081081081081\n",
      "Value 's_m_h70_val8: 0.9331081081081081' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.2802133560180664, train acc: 0.8767003297609234\n",
      "Epoch 10, train loss: 0.28020793199539185, train acc: 0.8767260923330585\n",
      "Epoch 0, train loss: 0.2802073061466217, train acc: 0.8767260923330585\n",
      "Epoch 10, train loss: 0.28020069003105164, train acc: 0.8767260923330585\n",
      "Accuracy for each output state:\n",
      "0.8765972794723825\n",
      "Value 's_m_h80_val8: 0.8765972794723825' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9243055555555555\n",
      "Value 's_m_h80_val8: 0.9243055555555555' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.3371273875236511, train acc: 0.8535955293125264\n",
      "Epoch 10, train loss: 0.3371161222457886, train acc: 0.853621889498102\n",
      "Epoch 0, train loss: 0.3371148407459259, train acc: 0.853621889498102\n",
      "Epoch 10, train loss: 0.33710142970085144, train acc: 0.853621889498102\n",
      "Accuracy for each output state:\n",
      "0.8535955293125264\n",
      "Value 's_m_h90_val8: 0.8535955293125264' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.915\n",
      "Value 's_m_h90_val8: 0.915' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.4049842059612274, train acc: 0.829744170984456\n",
      "Epoch 10, train loss: 0.404962420463562, train acc: 0.8297711571675302\n",
      "Epoch 0, train loss: 0.404960036277771, train acc: 0.8297711571675302\n",
      "Epoch 10, train loss: 0.4049351215362549, train acc: 0.8297711571675302\n",
      "Accuracy for each output state:\n",
      "0.8297981433506045\n",
      "Value 's_m_h100_val8: 0.8297981433506045' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9051470588235294\n",
      "Value 's_m_h100_val8: 0.9051470588235294' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.2260921150445938, train acc: 0.9029194116054508\n",
      "Epoch 10, train loss: 0.22608986496925354, train acc: 0.9028968504647595\n",
      "Epoch 0, train loss: 0.22608797252178192, train acc: 0.9028968504647595\n",
      "Epoch 10, train loss: 0.2260613590478897, train acc: 0.9028968504647595\n",
      "Accuracy for each output state:\n",
      "0.9024230665102427\n",
      "Value 's_m_h10_val9: 0.9024230665102427' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8389544688026982\n",
      "Value 's_m_h10_val9: 0.8389544688026982' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.20361892879009247, train acc: 0.9135438725715864\n",
      "Epoch 10, train loss: 0.20359373092651367, train acc: 0.9135438725715864\n",
      "Epoch 0, train loss: 0.2035912275314331, train acc: 0.9135438725715864\n",
      "Epoch 10, train loss: 0.20356620848178864, train acc: 0.9135668907098794\n",
      "Accuracy for each output state:\n",
      "0.9136359451247583\n",
      "Value 's_m_h20_val9: 0.9136359451247583' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8704974271012007\n",
      "Value 's_m_h20_val9: 0.8704974271012007' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.18553996086120605, train acc: 0.9243257212667982\n",
      "Epoch 10, train loss: 0.18552237749099731, train acc: 0.9243257212667982\n",
      "Epoch 0, train loss: 0.1855207234621048, train acc: 0.9243257212667982\n",
      "Epoch 10, train loss: 0.18550458550453186, train acc: 0.9243257212667982\n",
      "Accuracy for each output state:\n",
      "0.9244431914293769\n",
      "Value 's_m_h30_val9: 0.9244431914293769' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.906195462478185\n",
      "Value 's_m_h30_val9: 0.906195462478185' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.17876118421554565, train acc: 0.928293829766817\n",
      "Epoch 10, train loss: 0.17875072360038757, train acc: 0.928293829766817\n",
      "Epoch 0, train loss: 0.17874974012374878, train acc: 0.9283178197869686\n",
      "Epoch 10, train loss: 0.1787402629852295, train acc: 0.9283178197869686\n",
      "Accuracy for each output state:\n",
      "0.9284377698877266\n",
      "Value 's_m_h40_val9: 0.9284377698877266' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.933392539964476\n",
      "Value 's_m_h40_val9: 0.933392539964476' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.18361519277095795, train acc: 0.9249338300166651\n",
      "Epoch 10, train loss: 0.18360932171344757, train acc: 0.9249338300166651\n",
      "Epoch 0, train loss: 0.1836087852716446, train acc: 0.9249338300166651\n",
      "Epoch 10, train loss: 0.1836034208536148, train acc: 0.9249338300166651\n",
      "Accuracy for each output state:\n",
      "0.924933830016665\n",
      "Value 's_m_h50_val9: 0.924933830016665' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9281193490054249\n",
      "Value 's_m_h50_val9: 0.9281193490054249' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.19736692309379578, train acc: 0.9163660955816051\n",
      "Epoch 10, train loss: 0.1973637044429779, train acc: 0.9163660955816051\n",
      "Epoch 0, train loss: 0.19736339151859283, train acc: 0.9163660955816051\n",
      "Epoch 10, train loss: 0.19736026227474213, train acc: 0.9163660955816051\n",
      "Accuracy for each output state:\n",
      "0.9163911431720269\n",
      "Value 's_m_h60_val9: 0.9163911431720269' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.908379373848987\n",
      "Value 's_m_h60_val9: 0.908379373848987' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.22757138311862946, train acc: 0.9008298330089131\n",
      "Epoch 10, train loss: 0.22756874561309814, train acc: 0.9008554451388178\n",
      "Epoch 0, train loss: 0.22756847739219666, train acc: 0.9008554451388178\n",
      "Epoch 10, train loss: 0.22756527364253998, train acc: 0.9008554451388178\n",
      "Accuracy for each output state:\n",
      "0.9007529966191988\n",
      "Value 's_m_h70_val9: 0.9007529966191988' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8771106941838649\n",
      "Value 's_m_h70_val9: 0.8771106941838649' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.27082815766334534, train acc: 0.880856304370611\n",
      "Epoch 10, train loss: 0.27082300186157227, train acc: 0.8808825070747301\n",
      "Epoch 0, train loss: 0.2708224058151245, train acc: 0.8808825070747301\n",
      "Epoch 10, train loss: 0.27081605792045593, train acc: 0.8809087097788492\n",
      "Accuracy for each output state:\n",
      "0.8809349124829682\n",
      "Value 's_m_h80_val9: 0.8809349124829682' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8393881453154874\n",
      "Value 's_m_h80_val9: 0.8393881453154874' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.3242557942867279, train acc: 0.8594571397918678\n",
      "Epoch 10, train loss: 0.3242446780204773, train acc: 0.8594571397918678\n",
      "Epoch 0, train loss: 0.324243426322937, train acc: 0.8594571397918678\n",
      "Epoch 10, train loss: 0.3242301940917969, train acc: 0.8594839609483961\n",
      "Accuracy for each output state:\n",
      "0.8594571397918679\n",
      "Value 's_m_h90_val9: 0.8594571397918679' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.804093567251462\n",
      "Value 's_m_h90_val9: 0.804093567251462' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.3894626498222351, train acc: 0.8361169102296451\n",
      "Epoch 10, train loss: 0.38944122195243835, train acc: 0.8361169102296451\n",
      "Epoch 0, train loss: 0.3894388675689697, train acc: 0.8361169102296451\n",
      "Epoch 10, train loss: 0.3894144594669342, train acc: 0.8361169102296451\n",
      "Accuracy for each output state:\n",
      "0.8361718492473353\n",
      "Value 's_m_h100_val9: 0.8361718492473353' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.7683896620278329\n",
      "Value 's_m_h100_val9: 0.7683896620278329' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.22421996295452118, train acc: 0.9026595744680851\n",
      "Epoch 10, train loss: 0.22421765327453613, train acc: 0.9026374113475177\n",
      "Epoch 0, train loss: 0.22421589493751526, train acc: 0.9026374113475177\n",
      "Epoch 10, train loss: 0.22419100999832153, train acc: 0.9026595744680851\n",
      "Accuracy for each output state:\n",
      "0.9021054964539008\n",
      "Value 's_m_h10_val10: 0.9021054964539008' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.807741116751269\n",
      "Value 's_m_h10_val10: 0.807741116751269' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.2007003277540207, train acc: 0.913991862567812\n",
      "Epoch 10, train loss: 0.2006763517856598, train acc: 0.913991862567812\n",
      "Epoch 0, train loss: 0.20067396759986877, train acc: 0.913991862567812\n",
      "Epoch 10, train loss: 0.20065024495124817, train acc: 0.9140144665461121\n",
      "Accuracy for each output state:\n",
      "0.9139692585895118\n",
      "Value 's_m_h20_val10: 0.9139692585895118' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8307291666666666\n",
      "Value 's_m_h20_val10: 0.8307291666666666' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.18154305219650269, train acc: 0.9255996309963099\n",
      "Epoch 10, train loss: 0.1815260499715805, train acc: 0.9255996309963099\n",
      "Epoch 0, train loss: 0.18152441084384918, train acc: 0.9255996309963099\n",
      "Epoch 10, train loss: 0.18150877952575684, train acc: 0.9256457564575645\n",
      "Accuracy for each output state:\n",
      "0.9255535055350553\n",
      "Value 's_m_h30_val10: 0.9255535055350553' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8509358288770054\n",
      "Value 's_m_h30_val10: 0.8509358288770054' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.17393235862255096, train acc: 0.930484934086629\n",
      "Epoch 10, train loss: 0.17392198741436005, train acc: 0.9305084745762712\n",
      "Epoch 0, train loss: 0.17392101883888245, train acc: 0.9305084745762712\n",
      "Epoch 10, train loss: 0.17391158640384674, train acc: 0.9305084745762712\n",
      "Accuracy for each output state:\n",
      "0.9305084745762712\n",
      "Value 's_m_h40_val10: 0.9305084745762712' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8619505494505495\n",
      "Value 's_m_h40_val10: 0.8619505494505495' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.17884385585784912, train acc: 0.9270432692307692\n",
      "Epoch 10, train loss: 0.17883795499801636, train acc: 0.9270192307692308\n",
      "Epoch 0, train loss: 0.17883740365505219, train acc: 0.9270192307692308\n",
      "Epoch 10, train loss: 0.17883199453353882, train acc: 0.9270192307692308\n",
      "Accuracy for each output state:\n",
      "0.9270192307692309\n",
      "Value 's_m_h50_val10: 0.9270192307692309' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8587570621468927\n",
      "Value 's_m_h50_val10: 0.8587570621468927' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.19300848245620728, train acc: 0.9180992141453831\n",
      "Epoch 10, train loss: 0.19300508499145508, train acc: 0.9180992141453831\n",
      "Epoch 0, train loss: 0.19300474226474762, train acc: 0.9180992141453831\n",
      "Epoch 10, train loss: 0.1930014044046402, train acc: 0.9180992141453831\n",
      "Accuracy for each output state:\n",
      "0.918246561886051\n",
      "Value 's_m_h60_val10: 0.918246561886051' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8561046511627907\n",
      "Value 's_m_h60_val10: 0.8561046511627907' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.22346441447734833, train acc: 0.9024849397590361\n",
      "Epoch 10, train loss: 0.22346141934394836, train acc: 0.9024849397590361\n",
      "Epoch 0, train loss: 0.22346113622188568, train acc: 0.9024849397590361\n",
      "Epoch 10, train loss: 0.2234576940536499, train acc: 0.9024849397590361\n",
      "Accuracy for each output state:\n",
      "0.9023845381526104\n",
      "Value 's_m_h70_val10: 0.9023845381526104' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8315868263473053\n",
      "Value 's_m_h70_val10: 0.8315868263473053' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.2676536738872528, train acc: 0.881776180698152\n",
      "Epoch 10, train loss: 0.2676486074924469, train acc: 0.881776180698152\n",
      "Epoch 0, train loss: 0.26764801144599915, train acc: 0.881776180698152\n",
      "Epoch 10, train loss: 0.26764190196990967, train acc: 0.881776180698152\n",
      "Accuracy for each output state:\n",
      "0.881776180698152\n",
      "Value 's_m_h80_val10: 0.881776180698152' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.7993827160493827\n",
      "Value 's_m_h80_val10: 0.7993827160493827' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.3220962882041931, train acc: 0.8601890756302522\n",
      "Epoch 10, train loss: 0.3220860958099365, train acc: 0.8601890756302522\n",
      "Epoch 0, train loss: 0.3220849335193634, train acc: 0.8601890756302522\n",
      "Epoch 10, train loss: 0.3220728635787964, train acc: 0.8602153361344538\n",
      "Accuracy for each output state:\n",
      "0.8602153361344538\n",
      "Value 's_m_h90_val10: 0.8602153361344538' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.7595541401273885\n",
      "Value 's_m_h90_val10: 0.7595541401273885' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.38696232438087463, train acc: 0.8370430107526882\n",
      "Epoch 10, train loss: 0.3869428336620331, train acc: 0.8370430107526882\n",
      "Epoch 0, train loss: 0.38694068789482117, train acc: 0.8370430107526882\n",
      "Epoch 10, train loss: 0.3869183659553528, train acc: 0.8370430107526882\n",
      "Accuracy for each output state:\n",
      "0.8370161290322581\n",
      "Value 's_m_h100_val10: 0.8370161290322581' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.7171052631578947\n",
      "Value 's_m_h100_val10: 0.7171052631578947' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.22793035209178925, train acc: 0.9002856632744153\n",
      "Epoch 10, train loss: 0.2279280424118042, train acc: 0.9002856632744153\n",
      "Epoch 0, train loss: 0.22792625427246094, train acc: 0.9002856632744153\n",
      "Epoch 10, train loss: 0.22790127992630005, train acc: 0.9002856632744153\n",
      "Accuracy for each output state:\n",
      "0.8998839492947688\n",
      "Value 's_m_h10_val11: 0.8998839492947688' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.864936440677966\n",
      "Value 's_m_h10_val11: 0.864936440677966' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.20455609261989594, train acc: 0.9121289382626115\n",
      "Epoch 10, train loss: 0.20453226566314697, train acc: 0.9121517027863777\n",
      "Epoch 0, train loss: 0.20452986657619476, train acc: 0.9121517027863777\n",
      "Epoch 10, train loss: 0.20450618863105774, train acc: 0.9121517027863777\n",
      "Accuracy for each output state:\n",
      "0.9121061737388454\n",
      "Value 's_m_h20_val11: 0.9121061737388454' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8847402597402598\n",
      "Value 's_m_h20_val11: 0.8847402597402598' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.18562963604927063, train acc: 0.9236898346032336\n",
      "Epoch 10, train loss: 0.18561279773712158, train acc: 0.9236666047203123\n",
      "Epoch 0, train loss: 0.18561120331287384, train acc: 0.9236666047203123\n",
      "Epoch 10, train loss: 0.1855955868959427, train acc: 0.9236433748373908\n",
      "Accuracy for each output state:\n",
      "0.9237595242519977\n",
      "Value 's_m_h30_val11: 0.9237595242519977' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9087389380530974\n",
      "Value 's_m_h30_val11: 0.9087389380530974' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.17853689193725586, train acc: 0.9284528552456839\n",
      "Epoch 10, train loss: 0.17852643132209778, train acc: 0.9284765699108328\n",
      "Epoch 0, train loss: 0.17852546274662018, train acc: 0.9284765699108328\n",
      "Epoch 10, train loss: 0.17851589620113373, train acc: 0.9284765699108328\n",
      "Accuracy for each output state:\n",
      "0.9283579965850883\n",
      "Value 's_m_h40_val11: 0.9283579965850883' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9281674208144797\n",
      "Value 's_m_h40_val11: 0.9281674208144797' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.18499375879764557, train acc: 0.924578570044565\n",
      "Epoch 10, train loss: 0.18498750030994415, train acc: 0.924578570044565\n",
      "Epoch 0, train loss: 0.1849868893623352, train acc: 0.924578570044565\n",
      "Epoch 10, train loss: 0.1849810630083084, train acc: 0.924578570044565\n",
      "Accuracy for each output state:\n",
      "0.9246027901569464\n",
      "Value 's_m_h50_val11: 0.9246027901569464' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9386574074074074\n",
      "Value 's_m_h50_val11: 0.9386574074074074' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.20104564726352692, train acc: 0.9152395565234607\n",
      "Epoch 10, train loss: 0.20104177296161652, train acc: 0.9152395565234607\n",
      "Epoch 0, train loss: 0.20104140043258667, train acc: 0.9152395565234607\n",
      "Epoch 10, train loss: 0.20103757083415985, train acc: 0.9152395565234607\n",
      "Accuracy for each output state:\n",
      "0.9151900613739854\n",
      "Value 's_m_h60_val11: 0.9151900613739854' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9478672985781991\n",
      "Value 's_m_h60_val11: 0.9478672985781991' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.23214982450008392, train acc: 0.8991600890507995\n",
      "Epoch 10, train loss: 0.2321465015411377, train acc: 0.8991600890507995\n",
      "Epoch 0, train loss: 0.23214612901210785, train acc: 0.8991600890507995\n",
      "Epoch 10, train loss: 0.2321424037218094, train acc: 0.8991600890507995\n",
      "Accuracy for each output state:\n",
      "0.8991347905282332\n",
      "Value 's_m_h70_val11: 0.8991347905282332' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9320388349514562\n",
      "Value 's_m_h70_val11: 0.9320388349514562' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.27657511830329895, train acc: 0.8784671910577521\n",
      "Epoch 10, train loss: 0.27656999230384827, train acc: 0.8784671910577521\n",
      "Epoch 0, train loss: 0.2765693962574005, train acc: 0.8784671910577521\n",
      "Epoch 10, train loss: 0.2765633761882782, train acc: 0.8784671910577521\n",
      "Accuracy for each output state:\n",
      "0.8784671910577521\n",
      "Value 's_m_h80_val11: 0.8784671910577521' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9092039800995025\n",
      "Value 's_m_h80_val11: 0.9092039800995025' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.3305722773075104, train acc: 0.8567835204405846\n",
      "Epoch 10, train loss: 0.3305625915527344, train acc: 0.8567835204405846\n",
      "Epoch 0, train loss: 0.33056148886680603, train acc: 0.8567835204405846\n",
      "Epoch 10, train loss: 0.33055007457733154, train acc: 0.8567835204405846\n",
      "Accuracy for each output state:\n",
      "0.8567305655581444\n",
      "Value 's_m_h90_val11: 0.8567305655581444' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8781887755102041\n",
      "Value 's_m_h90_val11: 0.8781887755102041' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.3948533535003662, train acc: 0.8331435697245717\n",
      "Epoch 10, train loss: 0.39483505487442017, train acc: 0.8331435697245717\n",
      "Epoch 0, train loss: 0.3948330879211426, train acc: 0.8331435697245717\n",
      "Epoch 10, train loss: 0.3948122560977936, train acc: 0.8331435697245717\n",
      "Accuracy for each output state:\n",
      "0.8331435697245716\n",
      "Value 's_m_h100_val11: 0.8331435697245716' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8422774869109947\n",
      "Value 's_m_h100_val11: 0.8422774869109947' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.22693820297718048, train acc: 0.9015572613375684\n",
      "Epoch 10, train loss: 0.22693312168121338, train acc: 0.9015352038115405\n",
      "Epoch 0, train loss: 0.22693102061748505, train acc: 0.9015352038115405\n",
      "Epoch 10, train loss: 0.22690258920192719, train acc: 0.9015352038115405\n",
      "Accuracy for each output state:\n",
      "0.9012043409211223\n",
      "Value 's_m_h10_val12: 0.9012043409211223' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8301470588235295\n",
      "Value 's_m_h10_val12: 0.8301470588235295' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.20354048907756805, train acc: 0.9135549757063164\n",
      "Epoch 10, train loss: 0.20351441204547882, train acc: 0.9135549757063164\n",
      "Epoch 0, train loss: 0.20351186394691467, train acc: 0.9135549757063164\n",
      "Epoch 10, train loss: 0.20348630845546722, train acc: 0.9135549757063164\n",
      "Accuracy for each output state:\n",
      "0.9135549757063164\n",
      "Value 's_m_h20_val12: 0.9135549757063164' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8583333333333333\n",
      "Value 's_m_h20_val12: 0.8583333333333333' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.1848667412996292, train acc: 0.9244538277951165\n",
      "Epoch 10, train loss: 0.18484914302825928, train acc: 0.9244767762070865\n",
      "Epoch 0, train loss: 0.18484748899936676, train acc: 0.9244767762070865\n",
      "Epoch 10, train loss: 0.18483132123947144, train acc: 0.9244767762070865\n",
      "Accuracy for each output state:\n",
      "0.9244079309711768\n",
      "Value 's_m_h30_val12: 0.9244079309711768' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8859374999999999\n",
      "Value 's_m_h30_val12: 0.8859374999999999' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.1780574917793274, train acc: 0.9297826494285178\n",
      "Epoch 10, train loss: 0.17804685235023499, train acc: 0.9297826494285178\n",
      "Epoch 0, train loss: 0.1780458688735962, train acc: 0.9297826494285178\n",
      "Epoch 10, train loss: 0.1780361831188202, train acc: 0.9297826494285178\n",
      "Accuracy for each output state:\n",
      "0.929782649428518\n",
      "Value 's_m_h40_val12: 0.929782649428518' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9072580645161291\n",
      "Value 's_m_h40_val12: 0.9072580645161291' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.18393732607364655, train acc: 0.9254352400994834\n",
      "Epoch 10, train loss: 0.183930903673172, train acc: 0.9254591543906638\n",
      "Epoch 0, train loss: 0.18393027782440186, train acc: 0.9254591543906638\n",
      "Epoch 10, train loss: 0.18392430245876312, train acc: 0.9254591543906638\n",
      "Accuracy for each output state:\n",
      "0.9254591543906638\n",
      "Value 's_m_h50_val12: 0.9254591543906638' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9191666666666667\n",
      "Value 's_m_h50_val12: 0.9191666666666667' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.19926531612873077, train acc: 0.9161373851866328\n",
      "Epoch 10, train loss: 0.19926108419895172, train acc: 0.9161373851866328\n",
      "Epoch 0, train loss: 0.1992606371641159, train acc: 0.9161373851866328\n",
      "Epoch 10, train loss: 0.19925644993782043, train acc: 0.9161373851866328\n",
      "Accuracy for each output state:\n",
      "0.9160885284346296\n",
      "Value 's_m_h60_val12: 0.9160885284346296' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9336206896551724\n",
      "Value 's_m_h60_val12: 0.9336206896551724' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.23157304525375366, train acc: 0.8989914120231676\n",
      "Epoch 10, train loss: 0.231569305062294, train acc: 0.8989914120231676\n",
      "Epoch 0, train loss: 0.23156891763210297, train acc: 0.8989914120231676\n",
      "Epoch 10, train loss: 0.2315647304058075, train acc: 0.899016377072099\n",
      "Accuracy for each output state:\n",
      "0.8989914120231676\n",
      "Value 's_m_h70_val12: 0.8989914120231676' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9455357142857143\n",
      "Value 's_m_h70_val12: 0.9455357142857143' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.27770161628723145, train acc: 0.877782315703492\n",
      "Epoch 10, train loss: 0.27769577503204346, train acc: 0.8778078415356341\n",
      "Epoch 0, train loss: 0.2776951193809509, train acc: 0.8778078415356341\n",
      "Epoch 10, train loss: 0.2776881456375122, train acc: 0.8778078415356341\n",
      "Accuracy for each output state:\n",
      "0.8778078415356341\n",
      "Value 's_m_h80_val12: 0.8778078415356341' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9277777777777778\n",
      "Value 's_m_h80_val12: 0.9277777777777778' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.3342372477054596, train acc: 0.8549717986212659\n",
      "Epoch 10, train loss: 0.33422601222991943, train acc: 0.8549979110089827\n",
      "Epoch 0, train loss: 0.33422479033470154, train acc: 0.8549979110089827\n",
      "Epoch 10, train loss: 0.33421164751052856, train acc: 0.8549717986212659\n",
      "Accuracy for each output state:\n",
      "0.8548412366826823\n",
      "Value 's_m_h90_val12: 0.8548412366826823' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9096153846153846\n",
      "Value 's_m_h90_val12: 0.9096153846153846' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.40123704075813293, train acc: 0.8310348514004704\n",
      "Epoch 10, train loss: 0.4012161195278168, train acc: 0.8310348514004704\n",
      "Epoch 0, train loss: 0.40121376514434814, train acc: 0.8310348514004704\n",
      "Epoch 10, train loss: 0.4011899530887604, train acc: 0.8310615779345735\n",
      "Accuracy for each output state:\n",
      "0.8310081248663673\n",
      "Value 's_m_h100_val12: 0.8310081248663673' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.895\n",
      "Value 's_m_h100_val12: 0.895' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.2291019856929779, train acc: 0.9002633458311016\n",
      "Epoch 10, train loss: 0.22909964621067047, train acc: 0.9002633458311016\n",
      "Epoch 0, train loss: 0.22909784317016602, train acc: 0.9002633458311016\n",
      "Epoch 10, train loss: 0.22907237708568573, train acc: 0.9002856632744153\n",
      "Accuracy for each output state:\n",
      "0.8998393144081414\n",
      "Value 's_m_h10_val13: 0.8998393144081414' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8808262711864407\n",
      "Value 's_m_h10_val13: 0.8808262711864407' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.20424872636795044, train acc: 0.9127663449280641\n",
      "Epoch 10, train loss: 0.20422504842281342, train acc: 0.9127891094518302\n",
      "Epoch 0, train loss: 0.2042226940393448, train acc: 0.9127891094518302\n",
      "Epoch 10, train loss: 0.20419928431510925, train acc: 0.9128118739755964\n",
      "Accuracy for each output state:\n",
      "0.9127663449280641\n",
      "Value 's_m_h20_val13: 0.9127663449280641' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8896103896103896\n",
      "Value 's_m_h20_val13: 0.8896103896103896' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.18482212722301483, train acc: 0.9245493402713251\n",
      "Epoch 10, train loss: 0.18480592966079712, train acc: 0.9245958000371678\n",
      "Epoch 0, train loss: 0.18480436503887177, train acc: 0.9245958000371678\n",
      "Epoch 10, train loss: 0.1847894787788391, train acc: 0.9245725701542464\n",
      "Accuracy for each output state:\n",
      "0.9245725701542464\n",
      "Value 's_m_h30_val13: 0.9245725701542464' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9048672566371682\n",
      "Value 's_m_h30_val13: 0.9048672566371682' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.17710602283477783, train acc: 0.9303263137924492\n",
      "Epoch 10, train loss: 0.17709630727767944, train acc: 0.9303500284575982\n",
      "Epoch 0, train loss: 0.17709536850452423, train acc: 0.9303500284575982\n",
      "Epoch 10, train loss: 0.17708653211593628, train acc: 0.9303737431227471\n",
      "Accuracy for each output state:\n",
      "0.9303737431227471\n",
      "Value 's_m_h40_val13: 0.9303737431227471' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9117647058823529\n",
      "Value 's_m_h40_val13: 0.9117647058823529' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.183392733335495, train acc: 0.9252325130788607\n",
      "Epoch 10, train loss: 0.18338701128959656, train acc: 0.9252325130788607\n",
      "Epoch 0, train loss: 0.18338645994663239, train acc: 0.9252325130788607\n",
      "Epoch 10, train loss: 0.18338115513324738, train acc: 0.9252082929664793\n",
      "Accuracy for each output state:\n",
      "0.9253051734160047\n",
      "Value 's_m_h50_val13: 0.9253051734160047' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9282407407407407\n",
      "Value 's_m_h50_val13: 0.9282407407407407' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.19825397431850433, train acc: 0.9152890516729361\n",
      "Epoch 10, train loss: 0.19825033843517303, train acc: 0.9152890516729361\n",
      "Epoch 0, train loss: 0.1982499659061432, train acc: 0.9152890516729361\n",
      "Epoch 10, train loss: 0.1982463002204895, train acc: 0.9153137992476738\n",
      "Accuracy for each output state:\n",
      "0.9153880419718867\n",
      "Value 's_m_h60_val13: 0.9153880419718867' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9330568720379147\n",
      "Value 's_m_h60_val13: 0.9330568720379147' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.22974996268749237, train acc: 0.8983758348512447\n",
      "Epoch 10, train loss: 0.2297465056180954, train acc: 0.8983758348512447\n",
      "Epoch 0, train loss: 0.22974616289138794, train acc: 0.8983758348512447\n",
      "Epoch 10, train loss: 0.22974222898483276, train acc: 0.8983758348512447\n",
      "Accuracy for each output state:\n",
      "0.8983758348512447\n",
      "Value 's_m_h70_val13: 0.8983758348512447' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9326456310679612\n",
      "Value 's_m_h70_val13: 0.9326456310679612' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.2748066186904907, train acc: 0.8780273235355\n",
      "Epoch 10, train loss: 0.27480095624923706, train acc: 0.8780273235355\n",
      "Epoch 0, train loss: 0.2748003304004669, train acc: 0.8780273235355\n",
      "Epoch 10, train loss: 0.2747935950756073, train acc: 0.8780273235355\n",
      "Accuracy for each output state:\n",
      "0.8779496998551025\n",
      "Value 's_m_h80_val13: 0.8779496998551025' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9060945273631841\n",
      "Value 's_m_h80_val13: 0.9060945273631841' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.3295125961303711, train acc: 0.855909764880322\n",
      "Epoch 10, train loss: 0.3295017182826996, train acc: 0.855909764880322\n",
      "Epoch 0, train loss: 0.3295004963874817, train acc: 0.8558832874391019\n",
      "Epoch 10, train loss: 0.32948780059814453, train acc: 0.8558832874391019\n",
      "Accuracy for each output state:\n",
      "0.8558832874391019\n",
      "Value 's_m_h90_val13: 0.8558832874391019' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8737244897959184\n",
      "Value 's_m_h90_val13: 0.8737244897959184' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.3950546383857727, train acc: 0.832411624376491\n",
      "Epoch 10, train loss: 0.3950342535972595, train acc: 0.832411624376491\n",
      "Epoch 0, train loss: 0.3950320780277252, train acc: 0.832411624376491\n",
      "Epoch 10, train loss: 0.39500877261161804, train acc: 0.832411624376491\n",
      "Accuracy for each output state:\n",
      "0.832438733463457\n",
      "Value 's_m_h100_val13: 0.832438733463457' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8383507853403142\n",
      "Value 's_m_h100_val13: 0.8383507853403142' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.23108655214309692, train acc: 0.899486162444785\n",
      "Epoch 10, train loss: 0.23108401894569397, train acc: 0.899486162444785\n",
      "Epoch 0, train loss: 0.23108215630054474, train acc: 0.899486162444785\n",
      "Epoch 10, train loss: 0.2310558557510376, train acc: 0.8994636257099071\n",
      "Accuracy for each output state:\n",
      "0.8987875236635716\n",
      "Value 's_m_h10_val14: 0.8987875236635716' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9259896729776247\n",
      "Value 's_m_h10_val14: 0.9259896729776247' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.2064153403043747, train acc: 0.9120068058493516\n",
      "Epoch 10, train loss: 0.2063906490802765, train acc: 0.9120297985836475\n",
      "Epoch 0, train loss: 0.2063881903886795, train acc: 0.9120297985836475\n",
      "Epoch 10, train loss: 0.2063637673854828, train acc: 0.9120297985836475\n",
      "Accuracy for each output state:\n",
      "0.9120987767865354\n",
      "Value 's_m_h20_val14: 0.9120987767865354' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9290718038528897\n",
      "Value 's_m_h20_val14: 0.9290718038528897' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.1865864396095276, train acc: 0.9240120153947244\n",
      "Epoch 10, train loss: 0.1865694373846054, train acc: 0.9240354829625458\n",
      "Epoch 0, train loss: 0.18656785786151886, train acc: 0.9240354829625458\n",
      "Epoch 10, train loss: 0.18655221164226532, train acc: 0.9240354829625458\n",
      "Accuracy for each output state:\n",
      "0.9240589505303669\n",
      "Value 's_m_h30_val14: 0.9240589505303669' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9376114081996435\n",
      "Value 's_m_h30_val14: 0.9376114081996435' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.17888736724853516, train acc: 0.9293348030288507\n",
      "Epoch 10, train loss: 0.17887718975543976, train acc: 0.9293587654557653\n",
      "Epoch 0, train loss: 0.17887623608112335, train acc: 0.9293587654557653\n",
      "Epoch 10, train loss: 0.17886695265769958, train acc: 0.9293108406019361\n",
      "Accuracy for each output state:\n",
      "0.9292868781750216\n",
      "Value 's_m_h40_val14: 0.9292868781750216' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9496370235934664\n",
      "Value 's_m_h40_val14: 0.9496370235934664' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.1844952553510666, train acc: 0.9239204934886909\n",
      "Epoch 10, train loss: 0.18448925018310547, train acc: 0.9239204934886909\n",
      "Epoch 0, train loss: 0.1844886690378189, train acc: 0.9239204934886909\n",
      "Epoch 10, train loss: 0.1844831109046936, train acc: 0.9239204934886909\n",
      "Accuracy for each output state:\n",
      "0.9238470576715949\n",
      "Value 's_m_h50_val14: 0.9238470576715949' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9537892791127541\n",
      "Value 's_m_h50_val14: 0.9537892791127541' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.199176624417305, train acc: 0.915390773541479\n",
      "Epoch 10, train loss: 0.1991727650165558, train acc: 0.915390773541479\n",
      "Epoch 0, train loss: 0.19917237758636475, train acc: 0.915390773541479\n",
      "Epoch 10, train loss: 0.19916845858097076, train acc: 0.915390773541479\n",
      "Accuracy for each output state:\n",
      "0.9153407385169618\n",
      "Value 's_m_h60_val14: 0.9153407385169618' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9369114877589453\n",
      "Value 's_m_h60_val14: 0.9369114877589453' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.23057100176811218, train acc: 0.8992632763736826\n",
      "Epoch 10, train loss: 0.2305673211812973, train acc: 0.8992632763736826\n",
      "Epoch 0, train loss: 0.23056691884994507, train acc: 0.8992632763736826\n",
      "Epoch 10, train loss: 0.2305627316236496, train acc: 0.8992632763736826\n",
      "Accuracy for each output state:\n",
      "0.8992376956922132\n",
      "Value 's_m_h70_val14: 0.8992376956922132' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9141074856046065\n",
      "Value 's_m_h70_val14: 0.9141074856046065' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.2767852544784546, train acc: 0.8782057992253742\n",
      "Epoch 10, train loss: 0.2767792046070099, train acc: 0.8782057992253742\n",
      "Epoch 0, train loss: 0.27677854895591736, train acc: 0.8782057992253742\n",
      "Epoch 10, train loss: 0.2767713963985443, train acc: 0.8782057992253742\n",
      "Accuracy for each output state:\n",
      "0.8780749502773999\n",
      "Value 's_m_h80_val14: 0.8780749502773999' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8933463796477494\n",
      "Value 's_m_h80_val14: 0.8933463796477494' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.3342789113521576, train acc: 0.8548162434372656\n",
      "Epoch 10, train loss: 0.3342672884464264, train acc: 0.8548162434372656\n",
      "Epoch 0, train loss: 0.3342660069465637, train acc: 0.8548162434372656\n",
      "Epoch 10, train loss: 0.33425235748291016, train acc: 0.8548698167791707\n",
      "Accuracy for each output state:\n",
      "0.854682310082503\n",
      "Value 's_m_h90_val14: 0.854682310082503' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.877744510978044\n",
      "Value 's_m_h90_val14: 0.877744510978044' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.40296226739883423, train acc: 0.8305991440798859\n",
      "Epoch 10, train loss: 0.4029403030872345, train acc: 0.8305991440798859\n",
      "Epoch 0, train loss: 0.4029379189014435, train acc: 0.8305991440798859\n",
      "Epoch 10, train loss: 0.4029129445552826, train acc: 0.8305991440798859\n",
      "Accuracy for each output state:\n",
      "0.8305991440798859\n",
      "Value 's_m_h100_val14: 0.8305991440798859' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8615071283095723\n",
      "Value 's_m_h100_val14: 0.8615071283095723' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.23118574917316437, train acc: 0.8982289188474756\n",
      "Epoch 10, train loss: 0.23118360340595245, train acc: 0.8982289188474756\n",
      "Epoch 0, train loss: 0.23118169605731964, train acc: 0.8982289188474756\n",
      "Epoch 10, train loss: 0.2311549037694931, train acc: 0.8982289188474756\n",
      "Accuracy for each output state:\n",
      "0.897898493259318\n",
      "Value 's_m_h10_val15: 0.897898493259318' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9584615384615384\n",
      "Value 's_m_h10_val15: 0.9584615384615384' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.2080138623714447, train acc: 0.90971785425465\n",
      "Epoch 10, train loss: 0.20798838138580322, train acc: 0.9097403180878785\n",
      "Epoch 0, train loss: 0.20798583328723907, train acc: 0.9097403180878785\n",
      "Epoch 10, train loss: 0.20796042680740356, train acc: 0.9097403180878785\n",
      "Accuracy for each output state:\n",
      "0.9097852457543356\n",
      "Value 's_m_h20_val15: 0.9097852457543356' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.980952380952381\n",
      "Value 's_m_h20_val15: 0.980952380952381' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.1884395182132721, train acc: 0.9215097625813549\n",
      "Epoch 10, train loss: 0.1884218156337738, train acc: 0.9215555962966359\n",
      "Epoch 0, train loss: 0.1884201616048813, train acc: 0.9215555962966359\n",
      "Epoch 10, train loss: 0.18840396404266357, train acc: 0.9215555962966359\n",
      "Accuracy for each output state:\n",
      "0.9216701805848383\n",
      "Value 's_m_h30_val15: 0.9216701805848383' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9868852459016393\n",
      "Value 's_m_h30_val15: 0.9868852459016393' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.18058831989765167, train acc: 0.9270745626344841\n",
      "Epoch 10, train loss: 0.18057797849178314, train acc: 0.9270745626344841\n",
      "Epoch 0, train loss: 0.18057698011398315, train acc: 0.9270745626344841\n",
      "Epoch 10, train loss: 0.1805676817893982, train acc: 0.9270979511647488\n",
      "Accuracy for each output state:\n",
      "0.9270511741042192\n",
      "Value 's_m_h40_val15: 0.9270511741042192' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9906779661016949\n",
      "Value 's_m_h40_val15: 0.9906779661016949' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.1863606721162796, train acc: 0.9231063138790715\n",
      "Epoch 10, train loss: 0.1863550841808319, train acc: 0.9231301939058172\n",
      "Epoch 0, train loss: 0.18635456264019012, train acc: 0.9231301939058172\n",
      "Epoch 10, train loss: 0.18634946644306183, train acc: 0.9231301939058172\n",
      "Accuracy for each output state:\n",
      "0.9232018339860539\n",
      "Value 's_m_h50_val15: 0.9232018339860539' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9982456140350877\n",
      "Value 's_m_h50_val15: 0.9982456140350877' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.20177635550498962, train acc: 0.9141379646794809\n",
      "Epoch 10, train loss: 0.20177321135997772, train acc: 0.9141379646794809\n",
      "Epoch 0, train loss: 0.20177289843559265, train acc: 0.9141379646794809\n",
      "Epoch 10, train loss: 0.20176975429058075, train acc: 0.9141379646794809\n",
      "Accuracy for each output state:\n",
      "0.9141135720558102\n",
      "Value 's_m_h60_val15: 0.9141135720558102' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9954545454545455\n",
      "Value 's_m_h60_val15: 0.9954545454545455' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.23438088595867157, train acc: 0.8972729085651611\n",
      "Epoch 10, train loss: 0.23437799513339996, train acc: 0.8972729085651611\n",
      "Epoch 0, train loss: 0.2343776822090149, train acc: 0.8972729085651611\n",
      "Epoch 10, train loss: 0.23437416553497314, train acc: 0.8972729085651611\n",
      "Accuracy for each output state:\n",
      "0.8972978362748031\n",
      "Value 's_m_h70_val15: 0.8972978362748031' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9952830188679245\n",
      "Value 's_m_h70_val15: 0.9952830188679245' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.2812267243862152, train acc: 0.8758028341319196\n",
      "Epoch 10, train loss: 0.2812213897705078, train acc: 0.8758028341319196\n",
      "Epoch 0, train loss: 0.28122079372406006, train acc: 0.8758028341319196\n",
      "Epoch 10, train loss: 0.2812142074108124, train acc: 0.8758283209297584\n",
      "Accuracy for each output state:\n",
      "0.8758028341319196\n",
      "Value 's_m_h80_val15: 0.8758028341319196' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.996078431372549\n",
      "Value 's_m_h80_val15: 0.996078431372549' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.33840715885162354, train acc: 0.8528261549692355\n",
      "Epoch 10, train loss: 0.3383961617946625, train acc: 0.8528261549692355\n",
      "Epoch 0, train loss: 0.3383949100971222, train acc: 0.8528261549692355\n",
      "Epoch 10, train loss: 0.3383818566799164, train acc: 0.8528261549692355\n",
      "Accuracy for each output state:\n",
      "0.8528261549692356\n",
      "Value 's_m_h90_val15: 0.8528261549692356' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.996938775510204\n",
      "Value 's_m_h90_val15: 0.996938775510204' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.4067789316177368, train acc: 0.8282634219233643\n",
      "Epoch 10, train loss: 0.4067576825618744, train acc: 0.8282901056676273\n",
      "Epoch 0, train loss: 0.40675535798072815, train acc: 0.8282901056676273\n",
      "Epoch 10, train loss: 0.406730979681015, train acc: 0.8282901056676273\n",
      "Accuracy for each output state:\n",
      "0.8283701569004163\n",
      "Value 's_m_h100_val15: 0.8283701569004163' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9968085106382979\n",
      "Value 's_m_h100_val15: 0.9968085106382979' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.23143576085567474, train acc: 0.9005156950672646\n",
      "Epoch 10, train loss: 0.23143282532691956, train acc: 0.9005156950672646\n",
      "Epoch 0, train loss: 0.2314308136701584, train acc: 0.9005156950672646\n",
      "Epoch 10, train loss: 0.23140262067317963, train acc: 0.9005156950672646\n",
      "Accuracy for each output state:\n",
      "0.9002242152466368\n",
      "Value 's_m_h10_val16: 0.9002242152466368' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9126908396946565\n",
      "Value 's_m_h10_val16: 0.9126908396946565' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.20643861591815948, train acc: 0.912419945105215\n",
      "Epoch 10, train loss: 0.2064119130373001, train acc: 0.9124428179322964\n",
      "Epoch 0, train loss: 0.2064092606306076, train acc: 0.9124428179322964\n",
      "Epoch 10, train loss: 0.2063829004764557, train acc: 0.9124428179322964\n",
      "Accuracy for each output state:\n",
      "0.9125114364135407\n",
      "Value 's_m_h20_val16: 0.9125114364135407' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9173151750972762\n",
      "Value 's_m_h20_val16: 0.9173151750972762' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.185777947306633, train acc: 0.9247198879551821\n",
      "Epoch 10, train loss: 0.1857595592737198, train acc: 0.9247198879551821\n",
      "Epoch 0, train loss: 0.1857578456401825, train acc: 0.9247432306255836\n",
      "Epoch 10, train loss: 0.18574100732803345, train acc: 0.9247432306255836\n",
      "Accuracy for each output state:\n",
      "0.9247899159663865\n",
      "Value 's_m_h30_val16: 0.9247899159663865' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9161706349206349\n",
      "Value 's_m_h30_val16: 0.9161706349206349' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.17693041265010834, train acc: 0.9311963775023833\n",
      "Epoch 10, train loss: 0.1769195944070816, train acc: 0.9311963775023833\n",
      "Epoch 0, train loss: 0.17691858112812042, train acc: 0.9311963775023833\n",
      "Epoch 10, train loss: 0.17690882086753845, train acc: 0.9311963775023833\n",
      "Accuracy for each output state:\n",
      "0.9312202097235462\n",
      "Value 's_m_h40_val16: 0.9312202097235462' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.909919028340081\n",
      "Value 's_m_h40_val16: 0.909919028340081' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.1815698742866516, train acc: 0.9271178188899708\n",
      "Epoch 10, train loss: 0.18156388401985168, train acc: 0.9271178188899708\n",
      "Epoch 0, train loss: 0.1815633475780487, train acc: 0.9271178188899708\n",
      "Epoch 10, train loss: 0.1815578192472458, train acc: 0.9271178188899708\n",
      "Accuracy for each output state:\n",
      "0.9271665043816942\n",
      "Value 's_m_h50_val16: 0.9271665043816942' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8868801652892563\n",
      "Value 's_m_h50_val16: 0.8868801652892563' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.19564609229564667, train acc: 0.9196019900497513\n",
      "Epoch 10, train loss: 0.19564273953437805, train acc: 0.9196019900497513\n",
      "Epoch 0, train loss: 0.1956424117088318, train acc: 0.9196019900497513\n",
      "Epoch 10, train loss: 0.19563913345336914, train acc: 0.9196019900497513\n",
      "Accuracy for each output state:\n",
      "0.9195771144278606\n",
      "Value 's_m_h60_val16: 0.9195771144278606' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8586497890295359\n",
      "Value 's_m_h60_val16: 0.8586497890295359' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.22574463486671448, train acc: 0.903560528992879\n",
      "Epoch 10, train loss: 0.22574183344841003, train acc: 0.903560528992879\n",
      "Epoch 0, train loss: 0.22574150562286377, train acc: 0.903560528992879\n",
      "Epoch 10, train loss: 0.2257382869720459, train acc: 0.903560528992879\n",
      "Accuracy for each output state:\n",
      "0.9035096642929806\n",
      "Value 's_m_h70_val16: 0.9035096642929806' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8286637931034483\n",
      "Value 's_m_h70_val16: 0.8286637931034483' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.2697638273239136, train acc: 0.882570239334027\n",
      "Epoch 10, train loss: 0.2697591185569763, train acc: 0.882570239334027\n",
      "Epoch 0, train loss: 0.26975852251052856, train acc: 0.882570239334027\n",
      "Epoch 10, train loss: 0.26975274085998535, train acc: 0.8825962539021852\n",
      "Accuracy for each output state:\n",
      "0.8826222684703434\n",
      "Value 's_m_h80_val16: 0.8826222684703434' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8001101321585904\n",
      "Value 's_m_h80_val16: 0.8001101321585904' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.3243769109249115, train acc: 0.8598509052183173\n",
      "Epoch 10, train loss: 0.3243672251701355, train acc: 0.8598242811501597\n",
      "Epoch 0, train loss: 0.32436615228652954, train acc: 0.8598242811501597\n",
      "Epoch 10, train loss: 0.3243546485900879, train acc: 0.859877529286475\n",
      "Accuracy for each output state:\n",
      "0.8598509052183173\n",
      "Value 's_m_h90_val16: 0.8598509052183173' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.7792792792792793\n",
      "Value 's_m_h90_val16: 0.7792792792792793' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.38999608159065247, train acc: 0.8362322791712105\n",
      "Epoch 10, train loss: 0.3899773359298706, train acc: 0.8362050163576881\n",
      "Epoch 0, train loss: 0.3899752199649811, train acc: 0.8362050163576881\n",
      "Epoch 10, train loss: 0.38995349407196045, train acc: 0.8362050163576881\n",
      "Accuracy for each output state:\n",
      "0.8362322791712105\n",
      "Value 's_m_h100_val16: 0.8362322791712105' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.7494239631336406\n",
      "Value 's_m_h100_val16: 0.7494239631336406' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.22962217032909393, train acc: 0.8986191860465116\n",
      "Epoch 10, train loss: 0.2296176254749298, train acc: 0.8986191860465116\n",
      "Epoch 0, train loss: 0.22961558401584625, train acc: 0.8986191860465116\n",
      "Epoch 10, train loss: 0.22958756983280182, train acc: 0.8986191860465116\n",
      "Accuracy for each output state:\n",
      "0.898414789244186\n",
      "Value 's_m_h10_val17: 0.898414789244186' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9155405405405406\n",
      "Value 's_m_h10_val17: 0.9155405405405406' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.20413288474082947, train acc: 0.9120087133852428\n",
      "Epoch 10, train loss: 0.20410722494125366, train acc: 0.9120087133852428\n",
      "Epoch 0, train loss: 0.2041046917438507, train acc: 0.9120087133852428\n",
      "Epoch 10, train loss: 0.20407947897911072, train acc: 0.9120318872821653\n",
      "Accuracy for each output state:\n",
      "0.9120782350760104\n",
      "Value 's_m_h20_val17: 0.9120782350760104' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9066310975609757\n",
      "Value 's_m_h20_val17: 0.9066310975609757' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.18354886770248413, train acc: 0.9238029901589705\n",
      "Epoch 10, train loss: 0.18353159725666046, train acc: 0.9238029901589705\n",
      "Epoch 0, train loss: 0.18352997303009033, train acc: 0.9238029901589705\n",
      "Epoch 10, train loss: 0.18351425230503082, train acc: 0.9238266464799394\n",
      "Accuracy for each output state:\n",
      "0.9238739591218774\n",
      "Value 's_m_h30_val17: 0.9238739591218774' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8978328173374615\n",
      "Value 's_m_h30_val17: 0.8978328173374615' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.1749744564294815, train acc: 0.929116737533823\n",
      "Epoch 10, train loss: 0.17496424913406372, train acc: 0.929116737533823\n",
      "Epoch 0, train loss: 0.17496328055858612, train acc: 0.929116737533823\n",
      "Epoch 10, train loss: 0.17495395243167877, train acc: 0.929116737533823\n",
      "Accuracy for each output state:\n",
      "0.9290925782759953\n",
      "Value 's_m_h40_val17: 0.9290925782759953' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8887578616352201\n",
      "Value 's_m_h40_val17: 0.8887578616352201' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.18043379485607147, train acc: 0.9251826619273301\n",
      "Epoch 10, train loss: 0.18042756617069244, train acc: 0.9251826619273301\n",
      "Epoch 0, train loss: 0.1804269552230835, train acc: 0.9251826619273301\n",
      "Epoch 10, train loss: 0.18042102456092834, train acc: 0.925207345971564\n",
      "Accuracy for each output state:\n",
      "0.9251826619273302\n",
      "Value 's_m_h50_val17: 0.9251826619273302' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8793929712460065\n",
      "Value 's_m_h50_val17: 0.8793929712460065' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.195887953042984, train acc: 0.916658255954784\n",
      "Epoch 10, train loss: 0.19588308036327362, train acc: 0.916658255954784\n",
      "Epoch 0, train loss: 0.19588257372379303, train acc: 0.916658255954784\n",
      "Epoch 10, train loss: 0.19587743282318115, train acc: 0.916658255954784\n",
      "Accuracy for each output state:\n",
      "0.9166077916834882\n",
      "Value 's_m_h60_val17: 0.9166077916834882' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8685064935064936\n",
      "Value 's_m_h60_val17: 0.8685064935064936' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.22910067439079285, train acc: 0.9003148224607762\n",
      "Epoch 10, train loss: 0.2290946990251541, train acc: 0.9003148224607762\n",
      "Epoch 0, train loss: 0.22909407317638397, train acc: 0.9003148224607762\n",
      "Epoch 10, train loss: 0.2290872186422348, train acc: 0.9003148224607762\n",
      "Accuracy for each output state:\n",
      "0.900340627580512\n",
      "Value 's_m_h70_val17: 0.900340627580512' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8514851485148515\n",
      "Value 's_m_h70_val17: 0.8514851485148515' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.27628979086875916, train acc: 0.879277566539924\n",
      "Epoch 10, train loss: 0.27627983689308167, train acc: 0.879277566539924\n",
      "Epoch 0, train loss: 0.27627870440483093, train acc: 0.879277566539924\n",
      "Epoch 10, train loss: 0.27626723051071167, train acc: 0.879277566539924\n",
      "Accuracy for each output state:\n",
      "0.8791455428812843\n",
      "Value 's_m_h80_val17: 0.8791455428812843' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8263422818791946\n",
      "Value 's_m_h80_val17: 0.8263422818791946' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.33289578557014465, train acc: 0.8565095155709342\n",
      "Epoch 10, train loss: 0.3328784704208374, train acc: 0.856482482698962\n",
      "Epoch 0, train loss: 0.3328765332698822, train acc: 0.856482482698962\n",
      "Epoch 10, train loss: 0.3328569233417511, train acc: 0.856482482698962\n",
      "Accuracy for each output state:\n",
      "0.8564554498269896\n",
      "Value 's_m_h90_val17: 0.8564554498269896' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.7982081911262798\n",
      "Value 's_m_h90_val17: 0.7982081911262798' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.40115073323249817, train acc: 0.8325210456357998\n",
      "Epoch 10, train loss: 0.40112170577049255, train acc: 0.832548737261852\n",
      "Epoch 0, train loss: 0.40111860632896423, train acc: 0.832548737261852\n",
      "Epoch 10, train loss: 0.4010864198207855, train acc: 0.832548737261852\n",
      "Accuracy for each output state:\n",
      "0.8324933540097474\n",
      "Value 's_m_h100_val17: 0.8324933540097474' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.7773437500000001\n",
      "Value 's_m_h100_val17: 0.7773437500000001' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.22877155244350433, train acc: 0.9014517278232989\n",
      "Epoch 10, train loss: 0.22877046465873718, train acc: 0.9014517278232989\n",
      "Epoch 0, train loss: 0.2287687212228775, train acc: 0.9014517278232989\n",
      "Epoch 10, train loss: 0.22874358296394348, train acc: 0.9014517278232989\n",
      "Accuracy for each output state:\n",
      "0.9008950837192733\n",
      "Value 's_m_h10_val18: 0.9008950837192733' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9103139013452914\n",
      "Value 's_m_h10_val18: 0.9103139013452914' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.20381945371627808, train acc: 0.9136309956395349\n",
      "Epoch 10, train loss: 0.20379574596881866, train acc: 0.9136309956395349\n",
      "Epoch 0, train loss: 0.20379337668418884, train acc: 0.9136309956395349\n",
      "Epoch 10, train loss: 0.20376986265182495, train acc: 0.9136309956395349\n",
      "Accuracy for each output state:\n",
      "0.9136309956395349\n",
      "Value 's_m_h20_val18: 0.9136309956395349' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9082568807339448\n",
      "Value 's_m_h20_val18: 0.9082568807339448' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.18375661969184875, train acc: 0.9248934000741564\n",
      "Epoch 10, train loss: 0.1837402582168579, train acc: 0.9248702261772339\n",
      "Epoch 0, train loss: 0.18373873829841614, train acc: 0.9248702261772339\n",
      "Epoch 10, train loss: 0.1837237924337387, train acc: 0.9248934000741564\n",
      "Accuracy for each output state:\n",
      "0.9249397478680015\n",
      "Value 's_m_h30_val18: 0.9249397478680015' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9143192488262911\n",
      "Value 's_m_h30_val18: 0.9143192488262911' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.17539097368717194, train acc: 0.9313020439061317\n",
      "Epoch 10, train loss: 0.17538118362426758, train acc: 0.9313020439061317\n",
      "Epoch 0, train loss: 0.17538028955459595, train acc: 0.9313020439061317\n",
      "Epoch 10, train loss: 0.17537130415439606, train acc: 0.9313020439061317\n",
      "Accuracy for each output state:\n",
      "0.9312310749432248\n",
      "Value 's_m_h40_val18: 0.9312310749432248' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.903846153846154\n",
      "Value 's_m_h40_val18: 0.903846153846154' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.18074968457221985, train acc: 0.9275947042906841\n",
      "Epoch 10, train loss: 0.18074379861354828, train acc: 0.9275947042906841\n",
      "Epoch 0, train loss: 0.18074321746826172, train acc: 0.9275947042906841\n",
      "Epoch 10, train loss: 0.1807376891374588, train acc: 0.9275947042906841\n",
      "Accuracy for each output state:\n",
      "0.9275222265172014\n",
      "Value 's_m_h50_val18: 0.9275222265172014' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8848522167487685\n",
      "Value 's_m_h50_val18: 0.8848522167487685' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.1955491453409195, train acc: 0.9179255529225908\n",
      "Epoch 10, train loss: 0.1955452710390091, train acc: 0.9179502369668247\n",
      "Epoch 0, train loss: 0.19554488360881805, train acc: 0.9179502369668247\n",
      "Epoch 10, train loss: 0.1955408751964569, train acc: 0.9179502369668247\n",
      "Accuracy for each output state:\n",
      "0.9179008688783571\n",
      "Value 's_m_h60_val18: 0.9179008688783571' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8680555555555556\n",
      "Value 's_m_h60_val18: 0.8680555555555556' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.22749941051006317, train acc: 0.901014331853048\n",
      "Epoch 10, train loss: 0.22749555110931396, train acc: 0.901014331853048\n",
      "Epoch 0, train loss: 0.22749510407447815, train acc: 0.901014331853048\n",
      "Epoch 10, train loss: 0.22749066352844238, train acc: 0.901014331853048\n",
      "Accuracy for each output state:\n",
      "0.9009386354461042\n",
      "Value 's_m_h70_val18: 0.9009386354461042' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8426165803108808\n",
      "Value 's_m_h70_val18: 0.8426165803108808' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.27317193150520325, train acc: 0.8799287778695293\n",
      "Epoch 10, train loss: 0.27316567301750183, train acc: 0.8799287778695293\n",
      "Epoch 0, train loss: 0.2731649875640869, train acc: 0.8799287778695293\n",
      "Epoch 10, train loss: 0.27315759658813477, train acc: 0.8799545829892651\n",
      "Accuracy for each output state:\n",
      "0.8799803881090009\n",
      "Value 's_m_h80_val18: 0.8799803881090009' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8105053191489362\n",
      "Value 's_m_h80_val18: 0.8105053191489362' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.3282642066478729, train acc: 0.857256020278834\n",
      "Epoch 10, train loss: 0.32825252413749695, train acc: 0.857256020278834\n",
      "Epoch 0, train loss: 0.3282512426376343, train acc: 0.857256020278834\n",
      "Epoch 10, train loss: 0.3282376825809479, train acc: 0.857256020278834\n",
      "Accuracy for each output state:\n",
      "0.857256020278834\n",
      "Value 's_m_h90_val18: 0.857256020278834' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.7766393442622951\n",
      "Value 's_m_h90_val18: 0.7766393442622951' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.3933984637260437, train acc: 0.8341262975778547\n",
      "Epoch 10, train loss: 0.39337724447250366, train acc: 0.8341262975778547\n",
      "Epoch 0, train loss: 0.3933749198913574, train acc: 0.8341262975778547\n",
      "Epoch 10, train loss: 0.39335083961486816, train acc: 0.8341262975778547\n",
      "Accuracy for each output state:\n",
      "0.834153330449827\n",
      "Value 's_m_h100_val18: 0.834153330449827' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.7415730337078652\n",
      "Value 's_m_h100_val18: 0.7415730337078652' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.22954465448856354, train acc: 0.9000402612507828\n",
      "Epoch 10, train loss: 0.22954173386096954, train acc: 0.9000402612507828\n",
      "Epoch 0, train loss: 0.2295396775007248, train acc: 0.9000402612507828\n",
      "Epoch 10, train loss: 0.22951149940490723, train acc: 0.9000626286123289\n",
      "Accuracy for each output state:\n",
      "0.9000178938892368\n",
      "Value 's_m_h10_val19: 0.9000178938892368' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8762575452716297\n",
      "Value 's_m_h10_val19: 0.8762575452716297' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.20518708229064941, train acc: 0.9119056311034042\n",
      "Epoch 10, train loss: 0.20516031980514526, train acc: 0.9119284475677649\n",
      "Epoch 0, train loss: 0.20515766739845276, train acc: 0.9119056311034042\n",
      "Epoch 10, train loss: 0.20513129234313965, train acc: 0.9119056311034042\n",
      "Accuracy for each output state:\n",
      "0.9119512640321257\n",
      "Value 's_m_h20_val19: 0.9119512640321257' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8814168377823408\n",
      "Value 's_m_h20_val19: 0.8814168377823408' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.18529541790485382, train acc: 0.9243270932290212\n",
      "Epoch 10, train loss: 0.18527695536613464, train acc: 0.9243270932290212\n",
      "Epoch 0, train loss: 0.18527522683143616, train acc: 0.9243270932290212\n",
      "Epoch 10, train loss: 0.1852584183216095, train acc: 0.9243270932290212\n",
      "Accuracy for each output state:\n",
      "0.9241873894011361\n",
      "Value 's_m_h30_val19: 0.9241873894011361' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8867924528301887\n",
      "Value 's_m_h30_val19: 0.8867924528301887' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.17743639647960663, train acc: 0.9297803556147191\n",
      "Epoch 10, train loss: 0.17742562294006348, train acc: 0.9298041266520871\n",
      "Epoch 0, train loss: 0.1774245947599411, train acc: 0.9298041266520871\n",
      "Epoch 10, train loss: 0.1774149239063263, train acc: 0.9298041266520871\n",
      "Accuracy for each output state:\n",
      "0.9297803556147191\n",
      "Value 's_m_h40_val19: 0.9297803556147191' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8923982869379015\n",
      "Value 's_m_h40_val19: 0.8923982869379015' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.1832967847585678, train acc: 0.9257793532096728\n",
      "Epoch 10, train loss: 0.1832910031080246, train acc: 0.9257793532096728\n",
      "Epoch 0, train loss: 0.1832904815673828, train acc: 0.9257793532096728\n",
      "Epoch 10, train loss: 0.18328523635864258, train acc: 0.9258036321258619\n",
      "Accuracy for each output state:\n",
      "0.9257550742934836\n",
      "Value 's_m_h50_val19: 0.9257550742934836' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9004376367614879\n",
      "Value 's_m_h50_val19: 0.9004376367614879' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.19894129037857056, train acc: 0.9158479706261784\n",
      "Epoch 10, train loss: 0.19893817603588104, train acc: 0.9158479706261784\n",
      "Epoch 0, train loss: 0.19893786311149597, train acc: 0.9158479706261784\n",
      "Epoch 10, train loss: 0.19893474876880646, train acc: 0.9158727795971023\n",
      "Accuracy for each output state:\n",
      "0.9158727795971023\n",
      "Value 's_m_h60_val19: 0.9158727795971023' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9093959731543624\n",
      "Value 's_m_h60_val19: 0.9093959731543624' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.22979624569416046, train acc: 0.8998934767170539\n",
      "Epoch 10, train loss: 0.22979341447353363, train acc: 0.8998934767170539\n",
      "Epoch 0, train loss: 0.22979310154914856, train acc: 0.8998934767170539\n",
      "Epoch 10, train loss: 0.22978967428207397, train acc: 0.8998934767170539\n",
      "Accuracy for each output state:\n",
      "0.8997666632849751\n",
      "Value 's_m_h70_val19: 0.8997666632849751' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8987414187643021\n",
      "Value 's_m_h70_val19: 0.8987414187643021' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.274787038564682, train acc: 0.8789042233060081\n",
      "Epoch 10, train loss: 0.27478158473968506, train acc: 0.8789042233060081\n",
      "Epoch 0, train loss: 0.2747809588909149, train acc: 0.8789042233060081\n",
      "Epoch 10, train loss: 0.2747741937637329, train acc: 0.8789042233060081\n",
      "Accuracy for each output state:\n",
      "0.8788782816229117\n",
      "Value 's_m_h80_val19: 0.8788782816229117' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8852459016393442\n",
      "Value 's_m_h80_val19: 0.8852459016393442' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.3302057683467865, train acc: 0.8562174790272911\n",
      "Epoch 10, train loss: 0.3301942050457001, train acc: 0.8562174790272911\n",
      "Epoch 0, train loss: 0.330192893743515, train acc: 0.8562174790272911\n",
      "Epoch 10, train loss: 0.3301790654659271, train acc: 0.8562174790272911\n",
      "Accuracy for each output state:\n",
      "0.8561112880959966\n",
      "Value 's_m_h90_val19: 0.8561112880959966' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.86810551558753\n",
      "Value 's_m_h90_val19: 0.86810551558753' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.3968087136745453, train acc: 0.8322550831792976\n",
      "Epoch 10, train loss: 0.39678624272346497, train acc: 0.8322822659562901\n",
      "Epoch 0, train loss: 0.3967837989330292, train acc: 0.8322822659562901\n",
      "Epoch 10, train loss: 0.3967580497264862, train acc: 0.8323094487332826\n",
      "Accuracy for each output state:\n",
      "0.8322007176253127\n",
      "Value 's_m_h100_val19: 0.8322007176253127' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8402948402948404\n",
      "Value 's_m_h100_val19: 0.8402948402948404' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.23485782742500305, train acc: 0.897499775563336\n",
      "Epoch 10, train loss: 0.23485447466373444, train acc: 0.897499775563336\n",
      "Epoch 0, train loss: 0.23485229909420013, train acc: 0.897499775563336\n",
      "Epoch 10, train loss: 0.23482228815555573, train acc: 0.8975222192297334\n",
      "Accuracy for each output state:\n",
      "0.8971855642337733\n",
      "Value 's_m_h10_val20: 0.8971855642337733' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9654205607476636\n",
      "Value 's_m_h10_val20: 0.9654205607476636' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.2110034078359604, train acc: 0.9091033977470464\n",
      "Epoch 10, train loss: 0.21097570657730103, train acc: 0.9091033977470464\n",
      "Epoch 0, train loss: 0.21097296476364136, train acc: 0.9091033977470464\n",
      "Epoch 10, train loss: 0.210945725440979, train acc: 0.9091033977470464\n",
      "Accuracy for each output state:\n",
      "0.9091720853558019\n",
      "Value 's_m_h20_val20: 0.9091720853558019' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9742857142857143\n",
      "Value 's_m_h20_val20: 0.9742857142857143' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.19104422628879547, train acc: 0.9204598560613142\n",
      "Epoch 10, train loss: 0.191025510430336, train acc: 0.9204832227310964\n",
      "Epoch 0, train loss: 0.19102375209331512, train acc: 0.9204832227310964\n",
      "Epoch 10, train loss: 0.191006600856781, train acc: 0.9204832227310964\n",
      "Accuracy for each output state:\n",
      "0.9204598560613141\n",
      "Value 's_m_h30_val20: 0.9204598560613141' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.979126213592233\n",
      "Value 's_m_h30_val20: 0.979126213592233' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.1828612983226776, train acc: 0.9260425613131024\n",
      "Epoch 10, train loss: 0.18285030126571655, train acc: 0.9260425613131024\n",
      "Epoch 0, train loss: 0.18284928798675537, train acc: 0.9260425613131024\n",
      "Epoch 10, train loss: 0.18283933401107788, train acc: 0.9260425613131024\n",
      "Accuracy for each output state:\n",
      "0.9260425613131024\n",
      "Value 's_m_h40_val20: 0.9260425613131024' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9762376237623762\n",
      "Value 's_m_h40_val20: 0.9762376237623762' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.1879560947418213, train acc: 0.9226776488936543\n",
      "Epoch 10, train loss: 0.18794982135295868, train acc: 0.9226776488936543\n",
      "Epoch 0, train loss: 0.18794921040534973, train acc: 0.9226776488936543\n",
      "Epoch 10, train loss: 0.18794339895248413, train acc: 0.9226776488936543\n",
      "Accuracy for each output state:\n",
      "0.9227020177405205\n",
      "Value 's_m_h50_val20: 0.9227020177405205' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9671717171717171\n",
      "Value 's_m_h50_val20: 0.9671717171717171' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.20213893055915833, train acc: 0.9137364279310688\n",
      "Epoch 10, train loss: 0.20213496685028076, train acc: 0.9137364279310688\n",
      "Epoch 0, train loss: 0.20213454961776733, train acc: 0.9137364279310688\n",
      "Epoch 10, train loss: 0.2021305412054062, train acc: 0.9137364279310688\n",
      "Accuracy for each output state:\n",
      "0.9136866221735234\n",
      "Value 's_m_h60_val20: 0.9136866221735234' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9572164948453608\n",
      "Value 's_m_h60_val20: 0.9572164948453608' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.23354807496070862, train acc: 0.8975201140645687\n",
      "Epoch 10, train loss: 0.23354417085647583, train acc: 0.8975201140645687\n",
      "Epoch 0, train loss: 0.23354372382164001, train acc: 0.8975201140645687\n",
      "Epoch 10, train loss: 0.23353922367095947, train acc: 0.8975201140645687\n",
      "Accuracy for each output state:\n",
      "0.8975201140645688\n",
      "Value 's_m_h70_val20: 0.8975201140645688' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9457894736842105\n",
      "Value 's_m_h70_val20: 0.9457894736842105' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.2797899842262268, train acc: 0.8763152411709553\n",
      "Epoch 10, train loss: 0.2797832489013672, train acc: 0.8763152411709553\n",
      "Epoch 0, train loss: 0.2797824740409851, train acc: 0.8763152411709553\n",
      "Epoch 10, train loss: 0.27977442741394043, train acc: 0.8763152411709553\n",
      "Accuracy for each output state:\n",
      "0.8763412855505781\n",
      "Value 's_m_h80_val20: 0.8763412855505781' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9338709677419355\n",
      "Value 's_m_h80_val20: 0.9338709677419355' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.3367246389389038, train acc: 0.8533159185414223\n",
      "Epoch 10, train loss: 0.33671167492866516, train acc: 0.8533159185414223\n",
      "Epoch 0, train loss: 0.33671024441719055, train acc: 0.8533159185414223\n",
      "Epoch 10, train loss: 0.33669513463974, train acc: 0.8533159185414223\n",
      "Accuracy for each output state:\n",
      "0.853209297366457\n",
      "Value 's_m_h90_val20: 0.853209297366457' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.921978021978022\n",
      "Value 's_m_h90_val20: 0.921978021978022' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.40483126044273376, train acc: 0.8290206354405503\n",
      "Epoch 10, train loss: 0.4048076570034027, train acc: 0.8290206354405503\n",
      "Epoch 0, train loss: 0.4048050343990326, train acc: 0.8290206354405503\n",
      "Epoch 10, train loss: 0.404778391122818, train acc: 0.8290206354405503\n",
      "Accuracy for each output state:\n",
      "0.8289933398842668\n",
      "Value 's_m_h100_val20: 0.8289933398842668' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9089887640449439\n",
      "Value 's_m_h100_val20: 0.9089887640449439' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.23178718984127045, train acc: 0.9007416507416507\n",
      "Epoch 10, train loss: 0.23178525269031525, train acc: 0.9007416507416507\n",
      "Epoch 0, train loss: 0.23178336024284363, train acc: 0.9007416507416507\n",
      "Epoch 10, train loss: 0.23175670206546783, train acc: 0.9007416507416507\n",
      "Accuracy for each output state:\n",
      "0.9002184002184003\n",
      "Value 's_m_h10_val21: 0.9002184002184003' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9306569343065694\n",
      "Value 's_m_h10_val21: 0.9306569343065694' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.20681919157505035, train acc: 0.911598105673693\n",
      "Epoch 10, train loss: 0.20679379999637604, train acc: 0.911598105673693\n",
      "Epoch 0, train loss: 0.2067912518978119, train acc: 0.911598105673693\n",
      "Epoch 10, train loss: 0.20676614344120026, train acc: 0.911598105673693\n",
      "Accuracy for each output state:\n",
      "0.9115052465409973\n",
      "Value 's_m_h20_val21: 0.9115052465409973' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9325925925925926\n",
      "Value 's_m_h20_val21: 0.9325925925925926' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.18688905239105225, train acc: 0.9227414920845578\n",
      "Epoch 10, train loss: 0.1868714839220047, train acc: 0.9227414920845578\n",
      "Epoch 0, train loss: 0.18686982989311218, train acc: 0.9227414920845578\n",
      "Epoch 10, train loss: 0.18685375154018402, train acc: 0.9227651910133662\n",
      "Accuracy for each output state:\n",
      "0.9228362877997914\n",
      "Value 's_m_h30_val21: 0.9228362877997914' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9357142857142857\n",
      "Value 's_m_h30_val21: 0.9357142857142857' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.1791965663433075, train acc: 0.9268806273598605\n",
      "Epoch 10, train loss: 0.17918623983860016, train acc: 0.9268806273598605\n",
      "Epoch 0, train loss: 0.17918527126312256, train acc: 0.9268806273598605\n",
      "Epoch 10, train loss: 0.1791759431362152, train acc: 0.9268806273598605\n",
      "Accuracy for each output state:\n",
      "0.9269048310581858\n",
      "Value 's_m_h40_val21: 0.9269048310581858' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9419847328244275\n",
      "Value 's_m_h40_val21: 0.9419847328244275' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.18520452082157135, train acc: 0.9207884063705609\n",
      "Epoch 10, train loss: 0.18519867956638336, train acc: 0.9207884063705609\n",
      "Epoch 0, train loss: 0.18519814312458038, train acc: 0.9207884063705609\n",
      "Epoch 10, train loss: 0.1851927489042282, train acc: 0.9207884063705609\n",
      "Accuracy for each output state:\n",
      "0.9209367889999012\n",
      "Value 's_m_h50_val21: 0.9209367889999012' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.936046511627907\n",
      "Value 's_m_h50_val21: 0.936046511627907' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.20069381594657898, train acc: 0.9112144807361715\n",
      "Epoch 10, train loss: 0.20069020986557007, train acc: 0.9112144807361715\n",
      "Epoch 0, train loss: 0.20068982243537903, train acc: 0.9112144807361715\n",
      "Epoch 10, train loss: 0.20068618655204773, train acc: 0.9112144807361715\n",
      "Accuracy for each output state:\n",
      "0.9110880776620487\n",
      "Value 's_m_h60_val21: 0.9110880776620487' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9263779527559055\n",
      "Value 's_m_h60_val21: 0.9263779527559055' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.23337960243225098, train acc: 0.8947667804323094\n",
      "Epoch 10, train loss: 0.2333759218454361, train acc: 0.8947667804323094\n",
      "Epoch 0, train loss: 0.23337550461292267, train acc: 0.8947667804323094\n",
      "Epoch 10, train loss: 0.23337112367153168, train acc: 0.8947667804323094\n",
      "Accuracy for each output state:\n",
      "0.8946633571206951\n",
      "Value 's_m_h70_val21: 0.8946633571206951' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9124\n",
      "Value 's_m_h70_val21: 0.9124' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.28061744570732117, train acc: 0.8736903376018627\n",
      "Epoch 10, train loss: 0.28061071038246155, train acc: 0.8737432532543127\n",
      "Epoch 0, train loss: 0.28060993552207947, train acc: 0.8737432532543127\n",
      "Epoch 10, train loss: 0.2806018888950348, train acc: 0.8737432532543127\n",
      "Accuracy for each output state:\n",
      "0.8736903376018625\n",
      "Value 's_m_h80_val21: 0.8736903376018625' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8971544715447154\n",
      "Value 's_m_h80_val21: 0.8971544715447154' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.33848607540130615, train acc: 0.8508234911691408\n",
      "Epoch 10, train loss: 0.3384726047515869, train acc: 0.8508234911691408\n",
      "Epoch 0, train loss: 0.33847111463546753, train acc: 0.8508234911691408\n",
      "Epoch 10, train loss: 0.33845534920692444, train acc: 0.8508234911691408\n",
      "Accuracy for each output state:\n",
      "0.8507964026438402\n",
      "Value 's_m_h90_val21: 0.8507964026438402' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8727272727272728\n",
      "Value 's_m_h90_val21: 0.8727272727272728' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.40779900550842285, train acc: 0.8265345765345765\n",
      "Epoch 10, train loss: 0.4077740013599396, train acc: 0.8265345765345765\n",
      "Epoch 0, train loss: 0.40777119994163513, train acc: 0.8265345765345765\n",
      "Epoch 10, train loss: 0.4077427089214325, train acc: 0.8265345765345765\n",
      "Accuracy for each output state:\n",
      "0.8265068265068265\n",
      "Value 's_m_h100_val21: 0.8265068265068265' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8470588235294119\n",
      "Value 's_m_h100_val21: 0.8470588235294119' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.23064470291137695, train acc: 0.9020893632416788\n",
      "Epoch 10, train loss: 0.2306424230337143, train acc: 0.9020893632416788\n",
      "Epoch 0, train loss: 0.23064054548740387, train acc: 0.9020893632416788\n",
      "Epoch 10, train loss: 0.23061427474021912, train acc: 0.9020893632416788\n",
      "Accuracy for each output state:\n",
      "0.9016145079594791\n",
      "Value 's_m_h10_val22: 0.9016145079594791' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9029126213592233\n",
      "Value 's_m_h10_val22: 0.9029126213592233' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.20567122101783752, train acc: 0.9132521225544481\n",
      "Epoch 10, train loss: 0.20564644038677216, train acc: 0.9132521225544481\n",
      "Epoch 0, train loss: 0.20564395189285278, train acc: 0.9132521225544481\n",
      "Epoch 10, train loss: 0.20561937987804413, train acc: 0.9132521225544481\n",
      "Accuracy for each output state:\n",
      "0.913390550018457\n",
      "Value 's_m_h20_val22: 0.913390550018457' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9152960526315789\n",
      "Value 's_m_h20_val22: 0.9152960526315789' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.18557226657867432, train acc: 0.9250423888470234\n",
      "Epoch 10, train loss: 0.18555520474910736, train acc: 0.9250423888470234\n",
      "Epoch 0, train loss: 0.1855536252260208, train acc: 0.9250423888470234\n",
      "Epoch 10, train loss: 0.18553803861141205, train acc: 0.9250423888470234\n",
      "Accuracy for each output state:\n",
      "0.9251601356443104\n",
      "Value 's_m_h30_val22: 0.9251601356443104' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.919314381270903\n",
      "Value 's_m_h30_val22: 0.919314381270903' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.17784340679645538, train acc: 0.9307906887264332\n",
      "Epoch 10, train loss: 0.1778334081172943, train acc: 0.9307906887264332\n",
      "Epoch 0, train loss: 0.1778324693441391, train acc: 0.9307906887264332\n",
      "Epoch 10, train loss: 0.17782346904277802, train acc: 0.9307906887264332\n",
      "Accuracy for each output state:\n",
      "0.9307425933051173\n",
      "Value 's_m_h40_val22: 0.9307425933051173' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9217687074829932\n",
      "Value 's_m_h40_val22: 0.9217687074829932' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.18356414139270782, train acc: 0.9256092767295597\n",
      "Epoch 10, train loss: 0.1835586130619049, train acc: 0.9256092767295597\n",
      "Epoch 0, train loss: 0.18355809152126312, train acc: 0.9256092767295597\n",
      "Epoch 10, train loss: 0.183553084731102, train acc: 0.9256092767295597\n",
      "Accuracy for each output state:\n",
      "0.9257075471698113\n",
      "Value 's_m_h50_val22: 0.9257075471698113' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9165224913494809\n",
      "Value 's_m_h50_val22: 0.9165224913494809' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.19830527901649475, train acc: 0.9172107271996786\n",
      "Epoch 10, train loss: 0.1983022540807724, train acc: 0.9172107271996786\n",
      "Epoch 0, train loss: 0.19830195605754852, train acc: 0.9172107271996786\n",
      "Epoch 10, train loss: 0.19829897582530975, train acc: 0.9172107271996786\n",
      "Accuracy for each output state:\n",
      "0.9172107271996786\n",
      "Value 's_m_h60_val22: 0.9172107271996786' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.9053697183098591\n",
      "Value 's_m_h60_val22: 0.9053697183098591' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.2303723841905594, train acc: 0.9009089975349219\n",
      "Epoch 10, train loss: 0.23036985099315643, train acc: 0.9009089975349219\n",
      "Epoch 0, train loss: 0.23036955296993256, train acc: 0.9009089975349219\n",
      "Epoch 10, train loss: 0.2303665578365326, train acc: 0.9009089975349219\n",
      "Accuracy for each output state:\n",
      "0.9009603533278554\n",
      "Value 's_m_h70_val22: 0.9009603533278554' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8844086021505376\n",
      "Value 's_m_h70_val22: 0.8844086021505376' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.276902973651886, train acc: 0.8794398907103825\n",
      "Epoch 10, train loss: 0.2768985331058502, train acc: 0.8794661622530475\n",
      "Epoch 0, train loss: 0.27689796686172485, train acc: 0.8794661622530475\n",
      "Epoch 10, train loss: 0.2768924832344055, train acc: 0.8794661622530475\n",
      "Accuracy for each output state:\n",
      "0.8795449768810425\n",
      "Value 's_m_h80_val22: 0.8795449768810425' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8585766423357664\n",
      "Value 's_m_h80_val22: 0.8585766423357664' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.33368587493896484, train acc: 0.8564974182444062\n",
      "Epoch 10, train loss: 0.33367645740509033, train acc: 0.8565243115318416\n",
      "Epoch 0, train loss: 0.33367541432380676, train acc: 0.8565243115318416\n",
      "Epoch 10, train loss: 0.3336641788482666, train acc: 0.8565243115318416\n",
      "Accuracy for each output state:\n",
      "0.8565512048192772\n",
      "Value 's_m_h90_val22: 0.8565512048192772' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8359665427509293\n",
      "Value 's_m_h90_val22: 0.8359665427509293' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.40029770135879517, train acc: 0.8323049801674747\n",
      "Epoch 10, train loss: 0.4002794325351715, train acc: 0.8323049801674747\n",
      "Epoch 0, train loss: 0.40027743577957153, train acc: 0.8323049801674747\n",
      "Epoch 10, train loss: 0.40025633573532104, train acc: 0.8323049801674747\n",
      "Accuracy for each output state:\n",
      "0.8323049801674747\n",
      "Value 's_m_h100_val22: 0.8323049801674747' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8200757575757576\n",
      "Value 's_m_h100_val22: 0.8200757575757576' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.22787153720855713, train acc: 0.9010827197921178\n",
      "Epoch 10, train loss: 0.22786808013916016, train acc: 0.9010827197921178\n",
      "Epoch 0, train loss: 0.22786620259284973, train acc: 0.9010827197921178\n",
      "Epoch 10, train loss: 0.2278403490781784, train acc: 0.9011043741879602\n",
      "Accuracy for each output state:\n",
      "0.9007579038544824\n",
      "Value 's_m_h10_val23: 0.9007579038544824' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8875968992248062\n",
      "Value 's_m_h10_val23: 0.8875968992248062' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.20322869718074799, train acc: 0.9136644591611479\n",
      "Epoch 10, train loss: 0.20320473611354828, train acc: 0.9136644591611479\n",
      "Epoch 0, train loss: 0.20320239663124084, train acc: 0.9136644591611479\n",
      "Epoch 10, train loss: 0.20317870378494263, train acc: 0.9137527593818985\n",
      "Accuracy for each output state:\n",
      "0.9137306843267108\n",
      "Value 's_m_h20_val23: 0.9137306843267108' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8781512605042017\n",
      "Value 's_m_h20_val23: 0.8781512605042017' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.1834080070257187, train acc: 0.9260243133723548\n",
      "Epoch 10, train loss: 0.18339182436466217, train acc: 0.9260018009905449\n",
      "Epoch 0, train loss: 0.1833903044462204, train acc: 0.9260018009905449\n",
      "Epoch 10, train loss: 0.18337559700012207, train acc: 0.9260018009905449\n",
      "Accuracy for each output state:\n",
      "0.9260693381359748\n",
      "Value 's_m_h30_val23: 0.9260693381359748' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8440366972477064\n",
      "Value 's_m_h30_val23: 0.8440366972477064' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.17570634186267853, train acc: 0.9316490583371613\n",
      "Epoch 10, train loss: 0.17569711804389954, train acc: 0.9316490583371613\n",
      "Epoch 0, train loss: 0.1756962686777115, train acc: 0.9316490583371613\n",
      "Epoch 10, train loss: 0.1756879687309265, train acc: 0.9316720257234726\n",
      "Accuracy for each output state:\n",
      "0.9318098300413413\n",
      "Value 's_m_h40_val23: 0.9318098300413413' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8434343434343434\n",
      "Value 's_m_h40_val23: 0.8434343434343434' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.1813248097896576, train acc: 0.9268870135958743\n",
      "Epoch 10, train loss: 0.18131986260414124, train acc: 0.9268870135958743\n",
      "Epoch 0, train loss: 0.18131940066814423, train acc: 0.9268870135958743\n",
      "Epoch 10, train loss: 0.18131490051746368, train acc: 0.9268870135958743\n",
      "Accuracy for each output state:\n",
      "0.9269573370839193\n",
      "Value 's_m_h50_val23: 0.9269573370839193' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8342696629213483\n",
      "Value 's_m_h50_val23: 0.8342696629213483' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.19634193181991577, train acc: 0.9175921493537578\n",
      "Epoch 10, train loss: 0.1963392049074173, train acc: 0.9175921493537578\n",
      "Epoch 0, train loss: 0.1963389366865158, train acc: 0.9175921493537578\n",
      "Epoch 10, train loss: 0.19633617997169495, train acc: 0.9175921493537578\n",
      "Accuracy for each output state:\n",
      "0.9175442795595979\n",
      "Value 's_m_h60_val23: 0.9175442795595979' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8132911392405063\n",
      "Value 's_m_h60_val23: 0.8132911392405063' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.2284581959247589, train acc: 0.9006601466992665\n",
      "Epoch 10, train loss: 0.22845569252967834, train acc: 0.9006845965770172\n",
      "Epoch 0, train loss: 0.22845536470413208, train acc: 0.9006845965770172\n",
      "Epoch 10, train loss: 0.22845230996608734, train acc: 0.9007090464547677\n",
      "Accuracy for each output state:\n",
      "0.9007090464547678\n",
      "Value 's_m_h70_val23: 0.9007090464547678' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.786231884057971\n",
      "Value 's_m_h70_val23: 0.786231884057971' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.2745412588119507, train acc: 0.8791854072963519\n",
      "Epoch 10, train loss: 0.27453625202178955, train acc: 0.8791854072963519\n",
      "Epoch 0, train loss: 0.2745356857776642, train acc: 0.8791854072963519\n",
      "Epoch 10, train loss: 0.27452951669692993, train acc: 0.8791854072963519\n",
      "Accuracy for each output state:\n",
      "0.879135432283858\n",
      "Value 's_m_h80_val23: 0.879135432283858' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.75\n",
      "Value 's_m_h80_val23: 0.75' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.3311145305633545, train acc: 0.8567961165048543\n",
      "Epoch 10, train loss: 0.3311038911342621, train acc: 0.856821665815023\n",
      "Epoch 0, train loss: 0.3311026990413666, train acc: 0.856821665815023\n",
      "Epoch 10, train loss: 0.3310900628566742, train acc: 0.856821665815023\n",
      "Accuracy for each output state:\n",
      "0.8567450178845171\n",
      "Value 's_m_h90_val23: 0.8567450178845171' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.75\n",
      "Value 's_m_h90_val23: 0.75' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n",
      "Epoch 0, train loss: 0.3985891342163086, train acc: 0.8328018818609514\n",
      "Epoch 10, train loss: 0.39856839179992676, train acc: 0.8328018818609514\n",
      "Epoch 0, train loss: 0.3985661268234253, train acc: 0.8328018818609514\n",
      "Epoch 10, train loss: 0.3985423147678375, train acc: 0.8328018818609514\n",
      "Accuracy for each output state:\n",
      "0.8326973340303189\n",
      "Value 's_m_h100_val23: 0.8326973340303189' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_train_08052024.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.75\n",
      "Value 's_m_h100_val23: 0.75' saved to 'C:/Users/kacpe/Desktop/lab_rotation_git/results/test/smh_results_test_08052024.txt' successfully.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "batch_size should be a positive integer value, but got batch_size=0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[87], line 84\u001b[0m\n\u001b[0;32m     82\u001b[0m fullset_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(full_dataset, batch_size\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     83\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39mX_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 84\u001b[0m test_dataloader \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m train_losses, train_accs, val_losses, val_accs, train_predicted_labels, train_probs_final \u001b[38;5;241m=\u001b[39m run_training(\n\u001b[0;32m     88\u001b[0m     train_dataloader, val_dataloader\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, model\u001b[38;5;241m=\u001b[39mmodel, optimizer\u001b[38;5;241m=\u001b[39moptimizer, loss_fn\u001b[38;5;241m=\u001b[39mloss_fn, num_epochs\u001b[38;5;241m=\u001b[39mn_epochs, scheduler\u001b[38;5;241m=\u001b[39mscheduler)\n\u001b[0;32m     92\u001b[0m shifted_df \u001b[38;5;241m=\u001b[39m shifted_df[selected_columns]\n",
      "File \u001b[1;32mc:\\Users\\kacpe\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:359\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[1;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[0;32m    355\u001b[0m             sampler \u001b[38;5;241m=\u001b[39m SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m batch_sampler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;66;03m# auto_collation without custom batch_sampler\u001b[39;00m\n\u001b[1;32m--> 359\u001b[0m     batch_sampler \u001b[38;5;241m=\u001b[39m \u001b[43mBatchSampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43msampler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdrop_last\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;241m=\u001b[39m batch_size\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_last \u001b[38;5;241m=\u001b[39m drop_last\n",
      "File \u001b[1;32mc:\\Users\\kacpe\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\sampler.py:225\u001b[0m, in \u001b[0;36mBatchSampler.__init__\u001b[1;34m(self, sampler, batch_size, drop_last)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, sampler: Union[Sampler[\u001b[38;5;28mint\u001b[39m], Iterable[\u001b[38;5;28mint\u001b[39m]], batch_size: \u001b[38;5;28mint\u001b[39m, drop_last: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# Since collections.abc.Iterable does not check for `__getitem__`, which\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# is one way for an object to be an iterable, we don't do an `isinstance`\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m# check here.\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch_size, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch_size, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \\\n\u001b[0;32m    224\u001b[0m             batch_size \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 225\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size should be a positive integer value, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    226\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got batch_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(batch_size))\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(drop_last, \u001b[38;5;28mbool\u001b[39m):\n\u001b[0;32m    228\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop_last should be a boolean value, but got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    229\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop_last=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(drop_last))\n",
      "\u001b[1;31mValueError\u001b[0m: batch_size should be a positive integer value, but got batch_size=0"
     ]
    }
   ],
   "source": [
    "for j in np.arange(1,25):\n",
    "    for i in np.arange(10,101,step=10):\n",
    "        shift = i\n",
    "        set_values = j\n",
    "        model_name = 's_m_h'+str(shift)+'_'+'val'+str(set_values)\n",
    "\n",
    "\n",
    "        # Create an empty DataFrame to store the shifted data\n",
    "        shifted_df = pd.DataFrame()\n",
    "\n",
    "        # Loop through unique trial values\n",
    "        for trial_value in scaled_df['trial'].unique():\n",
    "            # Filter the DataFrame for the current trial\n",
    "            trial_df = scaled_df[scaled_df['trial'] == trial_value].copy()\n",
    "\n",
    "            # Create shifted columns for each column in columns_to_shift\n",
    "            for col in columns_to_shift:\n",
    "                new_col_name = col + '_minus_' + str(shift)\n",
    "                trial_df[new_col_name] = trial_df[col].shift(shift)\n",
    "\n",
    "            # Drop the last 'i' records for each trial\n",
    "            trial_df = trial_df.dropna()\n",
    "\n",
    "            # Append the modified trial_df to the shifted_df\n",
    "            shifted_df = shifted_df.append(trial_df, ignore_index=True)\n",
    "        \n",
    "      \n",
    "        selected_columns = ['trial','nose_x_minus_'+str(shift), 'nose_y_minus_'+str(shift),\n",
    "        'nose_z_minus_'+str(shift), 'headTop_x_minus_'+str(shift), 'headTop_y_minus_'+str(shift),\n",
    "        'headTop_z_minus_'+str(shift), 'neck_x_minus_'+str(shift), 'neck_y_minus_'+str(shift),\n",
    "        'neck_z_minus_'+str(shift), 'tailBase_x_minus_'+str(shift), 'tailBase_y_minus_'+str(shift),\n",
    "        'tailBase_z_minus_'+str(shift), 'lEar_x_minus_'+str(shift), 'lEar_y_minus_'+str(shift),\n",
    "        'lEar_z_minus_'+str(shift), 'lShoulder_x_minus_'+str(shift), 'lShoulder_y_minus_'+str(shift),\n",
    "        'lShoulder_z_minus_'+str(shift), 'lElbow_x_minus_'+str(shift), 'lElbow_y_minus_'+str(shift),\n",
    "        'lElbow_z_minus_'+str(shift), 'lWrist_x_minus_'+str(shift), 'lWrist_y_minus_'+str(shift),\n",
    "        'lWrist_z_minus_'+str(shift), 'lHip_x_minus_'+str(shift), 'lHip_y_minus_'+str(shift),\n",
    "        'lHip_z_minus_'+str(shift), 'rEar_x_minus_'+str(shift), 'rEar_y_minus_'+str(shift), 'rEar_z_minus_'+str(shift),\n",
    "        'rShoulder_x_minus_'+str(shift), 'rShoulder_y_minus_'+str(shift), 'rShoulder_z_minus_'+str(shift),\n",
    "        'rElbow_x_minus_'+str(shift), 'rElbow_y_minus_'+str(shift), 'rElbow_z_minus_'+str(shift),\n",
    "        'rWrist_x_minus_'+str(shift), 'rWrist_y_minus_'+str(shift), 'rWrist_z_minus_'+str(shift),\n",
    "        'rHip_x_minus_'+str(shift), 'rHip_y_minus_'+str(shift), 'rHip_z_minus_'+str(shift), 's_1_minus_'+str(shift),\n",
    "        's_2_minus_'+str(shift), 's_3_minus_'+str(shift), 's_4_minus_'+str(shift),'s_1','s_2','s_3','s_4','H_headFront_x_minus_'+str(shift), 'H_headFront_y_minus_'+str(shift), \n",
    "        'H_headFront_z_minus_'+str(shift), 'H_neck_x_minus_'+str(shift),'H_neck_y_minus_'+str(shift), 'H_neck_z_minus_'+str(shift), 'H_lowerBack_x_minus_'+str(shift), 'H_lowerBack_y_minus_'+str(shift),'H_lowerBack_z_minus_'+str(shift),\n",
    "        'H_leftWrist_x_minus_'+str(shift), 'H_leftWrist_y_minus_'+str(shift), 'H_leftWrist_z_minus_'+str(shift),'H_leftShoulder_x_minus_'+str(shift), 'H_leftShoulder_y_minus_'+str(shift), 'H_leftShoulder_z_minus_'+str(shift),\n",
    "       'H_leftElbow_x_minus_'+str(shift), 'H_leftElbow_y_minus_'+str(shift), 'H_leftElbow_z_minus_'+str(shift)]\n",
    "        shifted_df = shifted_df[selected_columns]\n",
    "        \n",
    "        trial_groups = shifted_df.groupby('trial')\n",
    "        \n",
    "        # Get a list of trial group names (trial IDs)\n",
    "        trial_ids = list(trial_groups.groups.keys())\n",
    "        \n",
    "        # Shuffle the trial IDs randomly \n",
    "        random.shuffle(trial_ids)\n",
    "        # Create an empty list to store shuffled trial DataFrames\n",
    "        shuffled_trial_dfs = []\n",
    "        \n",
    "        # Iterate through the shuffled trial IDs and add the corresponding trial DataFrames to the list\n",
    "        for trial_id in trial_ids:\n",
    "            shuffled_trial_dfs.append(trial_groups.get_group(trial_id))\n",
    "            \n",
    "        # Step 5: Split the data into training and test sets based on the 'trial' column\n",
    "        train_set = shifted_df[shifted_df['trial']!=set_values].drop(columns=['trial'])\n",
    "        test_set = shifted_df[shifted_df['trial']==set_values].drop(columns=['trial'])\n",
    "        full_set = shifted_df.drop(columns=['trial'])\n",
    "\n",
    "        # split data into x and y \n",
    "        X_train, y_train = train_set.drop(columns=labels), train_set[labels]\n",
    "        X_test, y_test = test_set.drop(columns=labels), test_set[labels]\n",
    "        X, y = full_set.drop(columns=labels), full_set[labels]\n",
    "        \n",
    "        # reset index \n",
    "        X_train, y_train = X_train.reset_index(drop=True), y_train.reset_index(drop=True)\n",
    "        X_test, y_test = X_test.reset_index(drop=True), y_test.reset_index(drop=True)\n",
    "        X, y = X.reset_index(drop=True), y.reset_index(drop=True) \n",
    "\n",
    "        # Create custom datasets for training, validation, and testing\n",
    "        full_dataset = MyDataset(torch.tensor(X.values), torch.tensor(y.values))\n",
    "        train_dataset = MyDataset(torch.tensor(X_train.values), torch.tensor(y_train.values))\n",
    "        test_dataset = MyDataset(torch.tensor(X_test.values), torch.tensor(y_test.values))\n",
    "\n",
    "        fullset_dataloader = DataLoader(full_dataset, batch_size=X.shape[0], shuffle=False)\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=X_train.shape[0], shuffle=False)\n",
    "        test_dataloader = DataLoader(test_dataset, batch_size=X_test.shape[0], shuffle=False)\n",
    "\n",
    "\n",
    "        train_losses, train_accs, val_losses, val_accs, train_predicted_labels, train_probs_final = run_training(\n",
    "            train_dataloader, val_dataloader=None, model=model, optimizer=optimizer, loss_fn=loss_fn, num_epochs=n_epochs, scheduler=scheduler)\n",
    "\n",
    "\n",
    "        state_dict = model.state_dict()\n",
    "\n",
    "        # Specify the folder path and the model filename\n",
    "        folder_path = os.path.join(current_dir, 'models')\n",
    "        dir_name = \"model_smh_\" + current_datetime\n",
    "        folder_path = os.path.join(folder_path, dir_name)\n",
    "\n",
    "        try:\n",
    "            # Check if the directory exists, if not, create it\n",
    "            if not os.path.exists(folder_path):\n",
    "                os.makedirs(folder_path)\n",
    "\n",
    "            # Combine the folder path and model filename\n",
    "            model_filename = model_name + '.pth'\n",
    "            full_model = os.path.join(folder_path, model_filename)\n",
    "\n",
    "            # Save the model to the specified folder\n",
    "            torch.save(state_dict, full_model)\n",
    "            print(\"Model saved successfully at:\", full_model)\n",
    "        except Exception as e:\n",
    "            print(\"An error occurred:\", e)\n",
    "\n",
    "\n",
    "\n",
    "        accs = evaluate_model(model, train_dataloader, y_train, current_datetime)\n",
    "        \n",
    "        # Define the directory where you want to save the file relative to current_dir\n",
    "        relative_dir = \"results/\"\n",
    "\n",
    "        # Create the full directory path by joining current_dir and relative_dir\n",
    "        full_dir_path = os.path.join(current_dir, relative_dir)\n",
    "\n",
    "        # Ensure that the directory exists, if not, create it\n",
    "        if not os.path.exists(full_dir_path):\n",
    "            os.makedirs(full_dir_path)\n",
    "\n",
    "        # Define the file name\n",
    "        file_name = 'smh_results_train_' + current_datetime + '.txt'\n",
    "\n",
    "        # Create the full file path by joining the directory path and the file name\n",
    "        file_path = os.path.join(full_dir_path, file_name)\n",
    "\n",
    "        # Define the value you want to save\n",
    "        value_to_save = model_name + \": \" + str(accs)\n",
    "\n",
    "        try:\n",
    "            # Open the file in append mode (create if it doesn't exist)\n",
    "            with open(file_path, \"a+\") as file:\n",
    "                # Move the file cursor to the beginning to check if the file is empty\n",
    "                file.seek(0)\n",
    "                # Read the first character of the file\n",
    "                first_char = file.read(1)\n",
    "                # If the first character is empty (file is empty), write a new line\n",
    "                if not first_char:\n",
    "                    file.write('\\n')\n",
    "                # Write the value to the file\n",
    "                file.write(value_to_save + '\\n')\n",
    "                print(f\"Value '{value_to_save}' saved to '{file_path}' successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            \n",
    "        accs = evaluate_model(model, test_dataloader, y_test, current_datetime)\n",
    "\n",
    "        # Define the directory where you want to save the file relative to current_dir\n",
    "        relative_dir = \"results/\"\n",
    "\n",
    "        # Create the full directory path by joining current_dir and relative_dir\n",
    "        full_dir_path = os.path.join(current_dir, relative_dir)\n",
    "\n",
    "        # Ensure that the directory exists, if not, create it\n",
    "        if not os.path.exists(full_dir_path):\n",
    "            os.makedirs(full_dir_path)\n",
    "\n",
    "        # Define the file name\n",
    "        file_name = 'smh_results_test_' + current_datetime + '.txt'\n",
    "\n",
    "        # Create the full file path by joining the directory path and the file name\n",
    "        file_path = os.path.join(full_dir_path, file_name)\n",
    "\n",
    "        # Define the value you want to save\n",
    "        value_to_save = model_name + \": \" + str(accs)\n",
    "\n",
    "        try:\n",
    "            # Open the file in append mode (create if it doesn't exist)\n",
    "            with open(file_path, \"a+\") as file:\n",
    "                # Move the file cursor to the beginning to check if the file is empty\n",
    "                file.seek(0)\n",
    "                # Read the first character of the file\n",
    "                first_char = file.read(1)\n",
    "                # If the first character is empty (file is empty), write a new line\n",
    "                if not first_char:\n",
    "                    file.write('\\n')\n",
    "                # Write the value to the file\n",
    "                file.write(value_to_save + '\\n')\n",
    "                print(f\"Value '{value_to_save}' saved to '{file_path}' successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['H_headFront_x', 'H_headFront_y', 'H_headFront_z', 'H_neck_x',\n",
       "       'H_neck_y', 'H_neck_z', 'H_lowerBack_x', 'H_lowerBack_y',\n",
       "       'H_lowerBack_z', 'H_leftWrist_x', 'H_leftWrist_y', 'H_leftWrist_z',\n",
       "       'H_leftShoulder_x', 'H_leftShoulder_y', 'H_leftShoulder_z',\n",
       "       'H_leftElbow_x', 'H_leftElbow_y', 'H_leftElbow_z', 's_1', 's_2', 's_3',\n",
       "       's_4'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data_human_jarvis_oldlabels.csv\")\n",
    "df.rename(columns={'H_trial': 'trial'}, inplace=True)\n",
    "# List of column names to drop\n",
    "labels = ['s_1','s_2','s_3','s_4']\n",
    "data_to_scale = df.drop(columns=['trial','s_1','s_2','s_3','s_4'])\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(data_to_scale)\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=data_to_scale.columns)\n",
    "scaled_df[['trial','s_1','s_2','s_3','s_4']] = df[['trial','s_1','s_2','s_3','s_4']]\n",
    "scaled_df = scaled_df.dropna(axis=0)\n",
    "cols_to_omit = ['trial']\n",
    "# Use the drop method to exclude columns\n",
    "columns_to_shift = scaled_df.drop(cols_to_omit, axis=1).columns\n",
    "columns_to_shift\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df.shape[1]-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_dim = scaled_df.shape[1]-1\n",
    "hidden_dim = 11\n",
    "output_dim = 4\n",
    "num_layers = 1\n",
    "n_epochs =100\n",
    "lr = 0.01\n",
    "\n",
    "# Create an instance of GRUCellNet\n",
    "model = GRUCellNet(input_dim, hidden_dim, output_dim, num_layers)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "#class_weights = torch.tensor([1.8]).to(device)\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=None)  \n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kacpe\\anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "c:\\Users\\kacpe\\anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:380: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return [base_lr * self.gamma ** (self.last_epoch // self.step_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train loss: 0.7035382390022278, train acc: 0.47385676573277696\n",
      "Model saved successfully at: c:\\Users\\kacpe\\Desktop\\lab_rotation_git\\data\\models\\model_sh_090524\\s_h0_val1.pth\n",
      "Accuracy for each output state:\n",
      "0.4957421442561526\n",
      "Value 's_h0_val1: 0.4957421442561526' saved to 'c:\\Users\\kacpe\\Desktop\\lab_rotation_git\\data\\results/sh_results_train_090524.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.6739130434782609\n",
      "Value 's_h0_val1: 0.6739130434782609' saved to 'c:\\Users\\kacpe\\Desktop\\lab_rotation_git\\data\\results/sh_results_test_090524.txt' successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kacpe\\anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "c:\\Users\\kacpe\\anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:380: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return [base_lr * self.gamma ** (self.last_epoch // self.step_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train loss: 0.669256329536438, train acc: 0.5556110483800921\n",
      "Model saved successfully at: c:\\Users\\kacpe\\Desktop\\lab_rotation_git\\data\\models\\model_sh_090524\\s_h10_val1.pth\n",
      "Accuracy for each output state:\n",
      "0.4975245374793712\n",
      "Value 's_h10_val1: 0.4975245374793712' saved to 'c:\\Users\\kacpe\\Desktop\\lab_rotation_git\\data\\results/sh_results_train_090524.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.685430463576159\n",
      "Value 's_h10_val1: 0.685430463576159' saved to 'c:\\Users\\kacpe\\Desktop\\lab_rotation_git\\data\\results/sh_results_test_090524.txt' successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kacpe\\anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "c:\\Users\\kacpe\\anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:380: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return [base_lr * self.gamma ** (self.last_epoch // self.step_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train loss: 0.6390988230705261, train acc: 0.6580918195515377\n",
      "Model saved successfully at: c:\\Users\\kacpe\\Desktop\\lab_rotation_git\\data\\models\\model_sh_090524\\s_h20_val1.pth\n",
      "Accuracy for each output state:\n",
      "0.4974740760436054\n",
      "Value 's_h20_val1: 0.4974740760436054' saved to 'c:\\Users\\kacpe\\Desktop\\lab_rotation_git\\data\\results/sh_results_train_090524.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.698581560283688\n",
      "Value 's_h20_val1: 0.698581560283688' saved to 'c:\\Users\\kacpe\\Desktop\\lab_rotation_git\\data\\results/sh_results_test_090524.txt' successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kacpe\\anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "c:\\Users\\kacpe\\anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:380: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return [base_lr * self.gamma ** (self.last_epoch // self.step_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train loss: 0.6157956123352051, train acc: 0.7023432552248259\n",
      "Model saved successfully at: c:\\Users\\kacpe\\Desktop\\lab_rotation_git\\data\\models\\model_sh_090524\\s_h30_val1.pth\n",
      "Accuracy for each output state:\n",
      "0.5037320184565277\n",
      "Value 's_h30_val1: 0.5037320184565277' saved to 'c:\\Users\\kacpe\\Desktop\\lab_rotation_git\\data\\results/sh_results_train_090524.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.7137404580152672\n",
      "Value 's_h30_val1: 0.7137404580152672' saved to 'c:\\Users\\kacpe\\Desktop\\lab_rotation_git\\data\\results/sh_results_test_090524.txt' successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kacpe\\anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "c:\\Users\\kacpe\\anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:380: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return [base_lr * self.gamma ** (self.last_epoch // self.step_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train loss: 0.5975390672683716, train acc: 0.7437632818996581\n",
      "Model saved successfully at: c:\\Users\\kacpe\\Desktop\\lab_rotation_git\\data\\models\\model_sh_090524\\s_h40_val1.pth\n",
      "Accuracy for each output state:\n",
      "0.5429178601127229\n",
      "Value 's_h40_val1: 0.5429178601127229' saved to 'c:\\Users\\kacpe\\Desktop\\lab_rotation_git\\data\\results/sh_results_train_090524.txt' successfully.\n",
      "Accuracy for each output state:\n",
      "0.8037190082644629\n",
      "Value 's_h40_val1: 0.8037190082644629' saved to 'c:\\Users\\kacpe\\Desktop\\lab_rotation_git\\data\\results/sh_results_test_090524.txt' successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kacpe\\anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "c:\\Users\\kacpe\\anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:380: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  return [base_lr * self.gamma ** (self.last_epoch // self.step_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train loss: 0.5830621719360352, train acc: 0.7671339563862928\n",
      "Model saved successfully at: c:\\Users\\kacpe\\Desktop\\lab_rotation_git\\data\\models\\model_sh_090524\\s_h50_val1.pth\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 102\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred:\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[1;32m--> 102\u001b[0m accs \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_datetime\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# Define the directory where you want to save the file relative to current_dir\u001b[39;00m\n\u001b[0;32m    105\u001b[0m relative_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[1;32mIn[15], line 22\u001b[0m, in \u001b[0;36mevaluate_model\u001b[1;34m(model, dataloader, y, current_datetime)\u001b[0m\n\u001b[0;32m     19\u001b[0m all_probs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Iterate through the train data batches\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, _ \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[0;32m     23\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[1;32mc:\\Users\\kacpe\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\kacpe\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    719\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    720\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 721\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    722\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    723\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\kacpe\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kacpe\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:175\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    172\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [default_collate(samples) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\kacpe\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:175\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    172\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mdefault_collate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\kacpe\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:141\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    139\u001b[0m         storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mstorage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    140\u001b[0m         out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m--> 141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m elem_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m elem_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstr_\u001b[39m\u001b[38;5;124m'\u001b[39m \\\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m elem_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstring_\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mndarray\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m elem_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmemmap\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;66;03m# array of string classes and object\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for j in np.arange(1,25):\n",
    "    for i in np.arange(0,101,step=10):\n",
    "        shift = i\n",
    "        set_values = j\n",
    "        model_name = 's_h'+str(shift)+'_'+'val'+str(set_values)\n",
    "\n",
    "\n",
    "        # Create an empty DataFrame to store the shifted data\n",
    "        shifted_df = pd.DataFrame()\n",
    "\n",
    "        # Loop through unique trial values\n",
    "        for trial_value in scaled_df['trial'].unique():\n",
    "            # Filter the DataFrame for the current trial\n",
    "            trial_df = scaled_df[scaled_df['trial'] == trial_value].copy()\n",
    "\n",
    "            # Create shifted columns for each column in columns_to_shift\n",
    "            for col in columns_to_shift:\n",
    "                new_col_name = col + '_minus_' + str(shift)\n",
    "                trial_df[new_col_name] = trial_df[col].shift(shift)\n",
    "\n",
    "            # Drop the last 'i' records for each trial\n",
    "            trial_df = trial_df.dropna()\n",
    "\n",
    "            # Append the modified trial_df to the shifted_df\n",
    "            shifted_df = shifted_df.append(trial_df, ignore_index=True)\n",
    "        \n",
    "        #selected_columns = ['id', 'trial','s_1_minus_'+str(shift),'s_2_minus_'+str(shift),'s_3_minus_'+str(shift),'s_4_minus_'+str(shift),'s_1','s_2','s_3','s_4']\n",
    "        selected_columns = ['trial', 's_1_minus_'+str(shift),\n",
    "        's_2_minus_'+str(shift), 's_3_minus_'+str(shift), 's_4_minus_'+str(shift),'s_1','s_2','s_3','s_4','H_headFront_x_minus_'+str(shift), 'H_headFront_y_minus_'+str(shift), \n",
    "        'H_headFront_z_minus_'+str(shift), 'H_neck_x_minus_'+str(shift),'H_neck_y_minus_'+str(shift), 'H_neck_z_minus_'+str(shift), 'H_lowerBack_x_minus_'+str(shift), 'H_lowerBack_y_minus_'+str(shift),'H_lowerBack_z_minus_'+str(shift),\n",
    "        'H_leftWrist_x_minus_'+str(shift), 'H_leftWrist_y_minus_'+str(shift), 'H_leftWrist_z_minus_'+str(shift),'H_leftShoulder_x_minus_'+str(shift), 'H_leftShoulder_y_minus_'+str(shift), 'H_leftShoulder_z_minus_'+str(shift),\n",
    "       'H_leftElbow_x_minus_'+str(shift), 'H_leftElbow_y_minus_'+str(shift), 'H_leftElbow_z_minus_'+str(shift)]\n",
    "        shifted_df = shifted_df[selected_columns]\n",
    "        \n",
    "        trial_groups = shifted_df.groupby('trial')\n",
    "        \n",
    "        # Get a list of trial group names (trial IDs)\n",
    "        trial_ids = list(trial_groups.groups.keys())\n",
    "        \n",
    "        # Shuffle the trial IDs randomly \n",
    "        random.shuffle(trial_ids)\n",
    "        # Create an empty list to store shuffled trial DataFrames\n",
    "        shuffled_trial_dfs = []\n",
    "        \n",
    "        # Iterate through the shuffled trial IDs and add the corresponding trial DataFrames to the list\n",
    "        for trial_id in trial_ids:\n",
    "            shuffled_trial_dfs.append(trial_groups.get_group(trial_id))\n",
    "            \n",
    "        # Step 5: Split the data into training and test sets based on the 'trial' column\n",
    "        train_set = shifted_df[shifted_df['trial']!=set_values].drop(columns=['trial'])\n",
    "        test_set = shifted_df[shifted_df['trial']==set_values].drop(columns=['trial'])\n",
    "        full_set = shifted_df.drop(columns=['trial'])\n",
    "\n",
    "        # split data into x and y \n",
    "        X_train, y_train = train_set.drop(columns=labels), train_set[labels]\n",
    "        X_test, y_test = test_set.drop(columns=labels), test_set[labels]\n",
    "        X, y = full_set.drop(columns=labels), full_set[labels]\n",
    "        \n",
    "        # reset index \n",
    "        X_train, y_train = X_train.reset_index(drop=True), y_train.reset_index(drop=True)\n",
    "        X_test, y_test = X_test.reset_index(drop=True), y_test.reset_index(drop=True)\n",
    "        X, y = X.reset_index(drop=True), y.reset_index(drop=True) \n",
    "\n",
    "        # Create custom datasets for training, validation, and testing\n",
    "        full_dataset = MyDataset(torch.tensor(X.values), torch.tensor(y.values))\n",
    "        train_dataset = MyDataset(torch.tensor(X_train.values), torch.tensor(y_train.values))\n",
    "        test_dataset = MyDataset(torch.tensor(X_test.values), torch.tensor(y_test.values))\n",
    "\n",
    "        fullset_dataloader = DataLoader(full_dataset, batch_size=X.shape[0], shuffle=False)\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=X_train.shape[0], shuffle=False)\n",
    "        test_dataloader = DataLoader(test_dataset, batch_size=X_test.shape[0], shuffle=False)\n",
    "\n",
    "\n",
    "        train_losses, train_accs, val_losses, val_accs, train_predicted_labels, train_probs_final = run_training(\n",
    "            train_dataloader, val_dataloader=None, model=model, optimizer=optimizer, loss_fn=loss_fn, num_epochs=n_epochs, scheduler=scheduler)\n",
    "\n",
    "\n",
    "        state_dict = model.state_dict()\n",
    "\n",
    "        # Specify the folder path and the model filename\n",
    "        folder_path = os.path.join(current_dir, 'models')\n",
    "        dir_name = \"model_sh_\" + current_datetime\n",
    "        folder_path = os.path.join(folder_path, dir_name)\n",
    "\n",
    "        try:\n",
    "            # Check if the directory exists, if not, create it\n",
    "            if not os.path.exists(folder_path):\n",
    "                os.makedirs(folder_path)\n",
    "\n",
    "            # Combine the folder path and model filename\n",
    "            model_filename = model_name + '.pth'\n",
    "            full_model = os.path.join(folder_path, model_filename)\n",
    "\n",
    "            # Save the model to the specified folder\n",
    "            torch.save(state_dict, full_model)\n",
    "            print(\"Model saved successfully at:\", full_model)\n",
    "        except Exception as e:\n",
    "            print(\"An error occurred:\", e)\n",
    "\n",
    "\n",
    "\n",
    "        accs = evaluate_model(model, train_dataloader, y_train, current_datetime)\n",
    "        \n",
    "        # Define the directory where you want to save the file relative to current_dir\n",
    "        relative_dir = \"results/\"\n",
    "\n",
    "        # Create the full directory path by joining current_dir and relative_dir\n",
    "        full_dir_path = os.path.join(current_dir, relative_dir)\n",
    "\n",
    "        # Ensure that the directory exists, if not, create it\n",
    "        if not os.path.exists(full_dir_path):\n",
    "            os.makedirs(full_dir_path)\n",
    "\n",
    "        # Define the file name\n",
    "        file_name = 'sh_results_train_' + current_datetime + '.txt'\n",
    "\n",
    "        # Create the full file path by joining the directory path and the file name\n",
    "        file_path = os.path.join(full_dir_path, file_name)\n",
    "\n",
    "        # Define the value you want to save\n",
    "        value_to_save = model_name + \": \" + str(accs)\n",
    "\n",
    "        try:\n",
    "            # Open the file in append mode (create if it doesn't exist)\n",
    "            with open(file_path, \"a+\") as file:\n",
    "                # Move the file cursor to the beginning to check if the file is empty\n",
    "                file.seek(0)\n",
    "                # Read the first character of the file\n",
    "                first_char = file.read(1)\n",
    "                # If the first character is empty (file is empty), write a new line\n",
    "                if not first_char:\n",
    "                    file.write('\\n')\n",
    "                # Write the value to the file\n",
    "                file.write(value_to_save + '\\n')\n",
    "                print(f\"Value '{value_to_save}' saved to '{file_path}' successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            \n",
    "        accs = evaluate_model(model, test_dataloader, y_test, current_datetime)\n",
    "\n",
    "        # Define the directory where you want to save the file relative to current_dir\n",
    "        relative_dir = \"results/\"\n",
    "\n",
    "        # Create the full directory path by joining current_dir and relative_dir\n",
    "        full_dir_path = os.path.join(current_dir, relative_dir)\n",
    "\n",
    "        # Ensure that the directory exists, if not, create it\n",
    "        if not os.path.exists(full_dir_path):\n",
    "            os.makedirs(full_dir_path)\n",
    "\n",
    "        # Define the file name\n",
    "        file_name = 'sh_results_test_' + current_datetime + '.txt'\n",
    "\n",
    "        # Create the full file path by joining the directory path and the file name\n",
    "        file_path = os.path.join(full_dir_path, file_name)\n",
    "\n",
    "        # Define the value you want to save\n",
    "        value_to_save = model_name + \": \" + str(accs)\n",
    "\n",
    "        try:\n",
    "            # Open the file in append mode (create if it doesn't exist)\n",
    "            with open(file_path, \"a+\") as file:\n",
    "                # Move the file cursor to the beginning to check if the file is empty\n",
    "                file.seek(0)\n",
    "                # Read the first character of the file\n",
    "                first_char = file.read(1)\n",
    "                # If the first character is empty (file is empty), write a new line\n",
    "                if not first_char:\n",
    "                    file.write('\\n')\n",
    "                # Write the value to the file\n",
    "                file.write(value_to_save + '\\n')\n",
    "                print(f\"Value '{value_to_save}' saved to '{file_path}' successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the labels for the y-axis (predicted states)\n",
    "y_labels = ['1','2','3','4']\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Create the heatmap plot\n",
    "heatmap = ax.imshow(all_probs_array.T, cmap='coolwarm', aspect='auto', interpolation='none')\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(heatmap)\n",
    "\n",
    "# Set the axis labels and title\n",
    "ax.set_xlabel('Time Step')\n",
    "ax.set_ylabel('Predicted State')\n",
    "ax.set_title('Probabilities of Predicting Output States')\n",
    "\n",
    "# Set the y-axis ticks and labels\n",
    "ax.set_yticks(np.arange(len(y_labels)))\n",
    "ax.set_yticklabels(y_labels)\n",
    "\n",
    "# Show the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the labels for the y-axis (predicted states)\n",
    "y_labels = ['1', '2', '3', '4']\n",
    "\n",
    "# Create a figure with a grid of subplots (2 rows, 1 column)\n",
    "fig, axs = plt.subplots(2, 1, figsize=(8, 10))\n",
    "\n",
    "# Create the heatmap plot in the first subplot\n",
    "heatmap = axs[0].imshow(all_probs_array.T, cmap='coolwarm', aspect='auto', interpolation='none')\n",
    "\n",
    "# Add colorbar to the heatmap subplot\n",
    "cbar = plt.colorbar(heatmap, ax=axs[0])\n",
    "\n",
    "# Set the axis labels and title for the heatmap subplot\n",
    "axs[0].set_xlabel('Time Step')\n",
    "axs[0].set_ylabel('Predicted State')\n",
    "axs[0].set_title('Probabilities of Predicting Output States')\n",
    "\n",
    "# Set the y-axis ticks and labels for the heatmap subplot\n",
    "axs[0].set_yticks(np.arange(len(y_labels)))\n",
    "axs[0].set_yticklabels(y_labels)\n",
    "\n",
    "# Create the second plot (line plot) in the second subplot\n",
    "axs[1].plot(np.arange(len(y_val)), y_val, color='green', label='Actual Values')\n",
    "axs[1].set_xlabel('Time Step')\n",
    "axs[1].set_ylabel('Actual Value')\n",
    "axs[1].set_title('Actual Test Values for Y')\n",
    "axs[1].legend()\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_values = y_val\n",
    "# Define the labels for the y-axis (predicted states)\n",
    "y_labels = ['1', '2', '3', '4']\n",
    "\n",
    "# Create a figure with a grid of subplots (2 rows, 1 column)\n",
    "fig, axs = plt.subplots(2,1, figsize=(8,10))\n",
    "\n",
    "# Create the first heatmap plot in the first subplot\n",
    "heatmap1 = axs[0].imshow(all_probs_array.T, cmap='coolwarm', aspect='auto', interpolation='none')\n",
    "\n",
    "# Add colorbar to the first heatmap subplot\n",
    "cbar1 = plt.colorbar(heatmap1, ax=axs[0])\n",
    "\n",
    "# Set the axis labels and title for the first heatmap subplot\n",
    "#axs[0].set_xlabel('Time Step')\n",
    "#axs[0].set_ylabel('Predicted State')\n",
    "axs[0].set_title('Predicted States Probabilities')\n",
    "\n",
    "# Set the y-axis ticks and labels for the first heatmap subplot\n",
    "axs[0].set_yticks(np.arange(len(y_labels)))\n",
    "axs[0].set_yticklabels(y_labels)\n",
    "\n",
    "# Create the second heatmap plot in the second subplot\n",
    "heatmap2 = axs[1].imshow(actual_values.T, cmap='coolwarm', aspect='auto', interpolation='none')\n",
    "\n",
    "# Add colorbar to the second heatmap subplot\n",
    "cbar2 = plt.colorbar(heatmap2, ax=axs[1])\n",
    "\n",
    "# Set the axis labels and title for the second heatmap subplot\n",
    "axs[1].set_xlabel('Time Step')\n",
    "#axs[1].set_ylabel('Predicted State')\n",
    "axs[1].set_title('True States')\n",
    "\n",
    "# Set the y-axis ticks and labels for the second heatmap subplot\n",
    "axs[1].set_yticks(np.arange(len(y_labels)))\n",
    "axs[1].set_yticklabels(y_labels)\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gates and hidden states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUCellNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.gru = nn.GRUCell(input_dim, hidden_dim, bias=True)                \n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.gru_cells = nn.ModuleList([\n",
    "            nn.GRUCell(input_dim, hidden_dim) if i == 0 else nn.GRUCell(hidden_dim, hidden_dim)\n",
    "            for i in range(num_layers)\n",
    "        ])\n",
    "        self.batch_norm = nn.BatchNorm1d(hidden_dim)  # Add BatchNorm outside GRU cells\n",
    "\n",
    "        \n",
    "        \n",
    "    def forward(self, x, h=None, hidden_states=None):\n",
    "        if h is None:\n",
    "            h = torch.zeros(x.size(0), self.hidden_dim)  # Initialize hidden state for the single layer\n",
    "\n",
    "        hidden_states = []  # Initialize a list to store hidden states at each time step\n",
    "\n",
    "        for t in range(x.size(1)):\n",
    "            input_t = x[:, t, :]\n",
    "            h = self.gru(input_t, h)  # Update the hidden state for the single layer\n",
    "            hidden_states.append(h)  # Append the hidden state for the current time step\n",
    "\n",
    "        h = self.batch_norm(h)  # Apply batch normalization to the final hidden state\n",
    "        out = self.fc(self.softplus(h))  # Calculate the output based on the final hidden state\n",
    "        out = torch.sigmoid(out)\n",
    "        out = torch.round(out)\n",
    "\n",
    "        # Return the output and the list of hidden states for the entire sequence\n",
    "        return out, h, hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, optimizer, loss_fn, scheduler=None, device=None):\n",
    "    epoch_loss = []\n",
    "    epoch_correct, epoch_total = 0, 0\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    predicted_probs = []\n",
    "    predicted_labels = []\n",
    "    hidden_states = []  # Initialize a list to store hidden states\n",
    "\n",
    "    for x, y in dataloader:\n",
    "        x = x.to(device).float()\n",
    "        y = y.to(device).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out, last_hidden_states, hidden_states_batch = model(x)  # Collect hidden states here\n",
    "        y_prob = torch.sigmoid(out)\n",
    "        # Append the predicted probabilities to the list\n",
    "        predicted_probs.append(y_prob.cpu().detach().numpy())\n",
    "        loss = loss_fn(out, y)\n",
    "        epoch_loss.append(loss.item())\n",
    "        \n",
    "        hidden_states.append(hidden_states_batch)  # Append hidden states to the list\n",
    "        \n",
    "        y_pred = torch.round(y_prob)\n",
    "        epoch_correct += sum((y == y_pred).flatten()).item()\n",
    "        epoch_total += y.numel()\n",
    "        \n",
    "        loss.backward()\n",
    "        torch_utils.clip_grad_norm_(model.parameters(), max_norm=10)\n",
    "        optimizer.step()\n",
    "\n",
    "        predicted_labels.extend(zip(y_pred.cpu().detach().cpu().numpy(), y.cpu().numpy()))\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "    \n",
    "    return np.mean(epoch_loss), accuracy(epoch_correct, epoch_total), predicted_labels, predicted_probs, hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(dataloader, model, loss_fn, device=None):\n",
    "    epoch_loss = []\n",
    "    epoch_correct, epoch_total = 0, 0\n",
    "    model = model.to(device).float()\n",
    "    model.eval()\n",
    "    predicted_probs = []\n",
    "    predicted_labels = []\n",
    "    hidden_states = []  # Initialize a list to store hidden states\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x = x.to(device).float()\n",
    "            y = y.to(device).float()\n",
    "            \n",
    "            out, last_hidden_states, hidden_states_batch = model(x)  # Collect hidden states here\n",
    "            \n",
    "            loss = loss_fn(out, y)\n",
    "            epoch_loss.append(loss.item())\n",
    "            \n",
    "            hidden_states.append(hidden_states_batch)  # Append hidden states to the list\n",
    "            \n",
    "            y_pred = torch.sigmoid(out)\n",
    "            predicted_probs.append(y_pred.cpu().detach().numpy())\n",
    "            y_pred = torch.round(y_pred)\n",
    "            epoch_correct += sum((y == y_pred).flatten())\n",
    "            epoch_total += y.numel()\n",
    "            predicted_labels.extend(zip(y_pred.cpu().numpy(), y.cpu().numpy()))\n",
    "    \n",
    "    return np.mean(epoch_loss), accuracy(epoch_correct, epoch_total), predicted_labels, predicted_probs, hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(train_dataloader, val_dataloader, model, optimizer, loss_fn, num_epochs, scheduler=None, device=None, schedule_on_train=True, verbose=True):\n",
    "    train_losses, train_accs = [], []\n",
    "    val_losses, val_accs = [], []\n",
    "\n",
    "    train_hidden_states, val_hidden_states = [], [] # Initialize lists to store hidden states\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_train_loss, epoch_train_acc, train_preds, train_probs, train_hidden = train(train_dataloader, model, optimizer, loss_fn, scheduler, device)\n",
    "        \n",
    "        train_losses.append(epoch_train_loss)\n",
    "        train_accs.append(epoch_train_acc)\n",
    "\n",
    "        train_hidden_states.extend(train_hidden)  # Append hidden states to the list\n",
    "        \n",
    "        if val_dataloader is not None:\n",
    "            epoch_val_loss, epoch_val_acc, val_preds, val_probs, val_hidden = validate(val_dataloader, model, loss_fn, device)\n",
    "        \n",
    "            val_losses.append(epoch_val_loss)\n",
    "            val_accs.append(epoch_val_acc)\n",
    "\n",
    "            val_hidden_states.extend(val_hidden)  # Append hidden states to the list\n",
    "        \n",
    "        #if isinstance(scheduler, ReduceLROnPlateau):\n",
    "        #    scheduler.step(epoch_train_acc if schedule_on_train or val_dataloader is None else epoch_val_acc)\n",
    "            \n",
    "        if epoch % 50 == 0:\n",
    "            val_str = f\", val loss: {epoch_val_loss}, val acc: {epoch_val_acc}\" if val_dataloader is not None else \"\"\n",
    "            print(f\"Epoch {epoch}, train loss: {epoch_train_loss}, train acc: {epoch_train_acc}{val_str}\")\n",
    "        if epoch == num_epochs - 1:  # Store values only for the final epoch\n",
    "            train_predicted_labels = train_preds\n",
    "            #val_predicted_labels = val_preds\n",
    "            train_probs_final = train_probs\n",
    "            #val_probs_final = val_probs\n",
    "            if val_dataloader is not None:\n",
    "                val_predicted_labels = val_preds\n",
    "                val_probs_final = val_probs\n",
    "\n",
    "    if val_dataloader is not None:        \n",
    "        return train_losses, train_accs, val_losses, val_accs, train_predicted_labels, val_predicted_labels, train_probs_final, val_probs_final, train_hidden_states, val_hidden_states\n",
    "    else: \n",
    "        return train_losses, train_accs, train_predicted_labels, train_probs_final, train_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['nose_x', 'nose_y', 'nose_z', 'headTop_x', 'headTop_y', 'headTop_z',\n",
       "       'neck_x', 'neck_y', 'neck_z', 'tailBase_x', 'tailBase_y', 'tailBase_z',\n",
       "       'lEar_x', 'lEar_y', 'lEar_z', 'lShoulder_x', 'lShoulder_y',\n",
       "       'lShoulder_z', 'lElbow_x', 'lElbow_y', 'lElbow_z', 'lWrist_x',\n",
       "       'lWrist_y', 'lWrist_z', 'lHip_x', 'lHip_y', 'lHip_z', 'rEar_x',\n",
       "       'rEar_y', 'rEar_z', 'rShoulder_x', 'rShoulder_y', 'rShoulder_z',\n",
       "       'rElbow_x', 'rElbow_y', 'rElbow_z', 'rWrist_x', 'rWrist_y', 'rWrist_z',\n",
       "       'rHip_x', 'rHip_y', 'rHip_z', 's_1', 's_2', 's_3', 's_4'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_drop = ['lKnee_x','lKnee_y','lKnee_z','lAnkle_x','lAnkle_y','lAnkle_z','rKnee_x','rKnee_y','rKnee_z','rAnkle_x','rAnkle_y','rAnkle_z']\n",
    "file = path + \"data_model_v3.csv\"\n",
    "df = pd.read_csv(file)\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "labels = ['s_1','s_2','s_3','s_4']\n",
    "data_to_scale = df.drop(columns=['id', 'trial'])\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(data_to_scale)\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=data_to_scale.columns)\n",
    "scaled_df[['id', 'trial']] = df[['id', 'trial']]\n",
    "cols_to_omit = ['id','trial']\n",
    "columns_to_shift = scaled_df.drop(cols_to_omit, axis=1).columns\n",
    "columns_to_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in train_dataloader:\n",
    "        x = x.to(device).float()\n",
    "        y = y.to(device).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out, last_hidden_states, batch_hidden_states = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_hidden_states[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batch_hidden_states[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states_array = batch_hidden_states[0][0].detach().numpy()\n",
    "hidden_states_array = hidden_states_array.T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with a single subplot\n",
    "fig, axs = plt.subplots(1, 1, figsize=(14,6))  # Adjust the figsize as needed\n",
    "\n",
    "# Create the heatmap plot in the single subplot\n",
    "heatmap = axs.imshow(hidden_states_array, cmap='coolwarm', aspect='auto', interpolation='none')\n",
    "\n",
    "# Add colorbar to the heatmap subplot\n",
    "cbar = plt.colorbar(heatmap, ax=axs)\n",
    "\n",
    "# Set the axis labels and title for the heatmap subplot\n",
    "axs.set_ylabel('hidden unit')\n",
    "axs.set_xlabel('time step')\n",
    "axs.set_title('Heatmap of hidden states')\n",
    "\n",
    "# Adjust spacing between the subplot\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df.shape[1]-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_dim = scaled_df.shape[1]-2\n",
    "hidden_dim = 34\n",
    "output_dim = 4\n",
    "num_layers = 1\n",
    "n_epochs =100\n",
    "lr = 0.01\n",
    "\n",
    "# Create an instance of GRUCellNet\n",
    "model = GRUCellNet(input_dim, hidden_dim, output_dim, num_layers)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "class_weights = torch.tensor([1.8]).to(device)\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=class_weights)  \n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_values = np.array([10,80,130])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train loss: 0.99318927526474, train acc: 0.6004935459377373\n",
      "Epoch 50, train loss: 0.08497070521116257, train acc: 0.9844343204252088\n",
      "Epoch 0, train loss: 0.43113425374031067, train acc: 0.8743532560214095\n",
      "Epoch 50, train loss: 0.18211303651332855, train acc: 0.9378679750223016\n",
      "Epoch 0, train loss: 0.3486967086791992, train acc: 0.8874617737003058\n",
      "Epoch 50, train loss: 0.2525496780872345, train acc: 0.904638124362895\n",
      "Epoch 0, train loss: 0.43490543961524963, train acc: 0.9182550115018074\n",
      "Epoch 50, train loss: 0.07446524500846863, train acc: 0.9850065724613868\n",
      "Epoch 0, train loss: 0.3527289927005768, train acc: 0.8772032902467685\n",
      "Epoch 50, train loss: 0.20687879621982574, train acc: 0.9199471210340776\n",
      "Epoch 0, train loss: 0.3726874589920044, train acc: 0.8681343622333182\n",
      "Epoch 50, train loss: 0.34488749504089355, train acc: 0.8746028143440763\n",
      "Epoch 0, train loss: 0.20412753522396088, train acc: 0.9521866582158136\n",
      "Epoch 50, train loss: 0.16878153383731842, train acc: 0.9604262398985898\n",
      "Epoch 0, train loss: 0.1832096129655838, train acc: 0.9315794410054399\n",
      "Epoch 50, train loss: 0.18222378194332123, train acc: 0.9335490527105609\n",
      "Epoch 0, train loss: 0.3256382346153259, train acc: 0.876592528611531\n",
      "Epoch 50, train loss: 0.3240588307380676, train acc: 0.877780177067588\n",
      "Epoch 0, train loss: 0.16090203821659088, train acc: 0.9623314829500397\n",
      "Epoch 50, train loss: 0.16017913818359375, train acc: 0.9624504361617764\n",
      "Epoch 0, train loss: 0.18131472170352936, train acc: 0.9329107981220657\n",
      "Epoch 50, train loss: 0.18129833042621613, train acc: 0.9329107981220657\n",
      "Epoch 0, train loss: 0.3272723853588104, train acc: 0.8788648648648648\n",
      "Epoch 50, train loss: 0.3272233009338379, train acc: 0.8788648648648648\n",
      "Epoch 0, train loss: 0.17304927110671997, train acc: 0.956870043696391\n",
      "Epoch 50, train loss: 0.17301636934280396, train acc: 0.956870043696391\n",
      "Epoch 0, train loss: 0.18730944395065308, train acc: 0.9333044816310829\n",
      "Epoch 50, train loss: 0.18730823695659637, train acc: 0.9333044816310829\n",
      "Epoch 0, train loss: 0.33237120509147644, train acc: 0.8749722160480107\n",
      "Epoch 50, train loss: 0.33236998319625854, train acc: 0.8749722160480107\n",
      "Epoch 0, train loss: 0.1716112494468689, train acc: 0.9597658808120497\n",
      "Epoch 50, train loss: 0.17161104083061218, train acc: 0.9597658808120497\n",
      "Epoch 0, train loss: 0.19612698256969452, train acc: 0.9316010140405616\n",
      "Epoch 50, train loss: 0.19612698256969452, train acc: 0.9316010140405616\n",
      "Epoch 0, train loss: 0.33461084961891174, train acc: 0.8773148148148148\n",
      "Epoch 50, train loss: 0.33461084961891174, train acc: 0.8773148148148148\n",
      "Epoch 0, train loss: 0.1586802750825882, train acc: 0.9634836065573771\n",
      "Epoch 50, train loss: 0.1586802750825882, train acc: 0.9634836065573771\n",
      "Epoch 0, train loss: 0.18959751725196838, train acc: 0.926123046875\n",
      "Epoch 50, train loss: 0.18959751725196838, train acc: 0.926123046875\n",
      "Epoch 0, train loss: 0.3384883999824524, train acc: 0.8721719457013575\n",
      "Epoch 50, train loss: 0.3384883999824524, train acc: 0.8721719457013575\n",
      "Epoch 0, train loss: 0.15686364471912384, train acc: 0.9620009430996542\n",
      "Epoch 50, train loss: 0.15686364471912384, train acc: 0.9620009430996542\n",
      "Epoch 0, train loss: 0.1761421412229538, train acc: 0.9358045336306205\n",
      "Epoch 50, train loss: 0.1761421412229538, train acc: 0.9358045336306205\n",
      "Epoch 0, train loss: 0.31047919392585754, train acc: 0.8850384451089278\n",
      "Epoch 50, train loss: 0.31047919392585754, train acc: 0.8850384451089278\n",
      "Epoch 0, train loss: 0.15053516626358032, train acc: 0.9658147484942211\n",
      "Epoch 50, train loss: 0.15053516626358032, train acc: 0.9658147484942211\n",
      "Epoch 0, train loss: 0.19236014783382416, train acc: 0.9261572729033508\n",
      "Epoch 50, train loss: 0.19236014783382416, train acc: 0.9261572729033508\n",
      "Epoch 0, train loss: 0.34757092595100403, train acc: 0.87138695944432\n",
      "Epoch 50, train loss: 0.34757092595100403, train acc: 0.87138695944432\n",
      "Epoch 0, train loss: 0.16347695887088776, train acc: 0.9592670401493931\n",
      "Epoch 50, train loss: 0.16347695887088776, train acc: 0.9592670401493931\n",
      "Epoch 0, train loss: 0.17688846588134766, train acc: 0.9364671318398825\n",
      "Epoch 50, train loss: 0.17688846588134766, train acc: 0.9364671318398825\n",
      "Epoch 0, train loss: 0.3195754885673523, train acc: 0.8832701222081754\n",
      "Epoch 50, train loss: 0.3195754885673523, train acc: 0.8832701222081754\n",
      "Epoch 0, train loss: 0.15976805984973907, train acc: 0.9597117202268431\n",
      "Epoch 50, train loss: 0.15976805984973907, train acc: 0.9597117202268431\n",
      "Epoch 0, train loss: 0.18115605413913727, train acc: 0.9354042473919523\n",
      "Epoch 50, train loss: 0.18115605413913727, train acc: 0.9354042473919523\n",
      "Epoch 0, train loss: 0.3274189233779907, train acc: 0.8799271636675235\n",
      "Epoch 50, train loss: 0.3274189233779907, train acc: 0.8799271636675235\n",
      "Epoch 0, train loss: 0.1595577448606491, train acc: 0.9623202001250781\n",
      "Epoch 50, train loss: 0.1595577448606491, train acc: 0.9623202001250781\n",
      "Epoch 0, train loss: 0.17294396460056305, train acc: 0.9335764401772526\n",
      "Epoch 50, train loss: 0.17294396460056305, train acc: 0.9335764401772526\n",
      "Epoch 0, train loss: 0.31131380796432495, train acc: 0.883481764206955\n",
      "Epoch 50, train loss: 0.31131380796432495, train acc: 0.883481764206955\n",
      "Epoch 0, train loss: 0.15928839147090912, train acc: 0.9598129359543437\n",
      "Epoch 50, train loss: 0.15928839147090912, train acc: 0.9598129359543437\n",
      "Epoch 0, train loss: 0.178154855966568, train acc: 0.9354823573573574\n",
      "Epoch 50, train loss: 0.178154855966568, train acc: 0.9354823573573574\n",
      "Epoch 0, train loss: 0.3210528492927551, train acc: 0.8809961106309421\n",
      "Epoch 50, train loss: 0.3210528492927551, train acc: 0.8809961106309421\n",
      "Epoch 0, train loss: 0.15765558183193207, train acc: 0.9605516356638871\n",
      "Epoch 50, train loss: 0.15765558183193207, train acc: 0.9605516356638871\n",
      "Epoch 0, train loss: 0.17631839215755463, train acc: 0.9354547184170472\n",
      "Epoch 50, train loss: 0.17631839215755463, train acc: 0.9354547184170472\n",
      "Epoch 0, train loss: 0.3071252107620239, train acc: 0.8826821773485514\n",
      "Epoch 50, train loss: 0.3071252107620239, train acc: 0.8826821773485514\n",
      "Epoch 0, train loss: 0.15200155973434448, train acc: 0.9619014194353455\n",
      "Epoch 50, train loss: 0.15200155973434448, train acc: 0.9619014194353455\n",
      "Epoch 0, train loss: 0.1814945787191391, train acc: 0.930445590130731\n",
      "Epoch 50, train loss: 0.1814945787191391, train acc: 0.930445590130731\n",
      "Epoch 0, train loss: 0.32141032814979553, train acc: 0.8780384696681462\n",
      "Epoch 50, train loss: 0.32141032814979553, train acc: 0.8780384696681462\n"
     ]
    }
   ],
   "source": [
    "#hidden_states_all = []\n",
    "hidden_states_dict = {}\n",
    "for j in np.arange(1,16):\n",
    "    for i in shift_values:\n",
    "        shift = i\n",
    "        set_values = j\n",
    "        model_name = 's_m'+str(shift)+'_'+'val'+str(set_values)+'_gates'\n",
    "\n",
    "\n",
    "        # Create an empty DataFrame to store the shifted data\n",
    "        shifted_df = pd.DataFrame()\n",
    "\n",
    "        # Loop through unique trial values\n",
    "        for trial_value in scaled_df['trial'].unique():\n",
    "            # Filter the DataFrame for the current trial\n",
    "            trial_df = scaled_df[scaled_df['trial'] == trial_value].copy()\n",
    "\n",
    "            # Create shifted columns for each column in columns_to_shift\n",
    "            for col in columns_to_shift:\n",
    "                new_col_name = col + '_minus_' + str(shift)\n",
    "                trial_df[new_col_name] = trial_df[col].shift(shift)\n",
    "\n",
    "            # Drop the last 'i' records for each trial\n",
    "            trial_df = trial_df.dropna()\n",
    "\n",
    "            # Append the modified trial_df to the shifted_df\n",
    "            shifted_df = shifted_df.append(trial_df, ignore_index=True)\n",
    "        \n",
    "        #selected_columns = ['id', 'trial','s_1_minus_'+str(shift),'s_2_minus_'+str(shift),'s_3_minus_'+str(shift),'s_4_minus_'+str(shift),'s_1','s_2','s_3','s_4']\n",
    "        selected_columns = ['id', 'trial','nose_x_minus_'+str(shift), 'nose_y_minus_'+str(shift),\n",
    "        'nose_z_minus_'+str(shift), 'headTop_x_minus_'+str(shift), 'headTop_y_minus_'+str(shift),\n",
    "        'headTop_z_minus_'+str(shift), 'neck_x_minus_'+str(shift), 'neck_y_minus_'+str(shift),\n",
    "        'neck_z_minus_'+str(shift), 'tailBase_x_minus_'+str(shift), 'tailBase_y_minus_'+str(shift),\n",
    "        'tailBase_z_minus_'+str(shift), 'lEar_x_minus_'+str(shift), 'lEar_y_minus_'+str(shift),\n",
    "        'lEar_z_minus_'+str(shift), 'lShoulder_x_minus_'+str(shift), 'lShoulder_y_minus_'+str(shift),\n",
    "        'lShoulder_z_minus_'+str(shift), 'lElbow_x_minus_'+str(shift), 'lElbow_y_minus_'+str(shift),\n",
    "        'lElbow_z_minus_'+str(shift), 'lWrist_x_minus_'+str(shift), 'lWrist_y_minus_'+str(shift),\n",
    "        'lWrist_z_minus_'+str(shift), 'lHip_x_minus_'+str(shift), 'lHip_y_minus_'+str(shift),\n",
    "        'lHip_z_minus_'+str(shift), 'rEar_x_minus_'+str(shift), 'rEar_y_minus_'+str(shift), 'rEar_z_minus_'+str(shift),\n",
    "        'rShoulder_x_minus_'+str(shift), 'rShoulder_y_minus_'+str(shift), 'rShoulder_z_minus_'+str(shift),\n",
    "        'rElbow_x_minus_'+str(shift), 'rElbow_y_minus_'+str(shift), 'rElbow_z_minus_'+str(shift),\n",
    "        'rWrist_x_minus_'+str(shift), 'rWrist_y_minus_'+str(shift), 'rWrist_z_minus_'+str(shift),\n",
    "        'rHip_x_minus_'+str(shift), 'rHip_y_minus_'+str(shift), 'rHip_z_minus_'+str(shift), 's_1_minus_'+str(shift),\n",
    "        's_2_minus_'+str(shift), 's_3_minus_'+str(shift), 's_4_minus_'+str(shift),'s_1','s_2','s_3','s_4']\n",
    "        shifted_df = shifted_df[selected_columns]\n",
    "        # Step 5: Split the data into training and test sets based on the 'trial' column\n",
    "        train_set = shifted_df[shifted_df['trial']!=set_values].drop(columns=['id', 'trial'])\n",
    "        test_set = shifted_df[shifted_df['trial']==set_values].drop(columns=['id', 'trial'])\n",
    "        full_set = shifted_df.drop(columns=['id','trial'])\n",
    "\n",
    "        # split data into x and y \n",
    "        X_train, y_train = train_set.drop(columns=labels), train_set[labels]\n",
    "        X_test, y_test = test_set.drop(columns=labels), test_set[labels]\n",
    "        X, y = full_set.drop(columns=labels), full_set[labels]\n",
    "        \n",
    "        # reset index \n",
    "        X_train, y_train = X_train.reset_index(drop=True), y_train.reset_index(drop=True)\n",
    "        X_test, y_test = X_test.reset_index(drop=True), y_test.reset_index(drop=True)\n",
    "        X, y = X.reset_index(drop=True), y.reset_index(drop=True) \n",
    "\n",
    "        # Create custom datasets for training, validation, and testing\n",
    "        full_dataset = MyDataset(torch.tensor(X.values), torch.tensor(y.values))\n",
    "        train_dataset = MyDataset(torch.tensor(X_train.values), torch.tensor(y_train.values))\n",
    "        test_dataset = MyDataset(torch.tensor(X_test.values), torch.tensor(y_test.values))\n",
    "\n",
    "        fullset_dataloader = DataLoader(full_dataset, batch_size=X.shape[0], shuffle=False)\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=X_train.shape[0], shuffle=False)\n",
    "        test_dataloader = DataLoader(test_dataset, batch_size=X_test.shape[0], shuffle=False)\n",
    "        #print(X_train.shape[0])\n",
    "        \n",
    "\n",
    "        train_losses, train_accs, train_predicted_labels, train_probs_final, train_hidden_states = run_training(\n",
    "            train_dataloader, val_dataloader=None, model=model, optimizer=optimizer, loss_fn=loss_fn, num_epochs=n_epochs, scheduler=scheduler)\n",
    "        \n",
    "        #hidden_states_dict[(shift, set_values)] = train_hidden_states\n",
    "        \n",
    "        all_preds = []\n",
    "        all_probs = []\n",
    "        hidden_states = []\n",
    "\n",
    "        # Iterate through the test data batches\n",
    "        for inputs, _ in train_dataloader:\n",
    "            inputs = inputs.float()\n",
    "            # Forward pass to get predictions\n",
    "            with torch.no_grad():\n",
    "                predictions, h, test_hidden_states = model(inputs)\n",
    "                probabilities = torch.sigmoid(predictions)\n",
    "                preds = torch.round(probabilities)\n",
    "\n",
    "            # Append predictions to the list\n",
    "            all_preds.append(preds)\n",
    "            all_probs.append(probabilities)\n",
    "            hidden_states.append(test_hidden_states)\n",
    "        \n",
    "        #print(hidden_states[0][0])    \n",
    "        hidden_states_array = hidden_states[0][0].detach().numpy()\n",
    "        hidden_states_array = hidden_states_array.T\n",
    "        #print(hidden_states_array.shape) \n",
    "        \n",
    "        # Concatenate the predicted batches\n",
    "        all_preds = torch.cat(all_preds, dim=0)\n",
    "        all_probs = torch.cat(all_probs, dim=0)\n",
    "\n",
    "        all_preds_array = all_preds.numpy()\n",
    "        all_probs_array = all_probs.numpy()\n",
    "\n",
    "\n",
    "        columns = ['s_1','s_2','s_3','s_4']\n",
    "        all_probs_df = pd.DataFrame(all_probs_array)\n",
    "        all_probs_df.columns = columns\n",
    "        # Convert the tensor of predictions to a DataFrame\n",
    "        predictions_df = pd.DataFrame(all_preds_array, columns=y_train.columns, index=y_train.index)\n",
    "        # Calculate accuracy for each output state\n",
    "        \n",
    "        # Create a figure with a single subplot\n",
    "        fig, axs = plt.subplots(2, 1, figsize=(16,10))  # Adjust the figsize as needed\n",
    "\n",
    "        # Create the heatmap plot in the single subplot\n",
    "        heatmap = axs[0].imshow(hidden_states_array, cmap='seismic', aspect='auto', interpolation='none')\n",
    "\n",
    "        # Add colorbar to the heatmap subplot\n",
    "        #cbar = plt.colorbar(heatmap, ax=axs)\n",
    "\n",
    "        # Set the axis labels and title for the heatmap subplot\n",
    "        axs[0].set_ylabel('hidden unit')\n",
    "        axs[0].set_xlabel('time step')\n",
    "        axs[0].set_title('Heatmap of hidden states for s='+str(i)+' trial='+str(j))\n",
    "        \n",
    "        axs[1].imshow(all_probs_array.T, cmap='seismic', aspect='auto', interpolation='none')\n",
    "        y_labels = ['1', '2', '3', '4']\n",
    "        axs[1].set_yticks(np.arange(len(y_labels)))\n",
    "        axs[1].set_yticklabels(y_labels)\n",
    "        \n",
    "        # Add colorbar to the heatmap subplot\n",
    "        #cbar = plt.colorbar(heatmap, ax=axs)\n",
    "        plot_title = 'solo_s'+str(i)+'_val'+str(j)\n",
    "        #plt.title(plot_title)\n",
    "        # Set the axis labels and title for the heatmap subplot\n",
    "        axs[0].set_ylabel('predictions')\n",
    "        axs[0].set_xlabel('time step')\n",
    "        #axs[0].set_title()\n",
    "        # Adjust spacing between the subplot\n",
    "        plt.tight_layout()\n",
    "        # Show the plot\n",
    "        # Specify the file path\n",
    "        # Specify the directory where you want to save the plots\n",
    "        save_directory = r'C:\\Users\\kacpe\\Desktop\\study\\research lab\\lab_rotation_git\\hidden_states_heatmaps_train'\n",
    "\n",
    "        # Create the directory if it doesn't exist\n",
    "        os.makedirs(save_directory, exist_ok=True)\n",
    "\n",
    "        # Define the plot title\n",
    "        plot_title = f'solo_s{i}_val{j}'\n",
    "\n",
    "        # Specify the file path using os.path.join\n",
    "        file_path = os.path.join(save_directory, f'{plot_title}.png')\n",
    "\n",
    "        # Save the plot to the specified path\n",
    "        fig.savefig(file_path)\n",
    "        #plt.show()\n",
    "        plt.close()\n",
    "                \n",
    "        \n",
    "       \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_dim = scaled_df.shape[1]-2\n",
    "hidden_dim = 34\n",
    "output_dim = 4\n",
    "num_layers = 1\n",
    "n_epochs =100\n",
    "lr = 0.01\n",
    "\n",
    "# Create an instance of GRUCellNet\n",
    "model = GRUCellNet(input_dim, hidden_dim, output_dim, num_layers)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "class_weights = torch.tensor([1.8]).to(device)\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=class_weights)  \n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train loss: 0.14604417979717255, train acc: 0.9692057704502219\n",
      "Epoch 50, train loss: 0.14604417979717255, train acc: 0.9692057704502219\n",
      "Epoch 0, train loss: 0.19220440089702606, train acc: 0.9305086336336337\n",
      "Epoch 50, train loss: 0.19220440089702606, train acc: 0.9305086336336337\n",
      "Epoch 0, train loss: 0.32724639773368835, train acc: 0.8729472774416595\n",
      "Epoch 50, train loss: 0.32724639773368835, train acc: 0.8729472774416595\n",
      "Epoch 0, train loss: 0.14533913135528564, train acc: 0.9692511225144324\n",
      "Epoch 50, train loss: 0.14533913135528564, train acc: 0.9692511225144324\n",
      "Epoch 0, train loss: 0.19234581291675568, train acc: 0.9297945205479452\n",
      "Epoch 50, train loss: 0.19234581291675568, train acc: 0.9297945205479452\n",
      "Epoch 0, train loss: 0.3151167333126068, train acc: 0.8735733099209834\n",
      "Epoch 50, train loss: 0.3151167333126068, train acc: 0.8735733099209834\n"
     ]
    }
   ],
   "source": [
    "#hidden_states_all = []\n",
    "hidden_states_dict = {}\n",
    "for j in np.arange(13,15):\n",
    "    for i in shift_values:\n",
    "        shift = i\n",
    "        set_values = j\n",
    "        model_name = 's_m'+str(shift)+'_'+'val'+str(set_values)+'_gates'\n",
    "\n",
    "\n",
    "        # Create an empty DataFrame to store the shifted data\n",
    "        shifted_df = pd.DataFrame()\n",
    "\n",
    "        # Loop through unique trial values\n",
    "        for trial_value in scaled_df['trial'].unique():\n",
    "            # Filter the DataFrame for the current trial\n",
    "            trial_df = scaled_df[scaled_df['trial'] == trial_value].copy()\n",
    "\n",
    "            # Create shifted columns for each column in columns_to_shift\n",
    "            for col in columns_to_shift:\n",
    "                new_col_name = col + '_minus_' + str(shift)\n",
    "                trial_df[new_col_name] = trial_df[col].shift(shift)\n",
    "\n",
    "            # Drop the last 'i' records for each trial\n",
    "            trial_df = trial_df.dropna()\n",
    "\n",
    "            # Append the modified trial_df to the shifted_df\n",
    "            shifted_df = shifted_df.append(trial_df, ignore_index=True)\n",
    "        \n",
    "        #selected_columns = ['id', 'trial','s_1_minus_'+str(shift),'s_2_minus_'+str(shift),'s_3_minus_'+str(shift),'s_4_minus_'+str(shift),'s_1','s_2','s_3','s_4']\n",
    "        selected_columns = ['id', 'trial','nose_x_minus_'+str(shift), 'nose_y_minus_'+str(shift),\n",
    "        'nose_z_minus_'+str(shift), 'headTop_x_minus_'+str(shift), 'headTop_y_minus_'+str(shift),\n",
    "        'headTop_z_minus_'+str(shift), 'neck_x_minus_'+str(shift), 'neck_y_minus_'+str(shift),\n",
    "        'neck_z_minus_'+str(shift), 'tailBase_x_minus_'+str(shift), 'tailBase_y_minus_'+str(shift),\n",
    "        'tailBase_z_minus_'+str(shift), 'lEar_x_minus_'+str(shift), 'lEar_y_minus_'+str(shift),\n",
    "        'lEar_z_minus_'+str(shift), 'lShoulder_x_minus_'+str(shift), 'lShoulder_y_minus_'+str(shift),\n",
    "        'lShoulder_z_minus_'+str(shift), 'lElbow_x_minus_'+str(shift), 'lElbow_y_minus_'+str(shift),\n",
    "        'lElbow_z_minus_'+str(shift), 'lWrist_x_minus_'+str(shift), 'lWrist_y_minus_'+str(shift),\n",
    "        'lWrist_z_minus_'+str(shift), 'lHip_x_minus_'+str(shift), 'lHip_y_minus_'+str(shift),\n",
    "        'lHip_z_minus_'+str(shift), 'rEar_x_minus_'+str(shift), 'rEar_y_minus_'+str(shift), 'rEar_z_minus_'+str(shift),\n",
    "        'rShoulder_x_minus_'+str(shift), 'rShoulder_y_minus_'+str(shift), 'rShoulder_z_minus_'+str(shift),\n",
    "        'rElbow_x_minus_'+str(shift), 'rElbow_y_minus_'+str(shift), 'rElbow_z_minus_'+str(shift),\n",
    "        'rWrist_x_minus_'+str(shift), 'rWrist_y_minus_'+str(shift), 'rWrist_z_minus_'+str(shift),\n",
    "        'rHip_x_minus_'+str(shift), 'rHip_y_minus_'+str(shift), 'rHip_z_minus_'+str(shift), 's_1_minus_'+str(shift),\n",
    "        's_2_minus_'+str(shift), 's_3_minus_'+str(shift), 's_4_minus_'+str(shift),'s_1','s_2','s_3','s_4']\n",
    "        shifted_df = shifted_df[selected_columns]\n",
    "        # Step 5: Split the data into training and test sets based on the 'trial' column\n",
    "        train_set = shifted_df[shifted_df['trial']!=set_values].drop(columns=['id', 'trial'])\n",
    "        test_set = shifted_df[shifted_df['trial']==set_values].drop(columns=['id', 'trial'])\n",
    "        full_set = shifted_df.drop(columns=['id','trial'])\n",
    "\n",
    "        # split data into x and y \n",
    "        X_train, y_train = train_set.drop(columns=labels), train_set[labels]\n",
    "        X_test, y_test = test_set.drop(columns=labels), test_set[labels]\n",
    "        X, y = full_set.drop(columns=labels), full_set[labels]\n",
    "        \n",
    "        # reset index \n",
    "        X_train, y_train = X_train.reset_index(drop=True), y_train.reset_index(drop=True)\n",
    "        X_test, y_test = X_test.reset_index(drop=True), y_test.reset_index(drop=True)\n",
    "        X, y = X.reset_index(drop=True), y.reset_index(drop=True) \n",
    "\n",
    "        # Create custom datasets for training, validation, and testing\n",
    "        full_dataset = MyDataset(torch.tensor(X.values), torch.tensor(y.values))\n",
    "        train_dataset = MyDataset(torch.tensor(X_train.values), torch.tensor(y_train.values))\n",
    "        test_dataset = MyDataset(torch.tensor(X_test.values), torch.tensor(y_test.values))\n",
    "\n",
    "        fullset_dataloader = DataLoader(full_dataset, batch_size=X.shape[0], shuffle=False)\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=X_train.shape[0], shuffle=False)\n",
    "        test_dataloader = DataLoader(test_dataset, batch_size=X_test.shape[0], shuffle=False)\n",
    "        #print(X_train.shape[0])\n",
    "        \n",
    "\n",
    "        train_losses, train_accs, train_predicted_labels, train_probs_final, train_hidden_states = run_training(\n",
    "            train_dataloader, val_dataloader=None, model=model, optimizer=optimizer, loss_fn=loss_fn, num_epochs=n_epochs, scheduler=scheduler)\n",
    "        \n",
    "        #hidden_states_dict[(shift, set_values)] = train_hidden_states\n",
    "        \n",
    "        all_preds = []\n",
    "        all_probs = []\n",
    "        hidden_states = []\n",
    "\n",
    "        # Iterate through the test data batches\n",
    "        for inputs, _ in test_dataloader:\n",
    "            inputs = inputs.float()\n",
    "            # Forward pass to get predictions\n",
    "            with torch.no_grad():\n",
    "                predictions, h, test_hidden_states = model(inputs)\n",
    "                probabilities = torch.sigmoid(predictions)\n",
    "                preds = torch.round(probabilities)\n",
    "\n",
    "            # Append predictions to the list\n",
    "            all_preds.append(preds)\n",
    "            all_probs.append(probabilities)\n",
    "            hidden_states.append(test_hidden_states)\n",
    "        \n",
    "        #print(hidden_states[0][0])    \n",
    "        hidden_states_array = hidden_states[0][0].detach().numpy()\n",
    "        hidden_states_array = hidden_states_array.T\n",
    "        #print(hidden_states_array.shape) \n",
    "        \n",
    "        # Concatenate the predicted batches\n",
    "        all_preds = torch.cat(all_preds, dim=0)\n",
    "        all_probs = torch.cat(all_probs, dim=0)\n",
    "\n",
    "        all_preds_array = all_preds.numpy()\n",
    "        all_probs_array = all_probs.numpy()\n",
    "        h_name = 'hidden_s'+str(i)+'_trial'+str(j)\n",
    "        p_name = 'probs_s'+str(i)+'_trial'+str(j)\n",
    "        np.save(h_name, hidden_states_array)\n",
    "        np.save(p_name, all_probs_array)\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "        \n",
    "       \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('hidden_states.npy', hidden_states_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_value = list(hidden_states_dict.values())[0]\n",
    "type(first_value)\n",
    "hidden_states_array = first_value[0][0].detach().numpy()\n",
    "hidden_states_array = hidden_states_array.T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with a single subplot\n",
    "fig, axs = plt.subplots(2, 1, figsize=(14,6))  # Adjust the figsize as needed\n",
    "\n",
    "# Create the heatmap plot in the single subplot\n",
    "heatmap = axs[0].imshow(hidden_states_array, cmap='seismic', aspect='auto', interpolation='none')\n",
    "\n",
    "# Add colorbar to the heatmap subplot\n",
    "cbar = plt.colorbar(heatmap, ax=axs)\n",
    "\n",
    "# Set the axis labels and title for the heatmap subplot\n",
    "axs[0].set_ylabel('hidden unit')\n",
    "axs[0].set_xlabel('time step')\n",
    "axs[0].set_title('Heatmap of hidden states')\n",
    "\n",
    "\n",
    "\n",
    "# Adjust spacing between the subplot\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Specify the folder path and the model filename\n",
    "        folder_path = 'C:/Users/kacpe/Desktop/study/research lab/lab_rotation_git/models' \n",
    "        model_filename = model_name + '.pth'  \n",
    "\n",
    "        # Combine the folder path and model filename\n",
    "        full_model = os.path.join(folder_path, model_filename)\n",
    "\n",
    "        # Save the model to the specified folder\n",
    "        torch.save(state_dict, full_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['nose_x', 'nose_y', 'nose_z', 'headTop_x', 'headTop_y', 'headTop_z',\n",
       "       'neck_x', 'neck_y', 'neck_z', 'tailBase_x', 'tailBase_y', 'tailBase_z',\n",
       "       'lEar_x', 'lEar_y', 'lEar_z', 'lShoulder_x', 'lShoulder_y',\n",
       "       'lShoulder_z', 'lElbow_x', 'lElbow_y', 'lElbow_z', 'lWrist_x',\n",
       "       'lWrist_y', 'lWrist_z', 'lHip_x', 'lHip_y', 'lHip_z', 'rEar_x',\n",
       "       'rEar_y', 'rEar_z', 'rShoulder_x', 'rShoulder_y', 'rShoulder_z',\n",
       "       'rElbow_x', 'rElbow_y', 'rElbow_z', 'rWrist_x', 'rWrist_y', 'rWrist_z',\n",
       "       'rHip_x', 'rHip_y', 'rHip_z', 's_1', 's_2', 's_3', 's_4'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_drop = ['lKnee_x','lKnee_y','lKnee_z','lAnkle_x','lAnkle_y','lAnkle_z','rKnee_x','rKnee_y','rKnee_z','rAnkle_x','rAnkle_y','rAnkle_z']\n",
    "file_path = os.path.join(data_folder, \"data_model_v3.csv\")\n",
    "df = pd.read_csv(file_path)\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "labels = ['s_1','s_2','s_3','s_4']\n",
    "data_to_scale = df.drop(columns=['id', 'trial'])\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(data_to_scale)\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=data_to_scale.columns)\n",
    "scaled_df[['id', 'trial']] = df[['id', 'trial']]\n",
    "cols_to_omit = ['id','trial']\n",
    "columns_to_shift = scaled_df.drop(cols_to_omit, axis=1).columns\n",
    "\n",
    "columns_to_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_dim = scaled_df.shape[1]-2\n",
    "hidden_dim = 34\n",
    "output_dim = 4\n",
    "num_layers = 1\n",
    "n_epochs =10\n",
    "lr = 0.01\n",
    "\n",
    "# Create an instance of GRUCellNet\n",
    "model = GRUCellNet(input_dim, hidden_dim, output_dim, num_layers)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "class_weights = torch.tensor([1.8]).to(device)\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=class_weights)  \n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.9, mode=\"min\", patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function GRUCellNet.forward at 0x000001948FC91670>\n"
     ]
    }
   ],
   "source": [
    "print(GRUCellNet.forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train loss: 1.093435525894165, train acc: 0.41514227642276424\n",
      "s_m10_val12_gates\n",
      "0.7213235294117647\n"
     ]
    }
   ],
   "source": [
    "#hidden_states_all = []\n",
    "hidden_states_dict = {}\n",
    "predictions_dict_sm = {}\n",
    "\n",
    "for j in np.arange(12,13):\n",
    "    for i in np.arange(10,11,10):\n",
    "        shift = i\n",
    "        set_values = j\n",
    "        model_name = 's_m'+str(shift)+'_'+'val'+str(set_values)+'_gates'\n",
    "\n",
    "\n",
    "        # Create an empty DataFrame to store the shifted data\n",
    "        shifted_df = pd.DataFrame()\n",
    "\n",
    "        # Loop through unique trial values\n",
    "        for trial_value in scaled_df['trial'].unique():\n",
    "            # Filter the DataFrame for the current trial\n",
    "            trial_df = scaled_df[scaled_df['trial'] == trial_value].copy()\n",
    "\n",
    "            # Create shifted columns for each column in columns_to_shift\n",
    "            for col in columns_to_shift:\n",
    "                new_col_name = col + '_minus_' + str(shift)\n",
    "                trial_df[new_col_name] = trial_df[col].shift(shift)\n",
    "\n",
    "            # Drop the last 'i' records for each trial\n",
    "            trial_df = trial_df.dropna()\n",
    "\n",
    "            # Append the modified trial_df to the shifted_df\n",
    "            shifted_df = shifted_df.append(trial_df, ignore_index=True)\n",
    "        \n",
    "        #selected_columns = ['id', 'trial','s_1_minus_'+str(shift),'s_2_minus_'+str(shift),'s_3_minus_'+str(shift),'s_4_minus_'+str(shift),'s_1','s_2','s_3','s_4']\n",
    "        selected_columns = ['id', 'trial','nose_x_minus_'+str(shift), 'nose_y_minus_'+str(shift),\n",
    "        'nose_z_minus_'+str(shift), 'headTop_x_minus_'+str(shift), 'headTop_y_minus_'+str(shift),\n",
    "        'headTop_z_minus_'+str(shift), 'neck_x_minus_'+str(shift), 'neck_y_minus_'+str(shift),\n",
    "        'neck_z_minus_'+str(shift), 'tailBase_x_minus_'+str(shift), 'tailBase_y_minus_'+str(shift),\n",
    "        'tailBase_z_minus_'+str(shift), 'lEar_x_minus_'+str(shift), 'lEar_y_minus_'+str(shift),\n",
    "        'lEar_z_minus_'+str(shift), 'lShoulder_x_minus_'+str(shift), 'lShoulder_y_minus_'+str(shift),\n",
    "        'lShoulder_z_minus_'+str(shift), 'lElbow_x_minus_'+str(shift), 'lElbow_y_minus_'+str(shift),\n",
    "        'lElbow_z_minus_'+str(shift), 'lWrist_x_minus_'+str(shift), 'lWrist_y_minus_'+str(shift),\n",
    "        'lWrist_z_minus_'+str(shift), 'lHip_x_minus_'+str(shift), 'lHip_y_minus_'+str(shift),\n",
    "        'lHip_z_minus_'+str(shift), 'rEar_x_minus_'+str(shift), 'rEar_y_minus_'+str(shift), 'rEar_z_minus_'+str(shift),\n",
    "        'rShoulder_x_minus_'+str(shift), 'rShoulder_y_minus_'+str(shift), 'rShoulder_z_minus_'+str(shift),\n",
    "        'rElbow_x_minus_'+str(shift), 'rElbow_y_minus_'+str(shift), 'rElbow_z_minus_'+str(shift),\n",
    "        'rWrist_x_minus_'+str(shift), 'rWrist_y_minus_'+str(shift), 'rWrist_z_minus_'+str(shift),\n",
    "        'rHip_x_minus_'+str(shift), 'rHip_y_minus_'+str(shift), 'rHip_z_minus_'+str(shift), 's_1_minus_'+str(shift),\n",
    "        's_2_minus_'+str(shift), 's_3_minus_'+str(shift), 's_4_minus_'+str(shift),'s_1','s_2','s_3','s_4']\n",
    "        shifted_df = shifted_df[selected_columns]\n",
    "        # Step 5: Split the data into training and test sets based on the 'trial' column\n",
    "        train_set = shifted_df[shifted_df['trial']!=set_values].drop(columns=['id', 'trial'])\n",
    "        test_set = shifted_df[shifted_df['trial']==set_values].drop(columns=['id', 'trial'])\n",
    "        full_set = shifted_df.drop(columns=['id','trial'])\n",
    "        \n",
    "        # split data into x and y \n",
    "        X_train, y_train = train_set.drop(columns=labels), train_set[labels]\n",
    "        X_test, y_test = test_set.drop(columns=labels), test_set[labels]\n",
    "        X, y = full_set.drop(columns=labels), full_set[labels]\n",
    "        #print(X_train.columns)\n",
    "        # reset index \n",
    "        X_train, y_train = X_train.reset_index(drop=True), y_train.reset_index(drop=True)\n",
    "        X_test, y_test = X_test.reset_index(drop=True), y_test.reset_index(drop=True)\n",
    "        X, y = X.reset_index(drop=True), y.reset_index(drop=True) \n",
    "        #print(X_train.columns)\n",
    "        # Create custom datasets for training, validation, and testing\n",
    "        full_dataset = MyDataset(torch.tensor(X.values), torch.tensor(y.values))\n",
    "        train_dataset = MyDataset(torch.tensor(X_train.values), torch.tensor(y_train.values))\n",
    "        test_dataset = MyDataset(torch.tensor(X_test.values), torch.tensor(y_test.values))\n",
    "\n",
    "        fullset_dataloader = DataLoader(full_dataset, batch_size=X.shape[0], shuffle=False)\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=X_train.shape[0], shuffle=False)\n",
    "        test_dataloader = DataLoader(test_dataset, batch_size=X_test.shape[0], shuffle=False)\n",
    "        #print(X_train.shape[0])\n",
    "        \n",
    "\n",
    "        train_losses, train_accs, val_losses, val_accs, train_predicted_labels, train_probs_final = run_training(\n",
    "            train_dataloader, val_dataloader=None, model=model, optimizer=optimizer, loss_fn=loss_fn, num_epochs=n_epochs, scheduler=scheduler)\n",
    "        \n",
    "        \n",
    "        \n",
    "        state_dict = model.state_dict()\n",
    "\n",
    "        # Specify the folder path and the model filename\n",
    "        folder_path = 'C:/Users/kacpe/Desktop/study/research lab/lab_rotation_git/models_gradient/' \n",
    "        model_filename = model_name + '.pth'  \n",
    "\n",
    "        # Combine the folder path and model filename\n",
    "        full_model = os.path.join(folder_path, model_filename)\n",
    "\n",
    "        # Save the model to the specified folder\n",
    "        torch.save(state_dict, full_model)\n",
    "\n",
    "\n",
    "        \n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        # Initialize an empty list to store predictions\n",
    "        all_preds = []\n",
    "        all_probs = []\n",
    "        \n",
    "\n",
    "        # Iterate through the test data batches\n",
    "        for inputs, _ in test_dataloader:\n",
    "            inputs = inputs.float()\n",
    "            # Forward pass to get predictions\n",
    "            with torch.no_grad():\n",
    "                predictions, _ = model(inputs)\n",
    "                probabilities = torch.sigmoid(predictions)\n",
    "                preds = torch.round(probabilities)\n",
    "\n",
    "            # Append predictions to the list\n",
    "            all_preds.append(preds)\n",
    "            all_probs.append(probabilities)\n",
    "\n",
    "        # Concatenate the predicted batches\n",
    "        all_preds = torch.cat(all_preds, dim=0)\n",
    "        all_probs = torch.cat(all_probs, dim=0)\n",
    "\n",
    "        all_preds_array = all_preds.numpy()\n",
    "        all_probs_array = all_probs.numpy()\n",
    "\n",
    "\n",
    "        columns = ['s_1','s_2','s_3','s_4']\n",
    "        all_probs_df = pd.DataFrame(all_probs_array)\n",
    "        all_probs_df.columns = columns\n",
    "        # Convert the tensor of predictions to a DataFrame\n",
    "        predictions_df = pd.DataFrame(all_preds_array, columns=y_test.columns, index=y_test.index)\n",
    "        # Calculate accuracy for each output state\n",
    "        accuracies = (predictions_df == y_test).mean()\n",
    "        # Construct the key for the combination\n",
    "        key = f\"sm_shift{shift}_set{set_values}\"\n",
    "\n",
    "        # Store the predictions as NumPy arrays in the dictionary\n",
    "        predictions_dict_sm[key] = all_preds_array \n",
    "\n",
    "        print(model_name)\n",
    "        print(np.mean(accuracies))\n",
    "\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a dictionary named predictions_dict\n",
    "# and you want to extract values associated with the first key\n",
    "first_key = next(iter(predictions_dict_sm))  # Get the first key\n",
    "\n",
    "# Access the values associated with the first key\n",
    "values_for_first_key = predictions_dict_sm[first_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sm_shift10_set12\n",
      "[[1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. 0.]\n",
      " [1. 1. 1. 0.]\n",
      " [1. 1. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(first_key)\n",
    "print(values_for_first_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "340"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = values_for_first_key\n",
    "len(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"y_tilda.csv\"\n",
    "\n",
    "\n",
    "y_tilda = pd.read_csv(file)\n",
    "y_tilda = y_tilda[y_tilda['trial']==12].drop(columns=['trial','id'])\n",
    "#y_tilda = y_tilda.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(350, 4)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tilda.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['s_1', 's_2', 's_3', 's_4', 's_1_minus_10', 's_2_minus_10',\n",
      "       's_3_minus_10', 's_4_minus_10'],\n",
      "      dtype='object')\n",
      "(340, 4)\n"
     ]
    }
   ],
   "source": [
    "# Create an empty DataFrame to store the shifted data\n",
    "file_path = os.path.join(data_folder, \"data_model_v3.csv\")\n",
    "y_tilda = pd.read_csv(file_path)\n",
    "y_tilda = y_tilda[y_tilda['trial']==12].drop(columns=['trial','id'])\n",
    "shift = 10 \n",
    "col_shift = ['s_1', 's_2', 's_3', 's_4']\n",
    "# Loop through unique trial values\n",
    "    # Create shifted columns for each column in columns_to_shift\n",
    "for col in col_shift:\n",
    "    new_col_name = col + '_minus_' + str(shift)\n",
    "    y_tilda[new_col_name] = y_tilda[col].shift(shift)\n",
    "\n",
    "# Drop the last 'i' records for each trial\n",
    "y_tilda = y_tilda.dropna()\n",
    "print(y_tilda.columns)\n",
    "y_tilda = y_tilda.drop(columns=['s_1', 's_2', 's_3', 's_4'])\n",
    "new_column_names = {'s_1_minus_10': 's_1',\n",
    "                    's_2_minus_10': 's_2',\n",
    "                    's_3_minus_10': 's_3',\n",
    "                    's_4_minus_10': 's_4'}\n",
    "\n",
    "y_tilda = y_tilda.rename(columns=new_column_names)\n",
    "y_tilda = y_tilda.to_numpy()\n",
    "print(y_tilda.shape)\n",
    "y_tilda = torch.tensor(y_tilda)\n",
    "y_hat = torch.tensor(y_hat, dtype=torch.float32, requires_grad=True)\n",
    "y_tilda = torch.tensor(y_tilda, dtype=torch.float32, requires_grad=True)\n",
    "#y_hat = torch.tensor(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kacpe\\AppData\\Local\\Temp\\ipykernel_23732\\2719183788.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_tilda = torch.tensor(y_tilda, dtype=torch.float32, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "y_hat = torch.tensor(y_hat, dtype=torch.float32, requires_grad=True)\n",
    "y_tilda = torch.tensor(y_tilda, dtype=torch.float32, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['nose_x_minus_10', 'nose_y_minus_10', 'nose_z_minus_10',\n",
       "       'headTop_x_minus_10', 'headTop_y_minus_10', 'headTop_z_minus_10',\n",
       "       'neck_x_minus_10', 'neck_y_minus_10', 'neck_z_minus_10',\n",
       "       'tailBase_x_minus_10', 'tailBase_y_minus_10', 'tailBase_z_minus_10',\n",
       "       'lEar_x_minus_10', 'lEar_y_minus_10', 'lEar_z_minus_10',\n",
       "       'lShoulder_x_minus_10', 'lShoulder_y_minus_10', 'lShoulder_z_minus_10',\n",
       "       'lElbow_x_minus_10', 'lElbow_y_minus_10', 'lElbow_z_minus_10',\n",
       "       'lWrist_x_minus_10', 'lWrist_y_minus_10', 'lWrist_z_minus_10',\n",
       "       'lHip_x_minus_10', 'lHip_y_minus_10', 'lHip_z_minus_10',\n",
       "       'rEar_x_minus_10', 'rEar_y_minus_10', 'rEar_z_minus_10',\n",
       "       'rShoulder_x_minus_10', 'rShoulder_y_minus_10', 'rShoulder_z_minus_10',\n",
       "       'rElbow_x_minus_10', 'rElbow_y_minus_10', 'rElbow_z_minus_10',\n",
       "       'rWrist_x_minus_10', 'rWrist_y_minus_10', 'rWrist_z_minus_10',\n",
       "       'rHip_x_minus_10', 'rHip_y_minus_10', 'rHip_z_minus_10', 's_1_minus_10',\n",
       "       's_2_minus_10', 's_3_minus_10', 's_4_minus_10'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([340, 46])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kacpe\\AppData\\Local\\Temp\\ipykernel_23732\\3382397077.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat, dtype=torch.float32)  # Convert to float\n",
      "C:\\Users\\kacpe\\AppData\\Local\\Temp\\ipykernel_23732\\3382397077.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_tilda = torch.tensor(y_tilda, dtype=torch.float32)  # Convert to float\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have 'y_hat' and 'y_tilda' as tensors containing binary values (0 or 1)\n",
    "y_hat = torch.tensor(y_hat, dtype=torch.float32)  # Convert to float\n",
    "y_tilda = torch.tensor(y_tilda, dtype=torch.float32)  # Convert to float\n",
    "\n",
    "y_hat = y_hat.requires_grad_(True)\n",
    "y_tilda = y_tilda.requires_grad_(True)\n",
    "\n",
    "# Define the loss function\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "# Calculate the loss\n",
    "binary_cross_entropy_loss = loss_fn(y_hat, y_tilda)\n",
    "input = torch.tensor(X_test.values)\n",
    "input = input.unsqueeze(1)\n",
    "input = input.float()\n",
    "# set input to require_grad\n",
    "input = input.requires_grad_(True)\n",
    "model.eval()\n",
    "output, f = model(input)\n",
    "\n",
    "# calculating loss \n",
    "output = output.requires_grad_(True)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "loss = loss_fn(output, y_tilda)\n",
    "loss.backward()\n",
    "#print(input)\n",
    "\n",
    "# Access the gradients for the input data\n",
    "input_gradients = input.grad.squeeze(1)\n",
    "print(input_gradients.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rWrist_x_minus_10'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.columns[-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lWrist_x_gradient = input_gradients[:,21].numpy()\n",
    "rWrist_x_gradient = input_gradients[:,-10].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.76474368e-05, -1.76542217e-05, -1.75890345e-05, -1.53147794e-05,\n",
       "       -1.52373414e-05, -1.54065729e-05, -1.53684487e-05, -1.54638383e-05,\n",
       "       -1.53771980e-05, -1.53767942e-05, -1.53613546e-05, -1.53780456e-05,\n",
       "       -1.53096698e-05, -1.47437058e-05, -1.50416718e-05, -1.48826812e-05,\n",
       "       -1.49087191e-05, -1.49521038e-05, -1.48654781e-05, -1.52426392e-05,\n",
       "       -1.53065903e-05, -1.53166438e-05, -1.54639529e-05, -1.53494366e-05,\n",
       "       -1.54897043e-05, -1.54544141e-05, -1.55553607e-05, -1.59791598e-05,\n",
       "       -1.61623902e-05, -1.58945604e-05, -1.63379354e-05, -1.60139989e-05,\n",
       "       -1.59030424e-05, -1.59875017e-05, -1.52859720e-05, -1.52791599e-05,\n",
       "       -1.53782294e-05, -1.55587986e-05, -1.56673359e-05, -1.57688792e-05,\n",
       "       -1.58552466e-05,  1.39490121e-05,  1.40369311e-05,  1.40971624e-05,\n",
       "        1.41446872e-05,  1.42036261e-05,  1.42420649e-05,  1.45333961e-05,\n",
       "        1.45750673e-05,  1.45582308e-05,  1.47301071e-05,  1.47653136e-05,\n",
       "        1.48840008e-05,  1.48873341e-05,  1.49060406e-05,  1.49042726e-05,\n",
       "        1.49377847e-05,  1.49444077e-05,  1.49469915e-05,  1.49543757e-05,\n",
       "        1.49523803e-05,  1.49455782e-05,  1.49432708e-05,  1.49234456e-05,\n",
       "        1.49191274e-05,  1.49106745e-05,  1.48916461e-05,  1.55136477e-05,\n",
       "        1.56061360e-05,  1.55711641e-05,  1.55599955e-05,  1.55126982e-05,\n",
       "        1.55410999e-05,  1.55571706e-05,  1.55528669e-05,  1.55686357e-05,\n",
       "        1.55674006e-05,  1.55544203e-05,  1.55148464e-05,  1.54809768e-05,\n",
       "        1.54181744e-05,  1.53622441e-05,  1.52841585e-05,  1.52412167e-05,\n",
       "        1.51949262e-05,  1.51528620e-05,  1.51118238e-05,  1.50691885e-05,\n",
       "        1.50057949e-05,  1.49532825e-05,  1.48850595e-05,  1.48828758e-05,\n",
       "        1.48730169e-05,  1.48648242e-05,  1.48500167e-05,  1.48425415e-05,\n",
       "        1.48345644e-05,  1.48488598e-05,  1.48279287e-05,  1.47805549e-05,\n",
       "        1.47641804e-05,  1.47626715e-05,  1.47557557e-05,  1.47571700e-05,\n",
       "        1.47901865e-05,  1.47861119e-05,  1.47610672e-05,  1.47309565e-05,\n",
       "        1.46620650e-05,  1.46130642e-05,  1.45277863e-05,  1.50453343e-05,\n",
       "        1.50146807e-05,  1.48708414e-05,  1.47406754e-05,  1.47261917e-05,\n",
       "        1.46052507e-05,  1.44630803e-05,  1.44666792e-05,  1.44058213e-05,\n",
       "        1.43438774e-05,  1.42450399e-05,  1.39259955e-05,  1.39104122e-05,\n",
       "        1.40302354e-05,  1.40062857e-05,  1.37346833e-05,  1.38059922e-05,\n",
       "        1.37789029e-05,  1.37675615e-05,  1.33194180e-05,  1.31092684e-05,\n",
       "        1.30752842e-05,  1.30362332e-05,  1.30475055e-05,  1.30274293e-05,\n",
       "        1.26230971e-05,  1.56546885e-05,  1.70353342e-05,  1.65309175e-05,\n",
       "        1.63674449e-05,  1.60679647e-05,  1.57044196e-05,  1.55311791e-05,\n",
       "        1.52864013e-05,  1.49694561e-05,  1.47375094e-05,  1.44708720e-05,\n",
       "        1.41343962e-05,  1.35213140e-05,  1.33888825e-05,  1.32417990e-05,\n",
       "        1.26469477e-05,  1.24208109e-05,  1.20741943e-05,  1.11972513e-05,\n",
       "        1.09021921e-05,  1.03604980e-05,  9.84565486e-06,  9.42497809e-06,\n",
       "        8.89511739e-06,  8.41756355e-06,  7.93387062e-06,  7.40603627e-06,\n",
       "        6.78801325e-06,  6.12272561e-06,  5.85522503e-06,  5.64980473e-06,\n",
       "        5.04100490e-06,  4.79877644e-06,  4.40799704e-06,  4.23249594e-06,\n",
       "        4.12484542e-06,  3.88707849e-06,  3.70855696e-06,  3.60621289e-06,\n",
       "        3.50619871e-06,  3.43519241e-06,  3.32033142e-06,  3.25511292e-06,\n",
       "        3.01674299e-06,  2.97568226e-06,  2.77588106e-06,  2.94507117e-06,\n",
       "        2.71175168e-06,  2.49988034e-06,  2.77485879e-06,  2.53585313e-06,\n",
       "        2.63500488e-06,  2.47598064e-06,  2.46996342e-06,  2.47462003e-06,\n",
       "       -3.61193679e-06, -3.75537184e-06, -3.34812739e-06, -5.13326631e-06,\n",
       "       -5.55956967e-06, -6.03606850e-06, -6.46219496e-06, -6.56418297e-06,\n",
       "       -6.68598159e-06, -6.26612200e-06, -6.60695923e-06, -7.19135915e-06,\n",
       "       -7.03013029e-06, -7.16286013e-06, -7.01286308e-06, -7.32541685e-06,\n",
       "       -7.42949669e-06, -7.38445578e-06, -7.27450652e-06, -7.23087487e-06,\n",
       "       -7.07560821e-06, -7.08131483e-06, -6.90601019e-06, -6.64744448e-06,\n",
       "       -6.43817020e-06, -6.18150034e-06, -5.87964269e-06, -5.57257044e-06,\n",
       "       -5.15444253e-06, -4.73140290e-06, -4.44214538e-06, -4.16951070e-06,\n",
       "       -3.69490272e-06, -3.36285621e-06, -3.19021410e-06, -2.97835777e-06,\n",
       "       -2.81922394e-06, -2.63888251e-06, -2.42049055e-06, -2.61203922e-06,\n",
       "       -2.58377986e-06, -2.60215893e-06, -2.37273980e-06, -3.01536238e-06,\n",
       "       -3.06484390e-06, -3.17505464e-06, -3.35555842e-06, -3.55058501e-06,\n",
       "       -3.71591705e-06, -3.92367838e-06, -4.16392550e-06, -4.45701835e-06,\n",
       "       -4.75744537e-06, -4.95556969e-06, -5.07668892e-06, -5.12958468e-06,\n",
       "       -5.34622222e-06, -5.52539404e-06, -5.72802173e-06, -5.67243069e-06,\n",
       "       -5.57599787e-06, -5.70213706e-06, -5.91048047e-06, -5.95179199e-06,\n",
       "       -6.13866314e-06, -5.92780634e-06, -5.90483614e-06, -5.99553323e-06,\n",
       "       -5.99197347e-06, -6.07105585e-06, -6.13251723e-06, -6.11783707e-06,\n",
       "       -6.10753114e-06, -6.13177690e-06, -6.08817209e-06, -6.07804714e-06,\n",
       "       -6.06619415e-06, -6.04926345e-06, -6.03868921e-06, -5.86377519e-06,\n",
       "       -5.83989413e-06, -5.77963783e-06, -5.59690125e-06, -5.49054721e-06,\n",
       "       -5.31295109e-06, -5.03864158e-06, -4.97073961e-06, -4.84458178e-06,\n",
       "       -4.70818622e-06, -4.54708470e-06, -4.27109944e-06, -4.03394733e-06,\n",
       "       -3.85852582e-06, -3.64268953e-06, -3.50304845e-06, -3.39375401e-06,\n",
       "       -3.24939401e-06, -3.06786205e-06, -2.97993120e-06, -2.88285537e-06,\n",
       "       -2.81976736e-06, -2.88771116e-06, -2.93888206e-06, -2.88844240e-06,\n",
       "       -3.15508714e-06, -3.21040534e-06, -3.22551750e-06, -3.31136198e-06,\n",
       "       -3.32572472e-06, -3.35799723e-06, -3.36412631e-06, -3.48411413e-06,\n",
       "       -3.58854777e-06, -3.67967459e-06, -3.77860761e-06, -3.85063777e-06,\n",
       "       -3.88772150e-06, -3.94062954e-06, -3.95011102e-06, -3.95785264e-06,\n",
       "       -3.92751099e-06, -3.92085349e-06, -3.85364456e-06, -3.78931145e-06,\n",
       "       -3.76643402e-06, -3.68846122e-06, -3.45267654e-06, -3.18833099e-06,\n",
       "       -3.02388980e-06, -2.78470634e-06, -2.57400097e-06, -2.37316090e-06,\n",
       "       -1.66940754e-06, -1.71893771e-06, -1.11228292e-06, -1.46338516e-06,\n",
       "       -1.17567470e-06, -1.27076510e-06, -7.95455890e-07,  1.92454536e-07,\n",
       "        3.00189640e-07,  6.50475613e-07,  1.25516908e-06,  1.81896303e-06,\n",
       "        2.86996419e-06,  2.51287292e-06,  2.79560982e-06,  2.86397790e-06],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rWrist_x_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8794117647058823"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(rWrist_x_gradient > lWrist_x_gradient)/len(rWrist_x_gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the folder and model filename\n",
    "load_folder = 'C:/Users/kacpe/Desktop/study/research lab/lab_rotation_git/gradient_models'\n",
    "model_filename = 's_m80_val13_gates.pth'\n",
    "\n",
    "# Iterate through the test data batches\n",
    "for inputs, _ in train_dataloader:\n",
    "    inputs = inputs.float()\n",
    "    inputs.requires_grad = True  # Set requires_grad to True\n",
    "    # Forward pass to get predictions\n",
    "    with torch.no_grad():\n",
    "        predictions, h, test_hidden_states = model(inputs)\n",
    "        probabilities = torch.sigmoid(predictions)\n",
    "        output = torch.round(probabilities)\n",
    "inputs.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 0.],\n",
       "        [1., 1., 1., 0.],\n",
       "        [1., 1., 1., 0.],\n",
       "        ...,\n",
       "        [1., 1., 0., 0.],\n",
       "        [1., 1., 0., 0.],\n",
       "        [1., 1., 0., 0.]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15.5881, 17.0496,  7.1234, -2.7169],\n",
       "        [15.6907, 16.8004,  7.1833, -2.5166],\n",
       "        [14.9813, 15.7438,  6.8294, -2.4401],\n",
       "        ...,\n",
       "        [ 5.0684,  3.3052, -4.5890, -2.3956],\n",
       "        [ 5.0625,  3.1659, -4.4379, -2.1808],\n",
       "        [ 5.0584,  3.2695, -4.3667, -2.2210]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(input)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5328, 1, 46])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "input = torch.tensor(X_train.values)\n",
    "input = input.unsqueeze(1)\n",
    "input = input.float()\n",
    "input.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[15.5881, 17.0496,  7.1234, -2.7169],\n",
       "         [15.6907, 16.8004,  7.1833, -2.5166],\n",
       "         [14.9813, 15.7438,  6.8294, -2.4401],\n",
       "         ...,\n",
       "         [ 5.0684,  3.3052, -4.5890, -2.3956],\n",
       "         [ 5.0625,  3.1659, -4.4379, -2.1808],\n",
       "         [ 5.0584,  3.2695, -4.3667, -2.2210]], grad_fn=<AddmmBackward0>),\n",
       " tensor([[-0.1361, -3.9054,  4.3457,  ...,  6.9570, -0.9351, -1.0151],\n",
       "         [-0.1834, -3.3678,  4.3394,  ...,  6.9214, -0.8772, -1.2564],\n",
       "         [-0.1403, -3.1291,  3.9980,  ...,  6.4979, -0.8859, -1.4158],\n",
       "         ...,\n",
       "         [-0.8940,  0.8611, -0.3193,  ...,  0.0296,  2.5547,  2.2299],\n",
       "         [-0.8732,  0.9012, -0.3054,  ...,  0.0481,  2.5995,  1.8107],\n",
       "         [-0.8328,  0.9142, -0.3030,  ...,  0.0511,  2.5933,  1.5676]],\n",
       "        grad_fn=<NativeBatchNormBackward0>),\n",
       " [tensor([[ 0.0378,  0.0049,  0.0404,  ...,  0.1942,  0.0496, -0.3348],\n",
       "          [ 0.0359,  0.0124,  0.0403,  ...,  0.1932,  0.0511, -0.3366],\n",
       "          [ 0.0376,  0.0157,  0.0368,  ...,  0.1812,  0.0509, -0.3379],\n",
       "          ...,\n",
       "          [ 0.0076,  0.0714, -0.0078,  ..., -0.0019,  0.1424, -0.3098],\n",
       "          [ 0.0084,  0.0720, -0.0077,  ..., -0.0014,  0.1436, -0.3130],\n",
       "          [ 0.0100,  0.0722, -0.0076,  ..., -0.0013,  0.1434, -0.3149]],\n",
       "         grad_fn=<AddBackward0>)])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\kacpe\\Desktop\\study\\research lab\\lab_rotation_git\\GRUCell.ipynb Cell 88\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/kacpe/Desktop/study/research%20lab/lab_rotation_git/GRUCell.ipynb#Y231sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m output\u001b[39m.\u001b[39;49msize\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "output.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[15.6528, 16.5354,  6.8842, -2.5370],\n",
       "         [15.7095, 16.3226,  6.9530, -2.3735],\n",
       "         [15.0120, 15.2652,  6.5979, -2.3344],\n",
       "         ...,\n",
       "         [ 4.9547,  3.1134, -4.5596, -2.0263],\n",
       "         [ 4.9473,  2.9779, -4.4284, -1.8249],\n",
       "         [ 4.9355,  3.0609, -4.3583, -1.8576]], grad_fn=<AddmmBackward0>),\n",
       " tensor([[-0.2498, -4.0778,  4.4233,  ...,  6.9959, -0.7348, -1.3482],\n",
       "         [-0.2950, -3.5366,  4.4125,  ...,  6.9596, -0.6890, -1.5728],\n",
       "         [-0.2455, -3.2876,  4.0599,  ...,  6.5503, -0.7003, -1.6831],\n",
       "         ...,\n",
       "         [-0.8525,  0.8381, -0.3202,  ..., -0.0396,  2.6897,  2.1940],\n",
       "         [-0.8352,  0.8757, -0.3068,  ..., -0.0204,  2.7345,  1.8132],\n",
       "         [-0.7982,  0.8865, -0.3056,  ..., -0.0164,  2.7295,  1.5923]],\n",
       "        grad_fn=<NativeBatchNormBackward0>),\n",
       " [tensor([[ 0.0308,  0.0021,  0.0413,  ...,  0.2176,  0.0700, -0.3320],\n",
       "          [ 0.0290,  0.0097,  0.0412,  ...,  0.2165,  0.0713, -0.3338],\n",
       "          [ 0.0310,  0.0132,  0.0376,  ...,  0.2037,  0.0710, -0.3346],\n",
       "          ...,\n",
       "          [ 0.0065,  0.0711, -0.0079,  ..., -0.0026,  0.1707, -0.3043],\n",
       "          [ 0.0072,  0.0717, -0.0078,  ..., -0.0020,  0.1720, -0.3073],\n",
       "          [ 0.0087,  0.0718, -0.0078,  ..., -0.0018,  0.1719, -0.3090]],\n",
       "         grad_fn=<AddBackward0>)])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[15.5881, 17.0496,  7.1234, -2.7169],\n",
       "         [15.6907, 16.8004,  7.1833, -2.5166],\n",
       "         [14.9813, 15.7438,  6.8294, -2.4401],\n",
       "         ...,\n",
       "         [ 5.0684,  3.3052, -4.5890, -2.3956],\n",
       "         [ 5.0625,  3.1659, -4.4379, -2.1808],\n",
       "         [ 5.0584,  3.2695, -4.3667, -2.2210]], grad_fn=<AddmmBackward0>),\n",
       " tensor([[-0.1361, -3.9054,  4.3457,  ...,  6.9570, -0.9351, -1.0151],\n",
       "         [-0.1834, -3.3678,  4.3394,  ...,  6.9214, -0.8772, -1.2564],\n",
       "         [-0.1403, -3.1291,  3.9980,  ...,  6.4979, -0.8859, -1.4158],\n",
       "         ...,\n",
       "         [-0.8940,  0.8611, -0.3193,  ...,  0.0296,  2.5547,  2.2299],\n",
       "         [-0.8732,  0.9012, -0.3054,  ...,  0.0481,  2.5995,  1.8107],\n",
       "         [-0.8328,  0.9142, -0.3030,  ...,  0.0511,  2.5933,  1.5676]],\n",
       "        grad_fn=<NativeBatchNormBackward0>),\n",
       " [tensor([[ 0.0378,  0.0049,  0.0404,  ...,  0.1942,  0.0496, -0.3348],\n",
       "          [ 0.0359,  0.0124,  0.0403,  ...,  0.1932,  0.0511, -0.3366],\n",
       "          [ 0.0376,  0.0157,  0.0368,  ...,  0.1812,  0.0509, -0.3379],\n",
       "          ...,\n",
       "          [ 0.0076,  0.0714, -0.0078,  ..., -0.0019,  0.1424, -0.3098],\n",
       "          [ 0.0084,  0.0720, -0.0077,  ..., -0.0014,  0.1436, -0.3130],\n",
       "          [ 0.0100,  0.0722, -0.0076,  ..., -0.0013,  0.1434, -0.3149]],\n",
       "         grad_fn=<AddBackward0>)])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[15.5881, 17.0496,  7.1234, -2.7169],\n",
       "         [15.6907, 16.8004,  7.1833, -2.5166],\n",
       "         [14.9813, 15.7438,  6.8294, -2.4401],\n",
       "         ...,\n",
       "         [ 5.0684,  3.3052, -4.5890, -2.3956],\n",
       "         [ 5.0625,  3.1659, -4.4379, -2.1808],\n",
       "         [ 5.0584,  3.2695, -4.3667, -2.2210]], grad_fn=<AddmmBackward0>),\n",
       " tensor([[-0.1361, -3.9054,  4.3457,  ...,  6.9570, -0.9351, -1.0151],\n",
       "         [-0.1834, -3.3678,  4.3394,  ...,  6.9214, -0.8772, -1.2564],\n",
       "         [-0.1403, -3.1291,  3.9980,  ...,  6.4979, -0.8859, -1.4158],\n",
       "         ...,\n",
       "         [-0.8940,  0.8611, -0.3193,  ...,  0.0296,  2.5547,  2.2299],\n",
       "         [-0.8732,  0.9012, -0.3054,  ...,  0.0481,  2.5995,  1.8107],\n",
       "         [-0.8328,  0.9142, -0.3030,  ...,  0.0511,  2.5933,  1.5676]],\n",
       "        grad_fn=<NativeBatchNormBackward0>),\n",
       " [tensor([[ 0.0378,  0.0049,  0.0404,  ...,  0.1942,  0.0496, -0.3348],\n",
       "          [ 0.0359,  0.0124,  0.0403,  ...,  0.1932,  0.0511, -0.3366],\n",
       "          [ 0.0376,  0.0157,  0.0368,  ...,  0.1812,  0.0509, -0.3379],\n",
       "          ...,\n",
       "          [ 0.0076,  0.0714, -0.0078,  ..., -0.0019,  0.1424, -0.3098],\n",
       "          [ 0.0084,  0.0720, -0.0077,  ..., -0.0014,  0.1436, -0.3130],\n",
       "          [ 0.0100,  0.0722, -0.0076,  ..., -0.0013,  0.1434, -0.3149]],\n",
       "         grad_fn=<AddBackward0>)])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        #selected_columns = ['id', 'trial','s_1_minus_'+str(shift),'s_2_minus_'+str(shift),'s_3_minus_'+str(shift),'s_4_minus_'+str(shift),'s_1','s_2','s_3','s_4']\n",
    "        selected_columns = ['id', 'trial','nose_x_minus_'+str(shift), 'nose_y_minus_'+str(shift),\n",
    "        'nose_z_minus_'+str(shift), 'headTop_x_minus_'+str(shift), 'headTop_y_minus_'+str(shift),\n",
    "        'headTop_z_minus_'+str(shift), 'neck_x_minus_'+str(shift), 'neck_y_minus_'+str(shift),\n",
    "        'neck_z_minus_'+str(shift), 'tailBase_x_minus_'+str(shift), 'tailBase_y_minus_'+str(shift),\n",
    "        'tailBase_z_minus_'+str(shift), 'lEar_x_minus_'+str(shift), 'lEar_y_minus_'+str(shift),\n",
    "        'lEar_z_minus_'+str(shift), 'lShoulder_x_minus_'+str(shift), 'lShoulder_y_minus_'+str(shift),\n",
    "        'lShoulder_z_minus_'+str(shift), 'lElbow_x_minus_'+str(shift), 'lElbow_y_minus_'+str(shift),\n",
    "        'lElbow_z_minus_'+str(shift), 'lWrist_x_minus_'+str(shift), 'lWrist_y_minus_'+str(shift),\n",
    "        'lWrist_z_minus_'+str(shift), 'lHip_x_minus_'+str(shift), 'lHip_y_minus_'+str(shift),\n",
    "        'lHip_z_minus_'+str(shift), 'rEar_x_minus_'+str(shift), 'rEar_y_minus_'+str(shift), 'rEar_z_minus_'+str(shift),\n",
    "        'rShoulder_x_minus_'+str(shift), 'rShoulder_y_minus_'+str(shift), 'rShoulder_z_minus_'+str(shift),\n",
    "        'rElbow_x_minus_'+str(shift), 'rElbow_y_minus_'+str(shift), 'rElbow_z_minus_'+str(shift),\n",
    "        'rWrist_x_minus_'+str(shift), 'rWrist_y_minus_'+str(shift), 'rWrist_z_minus_'+str(shift),\n",
    "        'rHip_x_minus_'+str(shift), 'rHip_y_minus_'+str(shift), 'rHip_z_minus_'+str(shift), 's_1_minus_'+str(shift),\n",
    "        's_2_minus_'+str(shift), 's_3_minus_'+str(shift), 's_4_minus_'+str(shift),'s_1','s_2','s_3','s_4']\n",
    "        shifted_df = shifted_df[selected_columns]\n",
    "        # Step 5: Split the data into training and test sets based on the 'trial' column\n",
    "        train_set = shifted_df[shifted_df['trial']!=set_values].drop(columns=['id', 'trial'])\n",
    "        test_set = shifted_df[shifted_df['trial']==set_values].drop(columns=['id', 'trial'])\n",
    "        full_set = shifted_df.drop(columns=['id','trial'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_tilda instead of target \n",
    "#output = y_hat \n",
    "# creating input\n",
    "input = torch.tensor(X_test.values)\n",
    "input = input.unsqueeze(1)\n",
    "input = input.float()\n",
    "# set input to require_grad\n",
    "input = input.requires_grad_(True)\n",
    "model.eval()\n",
    "output, f, f = model(input)\n",
    "\n",
    "# calculating loss \n",
    "output = output.requires_grad_(True)\n",
    "loss = loss_fn(output, target)\n",
    "loss.backward()\n",
    "\n",
    "# Access the gradients for the input data\n",
    "input_gradients = input.grad.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.grad.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "gru_cells.0.weight_ih\n",
      "tensor([[ 0.1454, -0.0767,  0.1165,  ...,  0.0882,  0.0758,  0.0415],\n",
      "        [ 0.0745, -0.1682,  0.0754,  ...,  0.0346, -0.0484, -0.1178],\n",
      "        [-0.0083, -0.1615,  0.1327,  ...,  0.0147, -0.1474, -0.1203],\n",
      "        ...,\n",
      "        [ 0.0235, -0.0237, -0.0839,  ...,  0.0383, -0.1634,  0.1645],\n",
      "        [-0.0403,  0.0512,  0.0946,  ..., -0.0186,  0.1682,  0.1391],\n",
      "        [ 0.1168, -0.0078, -0.1271,  ..., -0.0558,  0.1122,  0.0342]])\n",
      "gru_cells.0.weight_hh\n",
      "tensor([[ 0.0654,  0.0306,  0.1648,  ..., -0.0643,  0.1707,  0.0210],\n",
      "        [-0.0169,  0.1101,  0.0372,  ...,  0.0406, -0.0684,  0.0486],\n",
      "        [ 0.1226, -0.1662, -0.0386,  ...,  0.0828,  0.0141, -0.0264],\n",
      "        ...,\n",
      "        [ 0.1211, -0.1242,  0.1029,  ...,  0.0835,  0.0161,  0.0562],\n",
      "        [-0.0618, -0.0938, -0.0629,  ...,  0.0225,  0.1529, -0.1611],\n",
      "        [-0.0711,  0.0437, -0.0786,  ...,  0.0553,  0.0523,  0.1267]])\n",
      "gru_cells.0.bias_ih\n",
      "tensor([-0.0448, -0.1460, -0.1346,  0.0724, -0.1092, -0.0197,  0.0069,  0.1191,\n",
      "        -0.1403,  0.1496,  0.1430,  0.1667, -0.1598, -0.1411, -0.1425, -0.1688,\n",
      "         0.0917, -0.0277,  0.1599,  0.0327,  0.0347, -0.1244,  0.0508, -0.0665,\n",
      "        -0.0295, -0.1343, -0.1673,  0.0276,  0.1174, -0.0098,  0.1094, -0.1628,\n",
      "         0.1079, -0.0417, -0.0304, -0.1414, -0.0490,  0.0350, -0.0239, -0.0371,\n",
      "        -0.1674, -0.0318, -0.0888,  0.1208,  0.0407,  0.1607,  0.0913, -0.1196,\n",
      "        -0.1434,  0.0520,  0.0007,  0.0231,  0.0250, -0.1312, -0.0793, -0.1102,\n",
      "        -0.1343,  0.0433, -0.1600, -0.0174,  0.1429,  0.0239, -0.1694,  0.0577,\n",
      "         0.1607,  0.1639,  0.0046, -0.0801,  0.0591, -0.0131,  0.0726, -0.0672,\n",
      "         0.0513, -0.0894, -0.1173,  0.1703, -0.1659, -0.1647, -0.0099, -0.0328,\n",
      "        -0.0361, -0.1085, -0.0121, -0.0948,  0.0095, -0.0053, -0.1561,  0.0304,\n",
      "         0.1408, -0.0091,  0.1302,  0.0871, -0.0493, -0.0203,  0.1120, -0.0558,\n",
      "        -0.0629,  0.1430,  0.0259,  0.1392, -0.0475,  0.0217])\n",
      "gru_cells.0.bias_hh\n",
      "tensor([-0.0332,  0.0442, -0.1472, -0.0456, -0.1438,  0.1043,  0.0451,  0.1555,\n",
      "         0.1268, -0.1691,  0.0426, -0.1560, -0.1143, -0.0966, -0.0023,  0.1359,\n",
      "        -0.0607, -0.1227, -0.0863, -0.0531, -0.0958,  0.0333, -0.0704,  0.0937,\n",
      "        -0.0370,  0.0593, -0.1396,  0.1397,  0.0136,  0.0929,  0.0389,  0.1503,\n",
      "         0.0905, -0.1106,  0.1559, -0.0772,  0.0270,  0.1678, -0.1394, -0.1400,\n",
      "        -0.0626,  0.0926, -0.1114,  0.1665, -0.1708,  0.0881,  0.1589,  0.0757,\n",
      "         0.1052,  0.0133, -0.0148,  0.1212, -0.0758,  0.0402,  0.1526,  0.0132,\n",
      "        -0.1624, -0.1158,  0.1666, -0.1401,  0.1222, -0.0086, -0.0232, -0.0315,\n",
      "        -0.1643,  0.1242, -0.0542,  0.1045, -0.0093, -0.0621,  0.1381,  0.1522,\n",
      "        -0.1240, -0.1321,  0.1714, -0.1469, -0.0439, -0.0988,  0.1347, -0.1438,\n",
      "         0.0290,  0.0139,  0.0760, -0.1633,  0.0066,  0.0641, -0.1302, -0.0282,\n",
      "        -0.1271, -0.1249, -0.0584,  0.1551,  0.0984, -0.1548,  0.1204,  0.1488,\n",
      "         0.1022,  0.0271, -0.1225,  0.0938, -0.0121,  0.0651])\n"
     ]
    }
   ],
   "source": [
    "        # Define the folder and model filename\n",
    "load_folder = 'C:/Users/kacpe/Desktop/study/research lab/lab_rotation_git/gradient_models'\n",
    "model_filename = 's_m80_val13_gates.pth'\n",
    "\n",
    "# Load the model\n",
    "checkpoint = torch.load(os.path.join(load_folder, model_filename))\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "# Set the model in evaluation mode\n",
    "model.eval()\n",
    "# Set the model in evaluation mode\n",
    "\n",
    "\n",
    "# Access the model's state dictionary\n",
    "model_state_dict = model.state_dict()\n",
    "\n",
    "# Now you can access the weights of the nn.GRUCell layers\n",
    "gru_cell_weights = {\n",
    "    key: value\n",
    "    for key, value in model_state_dict.items()\n",
    "    if key.startswith('gru_cells.')\n",
    "}\n",
    "print(len(gru_cell_weights))\n",
    "# Print or access the weights as needed\n",
    "for key, value in gru_cell_weights.items():\n",
    "    print(key)\n",
    "    print(value)\n",
    "    \n",
    "\n",
    "\n",
    "# Extract and assign the weights to separate variables\n",
    "weight_ih = gru_cell_weights['gru_cells.0.weight_ih']\n",
    "weight_hh = gru_cell_weights['gru_cells.0.weight_hh']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weight_ih[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_ih_np = weight_ih.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['nose_x_minus_80', 'nose_y_minus_80', 'nose_z_minus_80',\n",
    "       'headTop_x_minus_80', 'headTop_y_minus_80', 'headTop_z_minus_80',\n",
    "       'neck_x_minus_80', 'neck_y_minus_80', 'neck_z_minus_80',\n",
    "       'tailBase_x_minus_80', 'tailBase_y_minus_80', 'tailBase_z_minus_80',\n",
    "       'lEar_x_minus_80', 'lEar_y_minus_80', 'lEar_z_minus_80',\n",
    "       'lShoulder_x_minus_80', 'lShoulder_y_minus_80', 'lShoulder_z_minus_80',\n",
    "       'lElbow_x_minus_80', 'lElbow_y_minus_80', 'lElbow_z_minus_80',\n",
    "       'lWrist_x_minus_80', 'lWrist_y_minus_80', 'lWrist_z_minus_80',\n",
    "       'lHip_x_minus_80', 'lHip_y_minus_80', 'lHip_z_minus_80',\n",
    "       'rEar_x_minus_80', 'rEar_y_minus_80', 'rEar_z_minus_80',\n",
    "       'rShoulder_x_minus_80', 'rShoulder_y_minus_80', 'rShoulder_z_minus_80',\n",
    "       'rElbow_x_minus_80', 'rElbow_y_minus_80', 'rElbow_z_minus_80',\n",
    "       'rWrist_x_minus_80', 'rWrist_y_minus_80', 'rWrist_z_minus_80',\n",
    "       'rHip_x_minus_80', 'rHip_y_minus_80', 'rHip_z_minus_80', 's_1_minus_80',\n",
    "       's_2_minus_80', 's_3_minus_80', 's_4_minus_80']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102, 46)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_ih_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = pd.DataFrame(weight_ih_np, columns=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     -0.118293\n",
       "1      0.057691\n",
       "2     -0.099260\n",
       "3      0.020036\n",
       "4      0.046773\n",
       "         ...   \n",
       "97    -0.108127\n",
       "98    -0.147265\n",
       "99     0.120991\n",
       "100   -0.109019\n",
       "101    0.127330\n",
       "Name: rWrist_x_minus_80, Length: 102, dtype: float32"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights['rWrist_x_minus_80']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.073618\n",
       "1      0.129745\n",
       "2     -0.052349\n",
       "3      0.136418\n",
       "4      0.078713\n",
       "         ...   \n",
       "97    -0.137238\n",
       "98    -0.041288\n",
       "99    -0.127240\n",
       "100   -0.085322\n",
       "101   -0.029799\n",
       "Name: lWrist_x_minus_80, Length: 102, dtype: float32"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights['lWrist_x_minus_80']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_dim = 1\n",
    "hidden_dim = 1\n",
    "output_dim = 4\n",
    "num_layers = 1\n",
    "n_epochs =151\n",
    "lr = 0.01\n",
    "\n",
    "# Create an instance of GRUCellNet\n",
    "model = GRUCellNet(input_dim, hidden_dim, output_dim, num_layers)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "class_weights = torch.tensor([1.8]).to(device)\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=class_weights)  \n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rwrist_df = scaled_df[['rWrist_x','trial','id','s_1','s_2','s_3','s_4']]\n",
    "lwrist_df = scaled_df[['lWrist_x','trial','id','s_1','s_2','s_3','s_4']]\n",
    "labels = ['s_1','s_2','s_3','s_4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       ...,\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5328, 4])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8470, dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rWrist_loss.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_folder = 'C:/Users/kacpe/Desktop/study/research lab/lab_rotation_git/gradient_models'\n",
    "model_filename = 's_m80_val13_gates.pth'\n",
    "\n",
    "# Load the model\n",
    "checkpoint = torch.load(os.path.join(load_folder, model_filename))\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5328, 4])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filtered_df = scaled_df[scaled_df['trial'] != 14]\n",
    "#target = filtered_df[['s_1','s_2','s_3','s_4']] \n",
    "target = torch.from_numpy(y_test.to_numpy())\n",
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'grad'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\kacpe\\Desktop\\study\\research lab\\lab_rotation_git\\GRUCell.ipynb Cell 102\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/kacpe/Desktop/study/research%20lab/lab_rotation_git/GRUCell.ipynb#Y223sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39minput\u001b[39;49m\u001b[39m.\u001b[39;49mgrad\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'grad'"
     ]
    }
   ],
   "source": [
    "input.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loss = loss_fn(output, target)\n",
    "model_loss.requires_grad_(True)\n",
    "model_loss.backward()\n",
    "\n",
    "\n",
    "# Access gradients for specific parameters\n",
    "gru_weight_ih_gradients = model.gru.weight_ih.grad  # Gradients for input-hidden weights of GRU\n",
    "gru_weight_hh_gradients = model.gru.weight_hh.grad  # Gradients for hidden-hidden weights of GRU\n",
    "linear_weight_gradients = model.fc.weight.grad  # Gradients for the weight of the linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6458, dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rWrist_x_minus_80</th>\n",
       "      <th>lWrist_x_minus_80</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     rWrist_x_minus_80  lWrist_x_minus_80\n",
       "0                  0.0                0.0\n",
       "1                  0.0                0.0\n",
       "2                  0.0                0.0\n",
       "3                  0.0                0.0\n",
       "4                  0.0                0.0\n",
       "..                 ...                ...\n",
       "97                 0.0                0.0\n",
       "98                 0.0                0.0\n",
       "99                 0.0                0.0\n",
       "100                0.0                0.0\n",
       "101                0.0                0.0\n",
       "\n",
       "[102 rows x 2 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients_array = gru_weight_ih_gradients.numpy()\n",
    "gradients = pd.DataFrame(gradients_array, columns=features)\n",
    "gradients[['rWrist_x_minus_80','lWrist_x_minus_80']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.392157618e-06"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(np.mean(np.round(gradients['rWrist_x_minus_80'] - gradients['lWrist_x_minus_80'],5)),15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kacpe\\anaconda3\\lib\\site-packages\\torch\\_tensor.py:1083: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at  C:\\b\\abs_bao0hdcrdh\\croot\\pytorch_1675190257512\\work\\build\\aten\\src\\ATen/core/TensorBody.h:482.)\n",
      "  return self._grad\n"
     ]
    }
   ],
   "source": [
    "# Perform the backward pass on the combined loss\n",
    "combined_loss = rWrist_loss + lWrist_loss\n",
    "combined_loss.backward()\n",
    "gradients = combined_loss.grad\n",
    "print(gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., dtype=torch.float64)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lWrist_gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Iterate through the test data batches\n",
    "        for inputs, _ in test_dataloader:\n",
    "            inputs = inputs.float()\n",
    "            # Forward pass to get predictions\n",
    "            with torch.no_grad():\n",
    "                predictions, h, test_hidden_states = model(inputs)\n",
    "                probabilities = torch.sigmoid(predictions)\n",
    "                preds = torch.round(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for GRUCellNet:\n\tsize mismatch for gru.weight_ih: copying a param with shape torch.Size([3, 1]) from checkpoint, the shape in current model is torch.Size([102, 46]).\n\tsize mismatch for gru.weight_hh: copying a param with shape torch.Size([3, 1]) from checkpoint, the shape in current model is torch.Size([102, 34]).\n\tsize mismatch for gru.bias_ih: copying a param with shape torch.Size([3]) from checkpoint, the shape in current model is torch.Size([102]).\n\tsize mismatch for gru.bias_hh: copying a param with shape torch.Size([3]) from checkpoint, the shape in current model is torch.Size([102]).\n\tsize mismatch for fc.weight: copying a param with shape torch.Size([4, 1]) from checkpoint, the shape in current model is torch.Size([4, 34]).\n\tsize mismatch for gru_cells.0.weight_ih: copying a param with shape torch.Size([3, 1]) from checkpoint, the shape in current model is torch.Size([102, 46]).\n\tsize mismatch for gru_cells.0.weight_hh: copying a param with shape torch.Size([3, 1]) from checkpoint, the shape in current model is torch.Size([102, 34]).\n\tsize mismatch for gru_cells.0.bias_ih: copying a param with shape torch.Size([3]) from checkpoint, the shape in current model is torch.Size([102]).\n\tsize mismatch for gru_cells.0.bias_hh: copying a param with shape torch.Size([3]) from checkpoint, the shape in current model is torch.Size([102]).\n\tsize mismatch for batch_norm.weight: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([34]).\n\tsize mismatch for batch_norm.bias: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([34]).\n\tsize mismatch for batch_norm.running_mean: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([34]).\n\tsize mismatch for batch_norm.running_var: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([34]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\kacpe\\Desktop\\study\\research lab\\lab_rotation_git\\GRUCell.ipynb Cell 110\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kacpe/Desktop/study/research%20lab/lab_rotation_git/GRUCell.ipynb#Y210sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Load the model\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kacpe/Desktop/study/research%20lab/lab_rotation_git/GRUCell.ipynb#Y210sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m checkpoint \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(load_folder, model_filename))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/kacpe/Desktop/study/research%20lab/lab_rotation_git/GRUCell.ipynb#Y210sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m model\u001b[39m.\u001b[39;49mload_state_dict(checkpoint)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kacpe/Desktop/study/research%20lab/lab_rotation_git/GRUCell.ipynb#Y210sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Set the model in evaluation mode\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kacpe/Desktop/study/research%20lab/lab_rotation_git/GRUCell.ipynb#Y210sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m model\u001b[39m.\u001b[39meval()\n",
      "File \u001b[1;32mc:\\Users\\kacpe\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1604\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   1599\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[0;32m   1600\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   1601\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[0;32m   1603\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m-> 1604\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   1605\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   1606\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for GRUCellNet:\n\tsize mismatch for gru.weight_ih: copying a param with shape torch.Size([3, 1]) from checkpoint, the shape in current model is torch.Size([102, 46]).\n\tsize mismatch for gru.weight_hh: copying a param with shape torch.Size([3, 1]) from checkpoint, the shape in current model is torch.Size([102, 34]).\n\tsize mismatch for gru.bias_ih: copying a param with shape torch.Size([3]) from checkpoint, the shape in current model is torch.Size([102]).\n\tsize mismatch for gru.bias_hh: copying a param with shape torch.Size([3]) from checkpoint, the shape in current model is torch.Size([102]).\n\tsize mismatch for fc.weight: copying a param with shape torch.Size([4, 1]) from checkpoint, the shape in current model is torch.Size([4, 34]).\n\tsize mismatch for gru_cells.0.weight_ih: copying a param with shape torch.Size([3, 1]) from checkpoint, the shape in current model is torch.Size([102, 46]).\n\tsize mismatch for gru_cells.0.weight_hh: copying a param with shape torch.Size([3, 1]) from checkpoint, the shape in current model is torch.Size([102, 34]).\n\tsize mismatch for gru_cells.0.bias_ih: copying a param with shape torch.Size([3]) from checkpoint, the shape in current model is torch.Size([102]).\n\tsize mismatch for gru_cells.0.bias_hh: copying a param with shape torch.Size([3]) from checkpoint, the shape in current model is torch.Size([102]).\n\tsize mismatch for batch_norm.weight: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([34]).\n\tsize mismatch for batch_norm.bias: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([34]).\n\tsize mismatch for batch_norm.running_mean: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([34]).\n\tsize mismatch for batch_norm.running_var: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([34])."
     ]
    }
   ],
   "source": [
    "        # Define the folder and model filename\n",
    "load_folder = 'C:/Users/kacpe/Desktop/study/research lab/lab_rotation_git/gradient_models'\n",
    "model_filename = 'lWrist_model.pth'\n",
    "\n",
    "# Load the model\n",
    "checkpoint = torch.load(os.path.join(load_folder, model_filename))\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "# Set the model in evaluation mode\n",
    "model.eval()\n",
    "# Set the model in evaluation mode\n",
    "\n",
    "\n",
    "# Access the model's state dictionary\n",
    "model_state_dict = model.state_dict()\n",
    "\n",
    "# Now you can access the weights of the nn.GRUCell layers\n",
    "gru_cell_weights = {\n",
    "    key: value\n",
    "    for key, value in model_state_dict.items()\n",
    "    if key.startswith('gru_cells.')\n",
    "}\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# Extract and assign the weights to separate variables\n",
    "lWrist_weights_ih = gru_cell_weights['gru_cells.0.weight_ih']\n",
    "lWrist_weights_hh = gru_cell_weights['gru_cells.0.weight_hh']\n",
    "\n",
    "\n",
    "        # Define the folder and model filename\n",
    "load_folder = 'C:/Users/kacpe/Desktop/study/research lab/lab_rotation_git/gradient_models'\n",
    "model_filename = 'rWrist_model.pth'\n",
    "\n",
    "# Load the model\n",
    "checkpoint = torch.load(os.path.join(load_folder, model_filename))\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "# Set the model in evaluation mode\n",
    "model.eval()\n",
    "# Set the model in evaluation mode\n",
    "\n",
    "\n",
    "# Access the model's state dictionary\n",
    "model_state_dict = model.state_dict()\n",
    "\n",
    "# Now you can access the weights of the nn.GRUCell layers\n",
    "gru_cell_weights = {\n",
    "    key: value\n",
    "    for key, value in model_state_dict.items()\n",
    "    if key.startswith('gru_cells.')\n",
    "}\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# Extract and assign the weights to separate variables\n",
    "rWrist_weights_ih = gru_cell_weights['gru_cells.0.weight_ih']\n",
    "rWrist_weights_hh = gru_cell_weights['gru_cells.0.weight_hh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6961],\n",
      "        [ 0.6693],\n",
      "        [-0.4421]])\n",
      "tensor([[ 0.6961],\n",
      "        [ 0.6693],\n",
      "        [-0.4421]])\n"
     ]
    }
   ],
   "source": [
    "print(lWrist_weights_ih)\n",
    "print(rWrist_weights_ih)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['rWrist_x'], dtype='object')\n",
      "Index(['rWrist_x'], dtype='object')\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "input has inconsistent input_size: got 1 expected 46",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\kacpe\\Desktop\\study\\research lab\\lab_rotation_git\\GRUCell.ipynb Cell 124\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kacpe/Desktop/study/research%20lab/lab_rotation_git/GRUCell.ipynb#Y233sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m test_dataloader \u001b[39m=\u001b[39m DataLoader(test_dataset, batch_size\u001b[39m=\u001b[39mX_test\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kacpe/Desktop/study/research%20lab/lab_rotation_git/GRUCell.ipynb#Y233sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m#print(X_train.shape[0])\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/kacpe/Desktop/study/research%20lab/lab_rotation_git/GRUCell.ipynb#Y233sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m train_losses, train_accs, train_predicted_labels, train_probs_final, train_hidden_states \u001b[39m=\u001b[39m run_training(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kacpe/Desktop/study/research%20lab/lab_rotation_git/GRUCell.ipynb#Y233sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     train_dataloader, val_dataloader\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, model\u001b[39m=\u001b[39;49mmodel, optimizer\u001b[39m=\u001b[39;49moptimizer, loss_fn\u001b[39m=\u001b[39;49mloss_fn, num_epochs\u001b[39m=\u001b[39;49mn_epochs, scheduler\u001b[39m=\u001b[39;49mscheduler)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kacpe/Desktop/study/research%20lab/lab_rotation_git/GRUCell.ipynb#Y233sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m state_dict \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mstate_dict()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kacpe/Desktop/study/research%20lab/lab_rotation_git/GRUCell.ipynb#Y233sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m folder_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mC:/Users/kacpe/Desktop/study/research lab/lab_rotation_git/gradient_models\u001b[39m\u001b[39m'\u001b[39m \n",
      "\u001b[1;32mc:\\Users\\kacpe\\Desktop\\study\\research lab\\lab_rotation_git\\GRUCell.ipynb Cell 124\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kacpe/Desktop/study/research%20lab/lab_rotation_git/GRUCell.ipynb#Y233sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m#train_hidden_states, val_hidden_states = [], []\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kacpe/Desktop/study/research%20lab/lab_rotation_git/GRUCell.ipynb#Y233sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/kacpe/Desktop/study/research%20lab/lab_rotation_git/GRUCell.ipynb#Y233sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     epoch_train_loss, epoch_train_acc, train_preds, train_probs \u001b[39m=\u001b[39m train(train_dataloader, model, optimizer, loss_fn, scheduler, device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kacpe/Desktop/study/research%20lab/lab_rotation_git/GRUCell.ipynb#Y233sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     train_losses\u001b[39m.\u001b[39mappend(epoch_train_loss)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kacpe/Desktop/study/research%20lab/lab_rotation_git/GRUCell.ipynb#Y233sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     train_accs\u001b[39m.\u001b[39mappend(epoch_train_acc)\n",
      "\u001b[1;32mc:\\Users\\kacpe\\Desktop\\study\\research lab\\lab_rotation_git\\GRUCell.ipynb Cell 124\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kacpe/Desktop/study/research%20lab/lab_rotation_git/GRUCell.ipynb#Y233sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mto(device)\u001b[39m.\u001b[39mfloat()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kacpe/Desktop/study/research%20lab/lab_rotation_git/GRUCell.ipynb#Y233sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/kacpe/Desktop/study/research%20lab/lab_rotation_git/GRUCell.ipynb#Y233sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m out, last_hidden_states \u001b[39m=\u001b[39m model(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kacpe/Desktop/study/research%20lab/lab_rotation_git/GRUCell.ipynb#Y233sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m y_prob \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msigmoid(out)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kacpe/Desktop/study/research%20lab/lab_rotation_git/GRUCell.ipynb#Y233sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# Append the predicted probabilities to the list\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kacpe\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\kacpe\\Desktop\\study\\research lab\\lab_rotation_git\\GRUCell.ipynb Cell 124\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kacpe/Desktop/study/research%20lab/lab_rotation_git/GRUCell.ipynb#Y233sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m new_hidden_states \u001b[39m=\u001b[39m []\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kacpe/Desktop/study/research%20lab/lab_rotation_git/GRUCell.ipynb#Y233sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mfor\u001b[39;00m layer_idx, gru_cell \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgru_cells):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/kacpe/Desktop/study/research%20lab/lab_rotation_git/GRUCell.ipynb#Y233sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     h[layer_idx] \u001b[39m=\u001b[39m gru_cell(input_t, h[layer_idx])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kacpe/Desktop/study/research%20lab/lab_rotation_git/GRUCell.ipynb#Y233sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     new_hidden_states\u001b[39m.\u001b[39mappend(h[layer_idx])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kacpe/Desktop/study/research%20lab/lab_rotation_git/GRUCell.ipynb#Y233sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     input_t \u001b[39m=\u001b[39m h[layer_idx]\n",
      "File \u001b[1;32mc:\\Users\\kacpe\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\kacpe\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1279\u001b[0m, in \u001b[0;36mGRUCell.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m   1276\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1277\u001b[0m     hx \u001b[39m=\u001b[39m hx\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_batched \u001b[39melse\u001b[39;00m hx\n\u001b[1;32m-> 1279\u001b[0m ret \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mgru_cell(\n\u001b[0;32m   1280\u001b[0m     \u001b[39minput\u001b[39;49m, hx,\n\u001b[0;32m   1281\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight_ih, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight_hh,\n\u001b[0;32m   1282\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_ih, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_hh,\n\u001b[0;32m   1283\u001b[0m )\n\u001b[0;32m   1285\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_batched:\n\u001b[0;32m   1286\u001b[0m     ret \u001b[39m=\u001b[39m ret\u001b[39m.\u001b[39msqueeze(\u001b[39m0\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: input has inconsistent input_size: got 1 expected 46"
     ]
    }
   ],
   "source": [
    "rwrist_df = scaled_df[['rWrist_x','trial','id','s_1','s_2','s_3','s_4']]\n",
    "lwrist_df = scaled_df[['lWrist_x','trial','id','s_1','s_2','s_3','s_4']]\n",
    "labels = ['s_1','s_2','s_3','s_4']\n",
    "\n",
    "#rwrist_df = lwrist_df.copy()\n",
    "set_values = 13 \n",
    "train_set = rwrist_df[rwrist_df['trial']!=set_values].drop(columns=['id', 'trial'])\n",
    "test_set = rwrist_df[rwrist_df['trial']==set_values].drop(columns=['id', 'trial'])\n",
    "full_set = rwrist_df.drop(columns=['id','trial'])\n",
    "\n",
    "# split data into x and y \n",
    "X_train, y_train = train_set.drop(columns=labels), train_set[labels]\n",
    "X_test, y_test = test_set.drop(columns=labels), test_set[labels]\n",
    "X, y = full_set.drop(columns=labels), full_set[labels]\n",
    "print(X_train.columns)\n",
    "# reset index \n",
    "X_train, y_train = X_train.reset_index(drop=True), y_train.reset_index(drop=True)\n",
    "X_test, y_test = X_test.reset_index(drop=True), y_test.reset_index(drop=True)\n",
    "X, y = X.reset_index(drop=True), y.reset_index(drop=True) \n",
    "print(X_train.columns)\n",
    "# Create custom datasets for training, validation, and testing\n",
    "full_dataset = MyDataset(torch.tensor(X.values), torch.tensor(y.values))\n",
    "train_dataset = MyDataset(torch.tensor(X_train.values), torch.tensor(y_train.values))\n",
    "test_dataset = MyDataset(torch.tensor(X_test.values), torch.tensor(y_test.values))\n",
    "\n",
    "fullset_dataloader = DataLoader(full_dataset, batch_size=X.shape[0], shuffle=False)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=X_train.shape[0], shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=X_test.shape[0], shuffle=False)\n",
    "#print(X_train.shape[0])\n",
    "\n",
    "\n",
    "train_losses, train_accs, train_predicted_labels, train_probs_final, train_hidden_states = run_training(\n",
    "    train_dataloader, val_dataloader=None, model=model, optimizer=optimizer, loss_fn=loss_fn, num_epochs=n_epochs, scheduler=scheduler)\n",
    "\n",
    "\n",
    "state_dict = model.state_dict()\n",
    "folder_path = 'C:/Users/kacpe/Desktop/study/research lab/lab_rotation_git/gradient_models' \n",
    "model_filename = 'rWrist_model.pth'  \n",
    "\n",
    "# Combine the folder path and model filename\n",
    "full_model = os.path.join(folder_path, model_filename)\n",
    "\n",
    "        # Save the model to the specified folder\n",
    "torch.save(state_dict, full_model)\n",
    "\n",
    "# Iterate through the test data batches\n",
    "for inputs, _ in train_dataloader:\n",
    "    inputs = inputs.float()\n",
    "    inputs.requires_grad = True  # Set requires_grad to True\n",
    "    # Forward pass to get predictions\n",
    "    with torch.no_grad():\n",
    "        predictions, h, test_hidden_states = model(inputs)\n",
    "        probabilities = torch.sigmoid(predictions)\n",
    "        rWrist_output = torch.round(probabilities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
